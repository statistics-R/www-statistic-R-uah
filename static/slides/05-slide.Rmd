---
title: "Estadística II"
author: "Valentina Andrade"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    self_contained: true
    lib_dir: "libs"
    chakra: "libs/remark-latest.min.js"
    css: ["default", "css/ath-slides.css", "css/ath-inferno-fonts.css", "css/animate.css"]
    seal: false
    includes:
      after_body: "html/insert-logo.html"
    anchor_sections: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "libs/macros.js"
      navigation:
        scroll: false
editor_options: 
  chunk_output_type: console
---


```{r packages-data, include=FALSE, echo =FALSE}
pacman::p_load(tidyverse, sjPlot, ggsci,wooldrige, broom)
theme_set(theme_sjplot2())

wages <- tibble(salario = c(0.5, 2, 1, 2.5, 3, 1.5, 2, 2.5, 2, 3),
                  educ = 1:10)
wages_data <- wages
wages_model <- lm(salario ~ educ, data = wages)
wages_fitted <- augment(wages_model)
wages_base <- ggplot(wages_fitted, aes(x = educ, y = salario)) +
  geom_point(size = 3) +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 3)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Años educacion", y = "Salarios") 
```
```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view", "animate_css", "share_again", "scribble", "frezeeframe", "editable", "progress_bar"))

xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```


```{r xaringanExtra-clipboard, echo=FALSE}
htmltools::tagList(
  xaringanExtra::use_clipboard(
    button_text = "<i class=\"fa fa-clipboard\">Copiar código</i>",
    success_text = "<i class=\"fa fa-check\" style=\"color: #90BE6D\">¡Listo!</i>",
    error_text = "<i class=\"fa fa-times-circle\" style=\"color: #F94144\"></i>"
  ),
  rmarkdown::html_dependency_font_awesome()
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = "center")
```

class: center middle main-title section-title-8 top-logo

.small[
# Regresión lineal simple
]

.class-info[
<br>
**Sesión N° 5**<br>
**Estadísitica II**
<br>

.pull-right.small[
**Profesora** Valentina Andrade de la Horra <br>
**Apoyo docente** Nicolás Godoy <br>
**Ayudantes** Moira Martinez y Charo Astorga
.tiny[Universidad Alberto Hurtado<br>
]
]

]

---
class: title title-inv-8

# Contenidos Sesión 

--
.box-2.medium.sp-after-half[Regresiones **lineal simple**]
--
.box-8.medium.sp-after-half[**MCO** supuestos]
--
.box-8.medium.sp-after-half[**MCO**: propiedades]


---
class: center middle main-title section-title-2 top-logo
name: basics

# Regresión **lineal** simple

---
class: title title-2

# 1. Pregunta

.box-inv-2.medium.sp-after-half[**educación sobre salario**]


```{r, echo = F,  fig.dim=c(7, 3), out.width="100%"}
wages_base <- ggplot(wages_fitted, aes(x = educ, y = salario)) +
  geom_point(size = 3) +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 3)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Años educacion", y = "Salarios") 
wages_base
```


---
class: title title-2

# 2. Formalizar el modelo teórico

$$y = \beta_0 + \beta_1 x_1 + u$$

--

- $y$ = datos sobre variable dependiente

- $x_1$ = datos sobre variable independiente

- $\beta_1$ = pendiente, parámetro que indica la relación de $x$ e $y$

- $\beta_o$ = intercepto

- $u$ = error

---

class: center middle main-title section-title-8 top-logo

# Interpretación $\beta_1$

--

##Por cada **unidad** que cambie $x$, $y$ va a cambiar en $\beta_1$, manteniendo **el resto de los factores constantes**. 

$$\triangle y = \beta_1 \triangle x  ~~~ si ~~\triangle u = 0$$

---

class: center middle main-title section-title-8 top-logo

# Interpretación $\beta_0$

--

## Valor esperado o medio de $y$ cuando $x = 0$ (o en ausencia de variables explicativas)

---

class: center middle main-title section-title-8 top-logo

# Error $u$

--

## Contiene todos los factores **relevantes** que afectan a $Y$ pero no son considerados en la regresión por ser **inobservables**

---

class: center middle main-title section-title-8 top-logo


# Pero, ¿cómo obtenemos los parámetros $\beta$

--

## Mínimos Cuadrados Ordinarios

---

class: title title-8
# Mínimos Cuadrados Ordinarios (OLS)


```{r cookies-lm-residual, echo=FALSE, message=FALSE, fig.dim=c(7, 3), out.width="100%"}
wages_with_residual <- wages_base +
  geom_smooth(method = "lm", color = "#0074D9", se = FALSE) +
  geom_segment(aes(xend = educ, yend = .fitted), color = "#FF851B", size = 1)
wages_with_residual
```

---

class: title title-8
# Mínimos Cuadrados Ordinarios (OLS)


- Método que busca encontrar la mejor ecuación de la recta, dado un set de datos

--

- *Mínimos*: minimizan los residuos

- *Cuadrados*: residuos al cuadrado

- *Ordinarios*: es un método estándar

---
class: title title-8
# Valor observado y valor predicho

- $y_i$: valor observado
- $\hat{y_i}$: valor predicho corresponde al valor que predecimos de $y_i$ cuando $x_{1i}$ toma un valor dado

--

$$\hat{y_i} = \beta_o + \beta_1 x_{1i}$$

- Hay un valor predicho para cada observación en la muestra

--

- ¿Qué significará la diferencia entre $y_i$ e $\hat{y_i}$?



---

class: center middle main-title section-title-8 top-logo

# El residuo $\hat{u_i}$

--

## En particular nos interesará que sea la **suma de los residuos** al **cuadrado** sea lo más pequeño posible

---
class: title title-8
# Distancia a recta regresión

<center>
<img src="https://raw.githubusercontent.com/statistics-R/slides/main/img/04/03.png" alt="drawing" style="width:700px;"/>
</center>


---
class: title title-8
# Suma de residuos al cuadrado 

- Minimizamos la *suma de residuos al cuadrado* $\sum_{i=1}^{n} \hat u_i^2$

- Encontramos matemáticamente $\hat{\beta_0}$ y $\hat{\beta_1}$ tal que $\sum_{i=1}^{n} \hat u_i^2$ sea lo más pequeño posible.

--

- Varios minutos después ⏱️📝 y ...

---
class: center middle main-title section-title-8 top-logo


## $$\hat \beta_1 = \frac{\sum^n_{i=1} (x_i - \bar x)(y_i - \bar y)}{\sum_{i=1}^n (x_i-\bar x)^2}$$

---
class: center middle main-title section-title-8 top-logo

## $$\hat \beta_1 = \frac{\sum^n_{i=1} (x_i - \bar x)(y_i - \bar y)}{\sum_{i=1}^n (x_i-\bar x)^2} = \frac{Cov(x_1,y)}{Var(x_1)}$$


---
class: center middle main-title section-title-8 top-logo

## $$\hat \beta_0 = \bar y = \hat{\beta_1} \bar x$$

---

class: center middle main-title section-title-8 top-logo

# En resumen

---
class: title title-8

# Estimación

.box-inv-8[Datos ->Estimación -> Verdad ]


| Datos | $X, Y$ |
|---|---|
| **Calculos** | $\bar{X} = \frac{\sum X}{n}$ |
| **Estimador** | $\bar{\beta_1}$|
| **Parametro verdadero** | $\beta$ |

---
class: title title-8

# Estimación: ejemplo

```{r, echo = F}
wage1<- wooldridge::wage1
modelo1 <- lm(wage ~ educ, data = wage1)
```

---

```{r, echo = T}
summary(modelo1)
```

---
class: center middle main-title section-title-8 top-logo

# Supuestos Modelo Regresión Lineal 

---
class: title title-8

# Supuesto 1 

.box-8[Linealidad de parámetros]
.box-inv-8[Linealidad refiere a que la ecuación puede ser escrita como

$$y = \beta_0 + \beta_1 x + u$$]

---
class: title title-8

# Supuesto 2

.box-8[Independencia de observaciones]
.box-inv-8[Se cuenta con una muestra aleatoria de tamaño $n$ que representa la población]

---
class: title title-8

# Supuesto 3 

.box-8[**Media condicional cero**]
.box-inv-8[Para todo valor de variable explicativa, el valor esperado del error u es cero

$$E(u|x) = 0$$]

--

.box-inv-8[ u no está correlacionada con x ]

--

.box-inv-8[Es el **supuesto más importante** del MRL]

---
## $$E(u|x) = 0$$

```{r, echo = F,  fig.dim=c(7, 3), out.width="100%"}
ggplot(modelo1, aes(x = educ, y = .resid)) +
    geom_point(size = 3) +
    geom_smooth(method = "lm", color = "#0074D9", se = FALSE) +
  labs( y = "Residuos")
```


---

## $$E(u|x) \neq 0$$


```{r, echo = F,  fig.dim=c(7, 3), out.width="100%"}
ggplot(modelo1, aes(x = educ, y = .resid*educ+10*educ)) +
    geom_point(size = 3) +
    geom_smooth(method = "lm", color = "#0074D9", se = FALSE) +
    labs( y = "Residuos")
```

---

## $$E(u|x) \neq 0$$


```{r, echo = F,  fig.dim=c(7, 3), out.width="100%"}
ggplot(modelo1, aes(x = educ, y = .resid*educ+10*educ)) +
    geom_point(size = 3) +
    geom_smooth(method = "lm", color = "#0074D9", se = FALSE) +
  geom_hline(yintercept = 0, color = "red", size = 1) +
    labs( y = "Residuos")
```

---
class: title title-8

# Supuesto 5 

.box-8[**Homocedasticidad**]
.box-inv-8[El error $u$ tiene la misma **varianza** para cualquier valor de la $X$

$$Var(u|x) = \sigma ^2$$]

--
.box-inv-8[La varianza de y dado x es **constante**]

--
.box-8[Supuesto importante para la **inferencia** sobre los estimadores]
.box-inv-8[Si le tomas raíz a esta varianza obtienes el **error estándar**]

---
class: center middle main-title section-title-8 top-logo

# Propiedades de los estimadores 

---
class: title title-8

# Propiedad 1

.box-8[Insesgamiento de los estimadores de MCO]
.box-inv-8[$$E(\hat \beta_1) = \beta_1$$
$$E(\hat \beta_0) = \beta_0$$]

--

- Por *supuesto 1 a 3*

---
class: title title-8

# Propiedad 2

.box-8[Eficiencia]

.box-inv-8[La varianza de los estimadores $b$ es la menor de todas]

--

.box-inv-8[Esto será muy importante para hacer test de hipótesis (inferencia)]


--

- Por *supuesto 5*


---
<center>
<img src="https://raw.githubusercontent.com/statistics-R/slides/main/img/05/01.png" alt="drawing" style="width:800px;"/>
</center>

---

<center>
<img src="https://raw.githubusercontent.com/statistics-R/slides/main/img/05/02.png" alt="drawing" style="width:800px;"/>
</center>


---
<center>
<img src="https://raw.githubusercontent.com/statistics-R/slides/main/img/05/03.png" alt="drawing" style="width:800px;"/>
</center>

---

layout: false
class: center middle main-title section-title-8 top-logo

.small[
# Regresión **lineal** simple
]

.class-info[
<br>
**Sesión N° 5**<br>
**Estadísitica II**
<br>

.pull-right.small[
**Profesora** Valentina Andrade de la Horra <br>
**Apoyo docente** Nicolás Godoy <br>
**Ayudantes** Moira Martinez y Charo Astorga
.tiny[Universidad Alberto Hurtado<br>
]
]

]
