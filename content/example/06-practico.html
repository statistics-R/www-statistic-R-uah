---
title: "Regresión lineal múltiple"
linktitle: "6: Regresión lineal múltiple"
date: "2023-28-03"
menu:
  example:
    parent: Ejemplos
    weight: 1
type: docs
toc: true
editor_options: 
  chunk_output_type: console
---


<div id="TOC">

</div>

<div id="objetivo-del-práctico" class="section level2">
<h2>0. Objetivo del práctico</h2>
<p>El presente práctico tiene dos objetivos:</p>
<ol style="list-style-type: decimal">
<li><p>Comprender las implicancias de la incorporación de más de un predictor en modelos de regresión lineal.</p></li>
<li><p>Aprender a estimar una regresión lineal múltiple en R con <code>lm()</code>.</p></li>
</ol>
<div id="materiales-de-la-sesión" class="section level3">
<h3>Materiales de la sesión</h3>
<p>Tal como en la sesión anterior, en este práctico se utilizarán los datos sobre <strong>salarios</strong> utilizados en el capítulo 2 del libro <em>Introducción a la econometría</em> de J.W. Wooldridge (2015).</p>
<p>Asimismo, la realización de este práctico requiere la carga de diversos <strong>paquetes</strong> que nos permitirán explorar los datos y presentar los modelos estimados.</p>
<pre class="r"><code>if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) # Instalamos pacman en caso de necesitarlo
pacman::p_load(wooldridge, #Para descargar los datos
               dplyr, #Para procesar datos
               sjmisc, #Para explorar los datos
               sjPlot, #Para explorar los datos
               srvyr, #Para crear un objeto encuesta
               survey, #Para realizar estimaciones incorporando el diseño muestral
               texreg) #Para presentar el modelo de regresión estimado
data(&quot;wage1&quot;) #Cargamos los datos
wage1 = select(wage1, wage, educ, exper) #Seleccionamos sólo las variables por analizar</code></pre>
</div>
</div>
<div id="volviendo-a-explorar-los-datos" class="section level2">
<h2>1. Volviendo a explorar los datos</h2>
<p>Si bien en este práctico volveremos a analizar el efecto de los años de escolaridad sobre los salarios por hora, ahora incorporaremos una nueva variable explicativa: los años de experiencia laboral.</p>
<ul>
<li><strong>wage</strong> (<span class="math inline">\(y\)</span>): indica el salario por hora en miles de pesos de cada persona en los datos.</li>
<li><strong>educ</strong> (<span class="math inline">\(x_1\)</span>): indica el número de años de escolaridad de cada persona en los datos.</li>
<li><strong>exper</strong> (<span class="math inline">\(x_2\)</span>): indica los años de experiencia laboral de cada persona en los datos.</li>
</ul>
<p>Las seleccionaremos utilizando la función <code>select()</code> de <code>dplyr</code>, a modo de trabajar con un set de datos más acotado</p>
<pre class="r"><code>wage1 = select(wage1, wage, educ, exper) #Seleccionamos sólo las variables por analizar</code></pre>
<p>Recordemos la distribución de estas variables:</p>
<p><img src="/example/06-practico_files/figure-html/plot_wage-1.png" width="672" /></p>
<p><img src="/example/06-practico_files/figure-html/plot_educ-1.png" width="672" /></p>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_bar).</code></pre>
<p><img src="/example/06-practico_files/figure-html/plot_exper-1.png" width="672" /></p>
<p>En este caso, la variable por explicar sigue siendo <strong>wage</strong> (<span class="math inline">\(y\)</span>), a partir de la cual estimaremos un modelo de <strong>regresión lineal múltiple</strong> sobre <strong>educ</strong> (<span class="math inline">\(x_1\)</span>) y <strong>exper</strong> (<span class="math inline">\(x_2\)</span>). Un modelo de regresión lineal múltiple se puede expresar a partir de la siguiente ecuación:</p>
<p><span class="math display">\[
\begin{equation}
\hat{y} = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2}
\end{equation}
\]</span>
Donde</p>
<ul>
<li><p><span class="math inline">\(\beta_0\)</span>: Corresponde al intercepto de regresión.</p></li>
<li><p><span class="math inline">\(\beta_1\)</span>: Corresponde a la <strong>pendiente</strong> estimada para la función de regresión lineal de los <strong>salarios por hora</strong> (<span class="math inline">\(y\)</span>) sobre los <strong>años de escolaridad</strong> (<span class="math inline">\(x_1\)</span>). Así, por cada unidad que aumente <span class="math inline">\(x_1\)</span> (en este caso, por cada año de escolaridad extra), el valor estimado <span class="math inline">\(\hat{y}\)</span> para los salarios por hora aumentará o disminuirá en <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p><span class="math inline">\(\beta_2\)</span>: Corresponde a la <strong>pendiente</strong> estimada para la función de regresión lineal de los <strong>salarios por hora</strong> (<span class="math inline">\(y\)</span>) sobre los <strong>años de experiencia laboral</strong> (<span class="math inline">\(x_2\)</span>). Así, por cada unidad que aumente <span class="math inline">\(x_1\)</span> (en este caso, por cada año de experiencia laboral), el valor estimado <span class="math inline">\(\hat{y}\)</span> para los salarios por hora aumentará o disminuirá en <span class="math inline">\(\beta_2\)</span>.</p></li>
</ul>
<p>En este caso, se podría plantear la hipótesis de que tanto <strong>educ</strong> como <strong>exper</strong> debiesen tener un efecto positivo sobre <strong>wage</strong>. Es decir, que</p>
<ul>
<li><p>Quienes tengan más años de escolaridad debiesen tender, en promedio, valores predichos más altos que quienes tengan menos años de escolaridad. Así, se espera que <span class="math inline">\(\beta_1&gt;0\)</span>; y</p></li>
<li><p>Quienes tengan más años de experiencia laboral debiesen tender, en promedio, valores predichos más altos que quienes tengan menos años de experiencia laboral. Así, se espera que <span class="math inline">\(\beta_2&gt;0\)</span>.</p></li>
</ul>
<p>Como sabemos, existe una correlación de 0.41 entre salarios por hora y años de escolaridad:</p>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/example/06-practico_files/figure-html/plot_cor1-1.png" width="672" /></p>
<p>Por otra parte, esperamos que exista una asociación positiva entre salarios por hora y años de experiencia laboral</p>
<pre class="r"><code>sjPlot::plot_scatter(wage1, 
                     x = exper, 
                     y = wage,
                     title = &quot;Relación entre salarios (en miles de pesos) por hora y años de experiencia laboral&quot;,
                     fit.line = &quot;lm&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/example/06-practico_files/figure-html/plot_cor2-1.png" width="672" /></p>
<p>Como podemos ver, la pendiente de la recta de regresión presentada no tiene una pendiente tan acentuada, lo cual sería indicativo de una baja relación entre ambas variables. Sin embargo, puede surgir la duda respecto de qué tan relacionadas están nuestras dos variables explicativas. Explorémoslo</p>
<pre class="r"><code>sjPlot::plot_scatter(wage1, 
                     x = educ, 
                     y = exper,
                     title = &quot;Relación entre años de escolaridad y años de experiencia laboral&quot;,
                     fit.line = &quot;lm&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/example/06-practico_files/figure-html/plot_cor3-1.png" width="672" /></p>
<p>La siguiente tabla presenta los coeficientes de correlación de Pearson para todas las variables por analizar:</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;">
 
</th>
<th style="font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;">
wage
</th>
<th style="font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;">
educ
</th>
<th style="font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;">
exper
</th>
</tr>
<tr>
<td style="font-style:italic;">
wage
</td>
<td style="padding:0.2cm; text-align:center;">
 
</td>
<td style="padding:0.2cm; text-align:center;">
 
</td>
<td style="padding:0.2cm; text-align:center;">
 
</td>
</tr>
<tr>
<td style="font-style:italic;">
educ
</td>
<td style="padding:0.2cm; text-align:center;">
0.406<span style="vertical-align:super;font-size:0.8em;">***</span>
</td>
<td style="padding:0.2cm; text-align:center;">
 
</td>
<td style="padding:0.2cm; text-align:center;">
 
</td>
</tr>
<tr>
<td style="font-style:italic;">
exper
</td>
<td style="padding:0.2cm; text-align:center;">
0.113<span style="vertical-align:super;font-size:0.8em;">**</span>
</td>
<td style="padding:0.2cm; text-align:center;">
-0.300<span style="vertical-align:super;font-size:0.8em;">***</span>
</td>
<td style="padding:0.2cm; text-align:center;">
 
</td>
</tr>
<tr>
<td colspan="4" style="border-bottom:double black; border-top:1px solid black; font-style:italic; font-size:0.9em; text-align:right;">
Computed correlation used pearson-method with listwise-deletion.
</td>
</tr>
</table>
<p>Como podemos ver, la asociación entre los años de experiencia laboral y los años de escolaridad es negativa y más fuerte que la correlación entre los primeros y el salario por hora. ¿Cómo puede esto afectar a la estimación de nuestro modelo? ¿qué efecto puede tener sobre la magnitud y el sentido de los coeficientes estimados? ¿cómo saber si vale la pena incorporar nuevas variables en el análisis? A continuación abordaremos todas estas inquietudes, retomando los conceptos que hemos estado revisando en las clases anteriores.</p>
</div>
<div id="estimando-modelos-de-regresión-lineal-simple-y-múltiple-con-lm" class="section level2">
<h2>2. Estimando modelos de regresión lineal simple y múltiple con <code>lm()</code></h2>
<p>En términos de código, la estimación de modelos de regresión lineal simple no distan mucho de la estimación de modelos de regresión lineal múltiple. Estimemos el modelo para salarios por hora sobre años de escolaridad</p>
<p><span class="math display">\[
\begin{equation}
\hat{wage} = \beta_0 + \beta_1educ_{i}
\end{equation}
\]</span></p>
<pre class="r"><code>m1 = lm(wage ~ educ, data = wage1)</code></pre>
<p>Luego, el modelo para salarios por hora sobre años de experiencia laboral</p>
<p><span class="math display">\[
\begin{equation}
\hat{wage} = \beta_0 + \beta_2exper_{i}
\end{equation}
\]</span></p>
<pre class="r"><code>m2 = lm(wage ~ exper, data = wage1)</code></pre>
<p>Por último, el modelo para salarios por hora sobre años de escolaridad y años de experiencia laboral</p>
<p><span class="math display">\[
\begin{equation}
\hat{wage} = \beta_0 + \beta_1educ_{i} + \beta_2exper_{i}
\end{equation}
\]</span></p>
<pre class="r"><code>m3 = lm(wage ~ educ + exper, data = wage1)</code></pre>
<p>Como podemos ver, la única diferencia entre la estimación de un modelo de regresión lineal simple y uno múltiple con <code>lm()</code> es la incorporación de todas las variables explicativas, una tras otra, separadas por <code>+</code> (signo más).</p>
<p>Comparemos los tres modelos:</p>
<pre><code>## 
## ===============================================
##              Modelo 1    Modelo 2    Modelo 3  
## -----------------------------------------------
## (Intercept)   -0.90        5.37 ***   -3.39 ***
##               (0.68)      (0.26)      (0.77)   
## educ           0.54 ***                0.64 ***
##               (0.05)                  (0.05)   
## exper                      0.03 **     0.07 ***
##                           (0.01)      (0.01)   
## -----------------------------------------------
## R^2            0.16        0.01        0.23    
## Adj. R^2       0.16        0.01        0.22    
## Num. obs.    526         526         526       
## ===============================================
## *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05</code></pre>
<p>Considerando las ecuaciones formuladas genéricamente más arriba, los modelos estimados se puede expresar así:</p>
<ul>
<li><strong>Modelo 1</strong>
<span class="math display">\[
\begin{equation}
\hat{wage} = -.9 + .54educ_{i}
\end{equation}
\]</span></li>
<li><strong>Modelo 2</strong></li>
</ul>
<p><span class="math display">\[
\begin{equation}
\hat{wage} = 5.37 + 0.03exper_{i}
\end{equation}
\]</span></p>
<ul>
<li><strong>Modelo 3</strong></li>
</ul>
<p><span class="math display">\[
\begin{equation}
\hat{wage} = -3.39 + .64educ_{i} + .07exper_{i}
\end{equation}
\]</span></p>
<p>Hay varias diferencias entre los tres modelos que podemos advertir:</p>
<ul>
<li><p>El valor del <strong>intercepto</strong> de regresión es distinto entre los tres modelos.</p></li>
<li><p>Los valores de los <strong>coeficientes de regresión</strong> estimados para ambas variables son diferentes al incorporar ambas variables en conjunto.</p></li>
<li><p>La bondad de ajuste de los tres modelos expresada a través del estadístico <span class="math inline">\(R^2\)</span> también difiere en los tres modelos, siendo mayor en el modelo 3 (<span class="math inline">\(R^2\)</span> = .22).</p></li>
<li><p>Mientras que en los modelos 1 y 2 los estadísticos <span class="math inline">\(R^2\)</span> y <span class="math inline">\(R^2\)</span> Ajustado (Adj. <span class="math inline">\(R^2\)</span>) son equivalentes, en el modelo 3 el valor de <span class="math inline">\(R^2\)</span> (.23) y <span class="math inline">\(R^2\)</span> Ajustado (.22) difieren en .01.</p></li>
</ul>
<p>De ello podemos deducir que:</p>
<ul>
<li>Los años de escolaridad permiten explicar mejor que los años de experiencia laboral los salarios por hora promedio. Esto, porque
<ul>
<li>El <span class="math inline">\(R^2\)</span> del modelo 1 (.16) es mayor que el del modelo 2 (.01).</li>
<li>La magnitud del coeficiente de regresión de años de escolaridad es mayor que la del coeficiente estimado para años de experiencia laboral.</li>
</ul></li>
<li>El efecto estimado de los años de escolaridad y años de experiencia laboral sobre los salarios por hora es positivo, tal como se planteó en la hipótesis al inicio del práctico.</li>
<li>El modelo 3 permite explicar mejor la variabilidad de <span class="math inline">\(y\)</span> que los modelos 2 y 1.</li>
<li>El valor estimado para el estadístico <span class="math inline">\(R^2\)</span> ajustado tiende a ser penalizado cuando se incorpora más de una variable explicativa; es decir, en modelos de regresión lineal múltiple, <span class="math inline">\(R^2 &gt; Adj.R^2\)</span>. Por eso, en modelos múltiples es preferible evaluar la bondad de ajuste en base al estadístico ajustado, en la medida que es un criterio más estricto para definir qué tan bien las variables explicativas en su conjunto permiten explicar la variabilidad de <span class="math inline">\(y\)</span>.</li>
</ul>
<p>¿Por qué sucede todo esto al incorporar una nueva variable explicativa? Para comprenderlo, recurriremos al concepto de <strong>parcialización</strong>.</p>
</div>
<div id="la-parcialización" class="section level2">
<h2>3. La parcialización</h2>
<p>Como pudimos ver anteriormente, <strong>educ</strong> está correlacionado negativa y moderadamente (R = -.3) con <strong>exper</strong>. Esto tiene como consecuencia que una parte del efecto de <strong>educ</strong> sobre <strong>wage</strong> es compartida por <strong>exper</strong>, y viceversa, lo cual genera cambios tanto en la estimación de los coeficientes de regresión como en la bondad de ajuste. Recordemos que lo que esperamos hacer con un modelo de estas características es aislar el efecto de <span class="math inline">\(x_1,x_2,...,x_n\)</span> sobre <span class="math inline">\(y\)</span>. Es decir: poder analizar el efecto de <span class="math inline">\(x_1\)</span> sobre <span class="math inline">\(y\)</span>, manteniendo constante el efecto del resto de variables involucradas en la variabilidad de <span class="math inline">\(y\)</span>. Considerando nuestro <strong>modelo 3</strong> <span class="math inline">\(\hat{wage} = -3.39 + .64educ_{i} + .07exper_{i}\)</span>, ello se leería de la siguiente manera:</p>
<ul>
<li><p>Por cada año de escolaridad adicional se espera que, en promedio, el salario por hora predicho aumente en .64 mil pesos, sin importar los años de experiencia que tenga la persona. Así, una persona con 20 años de experiencia, pero con 17 años de escolaridad debiese percibir un salario por hora promedio de 8.89 mil pesos; mientras se espera que, en promedio, alguien con los mismos años de experiencia laboral y 12 años de escolaridad obtenga un salario por hora de 5.69 mil pesos, lo cual expresa una diferencia media de 3.2 mil pesos.</p></li>
<li><p>Por cada año de experiencia laboral adicional se espera que, en promedio, el salario por hora predicho aumente en .07 mil pesos, sin importar los años de experiencia que tenga la persona. Así, una persona con 12 años de escolaridad, pero con 20 años de experiencia laboral debiese percibir un salario por hora promedio de 5.69 mil pesos; mientras se espera que, en promedio, alguien con los mismos años de escolaridad y 10 años de experiencia laboral obtenga un salario por hora de 4.99 mil pesos, lo cual expresa una diferencia media de 0.7 mil pesos.</p></li>
</ul>
<p>Para poder realizar un análisis “manteniendo constante el efecto del resto de factores”, empleamos el procedimiento de <strong>parcialización</strong>, que consiste en remover la <strong>covarianza común</strong> que existe entre los predictores. A ello se le denomina <strong>efecto parcial</strong>, en la medida que estima regresión considerando solamente el efecto de <span class="math inline">\(x_n\)</span> sobre <span class="math inline">\(y\)</span> que no es compartido con los otros predictores.
¿Cómo saber cuál es la magnitud del efecto común a ambas variables y extraerlo? Para ello podemos modelar una regresión simple en que los predictores son las variables del modelo. En este caso, estimar un modelo que mida el efecto de <strong>educ</strong> sobre <strong>exper</strong>. Ello nos permitirá calcular, a su vez, los <strong>residuos</strong> del modelo entre las variables explicativas, que representa la parte de <span class="math inline">\(x_1\)</span> que no es explicada por <span class="math inline">\(x_2\)</span>. A su vez, el coeficiente de regresión <span class="math inline">\(\beta_1\)</span> representa todo lo compartido entre <strong>educ</strong> y <strong>exper</strong>. Estimemos el modelo:</p>
<pre class="r"><code>mod_p = lm(educ ~ exper, wage1)
summary(mod_p)</code></pre>
<pre><code>## 
## Call:
## lm(formula = educ ~ exper, data = wage1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -12.258  -1.358  -0.236   1.721   6.170 
## 
## Coefficients:
##              Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept) 13.602708   0.185024  73.519 &lt; 0.0000000000000002 ***
## exper       -0.061113   0.008504  -7.187      0.0000000000023 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.644 on 524 degrees of freedom
## Multiple R-squared:  0.08973,    Adjusted R-squared:  0.08799 
## F-statistic: 51.65 on 1 and 524 DF,  p-value: 0.000000000002295</code></pre>
<p>Así</p>
<p><span class="math display">\[
\begin{equation}
\hat{educ} = 13.60 + 0.06exper_{i}
\end{equation}
\]</span></p>
<p>Estimemos los <strong>residuos</strong> para cada observación; es decir, la diferencia entre el valor predicho y el observado que, en este caso, representa la varianza no explicada de los años de experiencia laboral sobre los años de escolaridad.</p>
<pre class="r"><code>pred = fitted.values(mod_p)
res = residuals(mod_p)
wage1 = cbind(wage1, pred, res)</code></pre>
<p>Ahora hagamos una regresión lineal de <strong>wage</strong> sobre los <strong>residuos</strong> estimados para el modelo de <strong>educ</strong> sobre <strong>exper</strong></p>
<pre class="r"><code>mod_res = lm(wage ~ res, wage1)
screenreg(list(m3, mod_res), custom.model.names = c(&quot;Modelo 3&quot;, &quot;Modelo 4&quot;))</code></pre>
<pre><code>## 
## ===================================
##              Modelo 3    Modelo 4  
## -----------------------------------
## (Intercept)   -3.39 ***    5.90 ***
##               (0.77)      (0.14)   
## educ           0.64 ***            
##               (0.05)               
## exper          0.07 ***            
##               (0.01)               
## res                        0.64 ***
##                           (0.05)   
## -----------------------------------
## R^2            0.23        0.21    
## Adj. R^2       0.22        0.21    
## Num. obs.    526         526       
## ===================================
## *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05</code></pre>
<p>Podemos ver que el coeficiente estimado para <strong>educ</strong> en el modelo 3 es igual que aquel estimada para el modelo 4. Es decir, el <strong>coeficiente parcializado</strong> para los años de escolaridad estimado en el modelo 3 representa el efecto de la parte de <strong>educ</strong> que no es explicada por <strong>exper</strong> sobre <strong>wage</strong>. Como pueden haber intuido, la parcialización es un procedimiento que <code>lm()</code> realiza automáticamente a la hora de estimar los modelos, pese a lo cual es <strong>fundamental</strong> comprenderlo adecuadamente para poder entender qué significa analizar el efecto de <span class="math inline">\(x_n\)</span> sobre <span class="math inline">\(y\)</span> <em>ceteris paribus</em>.</p>
<p>En síntesis: la parcialización nos permite estimar y analizar el <strong>efecto parcial</strong> de <span class="math inline">\(x_n\)</span> sobre <span class="math inline">\(y\)</span>, <strong>controlando</strong> el efecto de otras variables sobre <span class="math inline">\(y\)</span>.</p>
</div>
<div id="resumen" class="section level2">
<h2>Resumen</h2>
<p>En este práctico aprendimos las diferencias existentes entre modelos de regresión lineal simple y múltiple, poniendo especial atención al concepto de <strong>parcialización</strong>.</p>
</div>
