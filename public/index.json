[{"authors":null,"categories":null,"content":"Aquí podrán encontrar recursos y guías extras sobre uso de R, datos y otros tópicos relevantes.\n","date":1628812800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1628812800,"objectID":"e5656835a9d5f0c69a44e56dc2b58101","permalink":"/resource/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/","section":"resource","summary":"Aquí podrán encontrar recursos y guías extras sobre uso de R, datos y otros tópicos relevantes.","tags":null,"title":"Recursos adicionales","type":"docs"},{"authors":null,"categories":null,"content":"Cada sesión de clases está dividida por una pestaña que puedes ver al costado izquierdo de tu pantalla. Dentro de cada página por sesión podrás encontrar\n (Slides) que es la presentación mostrada en clases. Encontrarás estos botones de modo de facilitar la descarga de la presentación y explorar las presentaciones   Ver las slides en una nueva ventana  Descargar las slides en PDF\nLa presentación también se puede ver directamente desde el sitio web del curso. Puedes presionar estas presentaciones y puedes navegar en ellas con ← y →. Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver una lista de comandos que te permitirán interactuar con ellos (por ejemplo, f sirve para ver en pantalla completa. También p modo presentador si quieres ver las notas. El lápiz en la esquina derecha te permite dejar tus propias notas).\n Material asociado a la clase, lo que incluye los ejemplos prácticos y contenido adicional que puede potenciar sus aprendizajes.  ","date":1647216000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1647216000,"objectID":"8899c927408853efa5f455eaa551e047","permalink":"/content/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/content/","section":"content","summary":"Cada sesión de clases está dividida por una pestaña que puedes ver al costado izquierdo de tu pantalla. Dentro de cada página por sesión podrás encontrar\n (Slides) que es la presentación mostrada en clases.","tags":null,"title":"Clases, prácticos y materiales","type":"docs"},{"authors":null,"categories":null,"content":"Evaluaciones Las evaluaciones del curso se componen de control de repaso (8% de la nota final), Controles sorpresa, (12% de la nota final), Avance de proyecto (25% de la nota final), Prueba (30% de la nota final) y el examen o proyecto final (25% de la nota final). En concreto, cada evaluación consiste en:\n1. Control de repaso (8% de la nota final): consiste en una evaluación de desarrollo para medir los conocimientos expuestos en las sesiones de clases (primera y segunda sesión). Esta evaluación es individual.\n2. Controles sorpresa (12% de la nota final): son en evaluaciones cortas y periódicas de 4 o 5 preguntas de alternativas. Estas evaluaciones serán individuales, se realizarán en clases de de forma presencial y tendrán retroalimentación. Es relevante considerar que si no se encuentran en clases el día del control sorpresa tendrán nota 1, a menos que presenten el justificativo correspondiente.\nRecuerden que los justificativos por inasistencia a clases y/o evaluaciones por enfermedad y/o otras razones deben hacerse a la coordinación de la carrera en el plazo establecido por el reglamento. Quienes no lo hagan serán evaluados con nota 1,0 o con inasistencia a clases, según corresponda.\nEjemplo de pregunta:\nSeñale la afirmación correcta respecto a la definición de una variable aleatoria discreta:\nI. Es una variable que sólo toma una cantidad finita o una cantidad infinita contable de valores II. Es una variable que puede tomar valores negativos III. Es una variable que puede tener resultados infinitos, pero sólo tienen valores enteros positivos. IV. Es una variable que puede tomar valores decimales\na. I y II b. Sólo III c. I, III y IV d. I y III\n3. Avance de proyecto (12% de la nota final):\n4. Prueba (30% de la nota final): Esta evaluación de carácter individual, la cual consiste en una prueba de desarrollo donde se evaluarán los contenidos vistos desde la tercera sesión (clase y práctico) hasta la última previa a la prueba (para mayor información revisar el calendario).\nLa modalidad de esta evaluación implicará que usted desarrolle habilidades de interpretación e inferencia, para lo cual no necesitará realizar cálculos.\n5. Proyecto de investigación o examen (25% de la nota final):\nCalendario de actividades El calendario de actividades se puede revisar con detención en la pestaña planificación. Un resumen breve de las tareas es\n   Evaluación Formato Fecha Ponderación Nota Final     Control de repaso Individual 21-23 marzo 8%   Controles sorpresa Individual Sorpresa 12% (en total)   Avance de proyecto Grupal 18-20 abril 25%   Prueba Individual 9-11 mayo 30%   Examen Individual 27 junio 25%    ","date":1636329600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1636329600,"objectID":"e18c399687bc0897ffd6503c7a1bbb8e","permalink":"/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"Evaluaciones Las evaluaciones del curso se componen de control de repaso (8% de la nota final), Controles sorpresa, (12% de la nota final), Avance de proyecto (25% de la nota final), Prueba (30% de la nota final) y el examen o proyecto final (25% de la nota final).","tags":null,"title":"Sobre las evaluaciones","type":"docs"},{"authors":null,"categories":null,"content":"Recuerden visitar esta sección una vez que han finalizado ver la clase y revisar los otros recursos. Estas contienen una descripción detallada de código de R y otras informaciones complementarias que serán indispensables para su aprendizaje como estudiantes.\nEn algunos casos existirán videos tutoriales y talleres complementarios donde codificamos en vivo o explicamos aspectos más desarrollados.\n","date":1629072000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629072000,"objectID":"e9b55dc35cd7c0402d035e510f00bf75","permalink":"/example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/","section":"example","summary":"Recuerden visitar esta sección una vez que han finalizado ver la clase y revisar los otros recursos. Estas contienen una descripción detallada de código de R y otras informaciones complementarias que serán indispensables para su aprendizaje como estudiantes.","tags":null,"title":"Prácticos (códigos de ejemplo)","type":"docs"},{"authors":null,"categories":null,"content":"Contenido 1. R R es un lenguaje de programación y software de código abierto, empleado en procesamiento, análisis y visualización de datos estadísticos, altamente extendibles.\nVentajas: Las principales ventajas son:\n  Es un lenguaje de programación destacado en lo que respecta al análisis estadístico\n  Es de acceso y código abierto\n  Permite graficar el análisis y los datos estadísticos de forma eficiente y llamativa\n  Se encuentra en constante actualización y desarrollo\n  Para descargar R, deben dirigirse al siguiente link, y seguir los pasos de instalación según su sistema operativo. Para el caso de Windows y macOS, se debe descargar el instalador de R, ejecutarlo, y proseguir con la instalación. Lo recomendado es instalarlo en español, y mantener las opciones de instalación que vienen por defecto.\nA continuación, se presentan imágenes del proceso de instalación de R en Windows\nSe aceptan las condiciones de uso\nSe define la carpeta de instalación. Pueden escoger donde deseen realizar la instalación clickeando en examinar; no obstante, se recomienda mantener la ruta predeterminada, en Archivos de programa\nSe recomienda seleccionar la Instalación de usuario\nAsimismo, también es recomendable no especificar las opciones de configuración\nSi se desea, se pueden crear accesos directos. Lo que sí es importante, es guardar el número de versión en el registro, y asociar archivos .RData con R (lo análogo a asociar archivos .sav con SPSS, o archivos .dta con STATA)\nParticularmente para el caso de macOS, es indispensable la instalación de XQuartz, pues este software nos permitirá visualizar, por ejemplo, los gráficos que elaboremos en R. Para ello, debemos dirigirnos al siguiente enlace, descargar la última versión disponible del software, y seguir el proceso de instalación. Tal como en el caso de R, lo recomendado es mantener la configuración predeterminada.\nPara el caso de Ubuntu, la versión 4.1 de R (que es la actual) viene incluida para gran parte de las versiones de Ubuntu. Para poder ejecutarlas, deben abrir el terminal y ejecutar los siguientes códigos (disponibles en el mirror de Ubuntu):\nSiguiendo los pasos anteriores, la instalación de R está finalizada.\nSin embargo, para laborar y aprender de manera más cómoda y eficiente, este curso trabajará principalmente con RStudio.\n2. RStudio Es un ambiente integrado de desarrollo para R (y Python, otro lenguaje de programación, que no se abordará en este curso), que permite visualizar el trabajo llevado a cabo, de manera más cómoda, sencilla y eficiente.\nPara instalarlo, deben dirigirse a la siguiente página web. Allí, en la sección All Installers, seleccionar el instalador correspondiente a su sistema operativo.\nEl proceso de instalación es el mismo que para R. Simplemente, se recomienda mantener todo en predeterminado.\n2.1. RStudio Cloud Sin embargo, también está la opción de trabajar en RStudio Cloud, en caso que sus computadores no presenten los requerimientos mínimimos para trabajar con RStudio de manera local. Para poder trabajar en RStudio Cloud, debemos crear un usuario. Sin embargo, primero crearemos un usuario en GitHub, para luego conectarse a RStudio Cloud desde allí.\nEntonces, debemos dirigirnos a la página de GitHub. Allí, debemos hacer click en Sign up.\nUna vez allí, debemos ingresar nuestro correo electrónico, y luego seguir los pasos que se encuentran en el correo de confirmación. Es recomendable que creen la cuenta con la dirección de correo electrónico que usen cotidianamente.\nPosteriormente, nos dirigimos a la página de RStudio Cloud, y hacemos click en Sign Up.\nVolvemos a hacer click en Sign Up\nLuego, hacemos click en Sign Up with GitHub\nSe nos redirigirá a la página de GitHub, donde debemos ingresar los datos del usuario de GitHub que creamos en pasos anteriores.\nUna vez realizado todo lo anterior, ingresaremos a RStudio Cloud. Allí, encontraremos nuestro espacio de trabajo (Your Workspace), donde podremos encontrar nuestros proyectos.\nHaciendo click en la pestaña Projects, situada en la pestaña superior, aparecerá el botón New Project. Al pulsarlo, podremos crear un nuevo proyecto.\nLuego, se generará el nuevo proyecto. Es importante que renombremos el nuevo proyecto, haciendo click en el recuadro que se encuentra en la sección superior (en este caso, el proyecto se nombró como Proyecto 1).\nPara cargar archivos (como bases de datos, o archivos .R), debemos hacer click en el botón Upload, situado en la sección Files situada en la esquina inferior derecha. Aparecerá una ventana emergente, y debemos hacer click en Seleccionar archivo, para explorar en nuestra computadora los archivos que necesitemos para trabajar.\nTambién podemos exportar el proyecto (con todos sus archivos asociados), haciendo click en el botón More (al lado del engranaje). Es importante que hagamos click en las casillas situadas a la izquierda de todos los archivos que deseemos descargar.\nEn la sección superior derecha, encontraremos un engranaje. En la pestaña Info encontraremos la información general del proyecto; además, podremos agregar una descripción general de este.\nA la derecha de Info, encontraremos la pestaña Access. Allí, podremos cambiar quiénes pueden ver el proyecto. Por defecto, solamente quien creó el proyecto puede verlo; sin embargo, podemos permitir que cualquiera (Everyone) pueda hacerlo.\nPara poder compartir nuestros proyectos, debemos hacer click en los tres puntos situados a la derecha del engranaje, y luego hacer click en Share Project Link. Aparecerá una ventana emergente, donde podemos agregar las direcciones de correo electrónico de todas las personas que queramos invitar al proyecto. También podemos agregar un mensaje a la invitación.\n3. Slack Este software será el principal medio de comunicación en el marco del curso. Allí, las y los estudiantes podrán plantear todas sus dudas, para que estas puedan ser respondidas de forma colectiva, tanto por parte del equipo docente, como de otras y otros estudiantes.\nPrimero, debemos descargar el instalador de Slack, dependiendo de nuestro sistema operativo:\n Windows macOS Linux  En la siguiente imagen, está el ejemplo de Windows (64 bits)\nUna vez descargado el archivo, debemos ejecutarlo, y seguir el proceso de instalación. Tal como en el resto de los software instalados, recomendamos mantener todas las opciones de instalación por defecto.\nLuego, debemos crear una cuenta de Slack, dirigiéndose a la siguiente página web. Se recomienda usar la dirección de correo que usen de forma cotidiana, a modo de estar al tanto de la actividad en el canal de Slack.\nPosteriormente, deben confirmar su correo electrónico y, por último, han de hacer click en el link Unirse a slack de curso, presente en el apartado Syllabus de la página web. Ello redireccionará a la aplicación, abriendo allí el espacio de trabajo del curso.\nUna vez realizado aquello, debemos permitir que la página web abra la aplicación de Slack, y se nos redirigirá al espacio de trabajo del curso.\nA la izquierda, encontraremos los diversos canales asignados para distintas actividades. Aquellos que tengan a la izquierda un #, son canales abiertos a todas y todos quienes integren el espacio de trabajo; mientras que aquellos que tengan un candado a su izquierda son canales privados. Haciendo click en añadir canales, podemos crear nuevos canales (lo cual pueden hacer cuando, en el futuro, utilicen Slack para sus trabajos personales).\nBajo los canales encontraremos la sección de mensajes directos, donde podremos enviar mensajes privados a cualquier persona que integre el espacio de trabajo. No olviden que pueden comunicarnos todas sus dudas, inquietudes y sugerencias respecto del curso.\nEn la sección superior derecha encontraremos nuestro usuario.\nSi hacemos click, se abrirá una pestaña emergente, donde podremos acceder a diversas configuraciones.\nEn Modificar tu perfil, podemos cambiar nuestro nombre, describir a qué nos dedicamos, definir nuestros pronombres, entre otros elementos. También, podemos seleccionar una foto de perfil, para que el resto de las personas que integren el espacio de trabajo puedan (re)conocernos.\nEn la sección de Preferencias, podremos establecer diferentes configuraciones referentes, por ejemplo, a las notificaciones, la barra lateral, o seleccionar distintos temas, para personalizar la apariencia de nuestro espacio de trabajo.\nUna vez realizado todo lo anterior ¡Ya estamos listas y listos para empezar a trabajar en el curso! 4. Video tutorial en Youtube Recuerden que el video de asociado a este práctico y muchos más podrán encontrarlos en el canal de youtube del curso\n\r\r","date":1628640000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628640000,"objectID":"c5e6c5f0d0baae071e282245bbba803c","permalink":"/resource/install/","publishdate":"2021-08-11T00:00:00Z","relpermalink":"/resource/install/","section":"resource","summary":"Contenido 1. R R es un lenguaje de programación y software de código abierto, empleado en procesamiento, análisis y visualización de datos estadísticos, altamente extendibles.\nVentajas: Las principales ventajas son:","tags":null,"title":"Instalación de R, RStudio y Slack","type":"docs"},{"authors":null,"categories":null,"content":"La presente entrada es una traducción del artículo Data types in R elaborado por Antoine Soetewey (2019).\nEste artículo presenta los diferentes tipos de datos (data types) en R. Para aprender sobre diferentes tipos de variables desde un punto de vista estadístico, diríjanse a la entrada Tipos de variables y ejemplos, disponible en la sección Recursos.\n¿Qué tipos de datos existen en R? Los 6 tipos de datos más comunes en R son:\n Numeric Integer Complex Character Factor Logical  Los sets de datos en R usualmente constituyen una combinación de estos 6 tipos diferentes de datos. Más adelante, exploraremos en mayor detalle cada tipo de dato, exceptuando el tipo \u0026ldquo;complex\u0026rdquo;, en tanto nos enfocaremos en los principales, y este tipo de dato rara vez es utilizado en la práctica.\nNumeric El tipo de dato más común en R es numeric. Una variable o una serie será almacenado como un dato numérico si sus valores son números, o si tales valores contienen decimales. Por ejemplo, las siguientes dos series son almacenadas como numeric de forma predeterminada:\n# Series numeric sin decimales num_data \u0026lt;- c(3, 7, 2) num_data ## [1] 3 7 2 class(num_data) ## [1] \u0026#34;numeric\u0026#34; # Series numeric con decimales num_data_dec \u0026lt;- c(3.4, 7.1, 2.9) num_data_dec ## [1] 3.4 7.1 2.9 class(num_data_dec) ## [1] \u0026#34;numeric\u0026#34; # También podemos chequear la clase con la función str()  str(num_data_dec) ## num [1:3] 3.4 7.1 2.9 En otras palabras, si se asigna uno o varios números a un objeto en R, este se almacenará como numeric de forma predeterminada (números con decimales), a menos que se especifique algo distinto.\nInteger Los datos de tipo Integer son, de hecho, un tipo particular de datos numericos. Los Integer (enteros) son datos numéricos sin decimales. Pueden ser utilizados si es que estás seguro/a de que los números almacenados nunca incorporarán decimales. Por ejemplo, digamos que estás interesada/o en el número de hijas/os en una muestra de 10 familias. Esta variable es discreta (para repasar estos contenidos, diríjanse a la entrada Tipos de variables y ejemplos), y nunca tendrá decimales. De estemodo, estos datos pueden almacenarse como integer gracias a la función as.integer():\nchildren ## [1] 1 3 2 2 4 4 1 1 1 4 children \u0026lt;- as.integer(children) class(children) ## [1] \u0026#34;integer\u0026#34; Hay que considerar que si la variable no tiene decimales, R automáticamente establecerá el tipo de datos como integer en lugar de numeric.\nCharacter Los datos de tipo character son utilizados al almacenar texto, conocido como strings en R. La forma más simple de almacenar datos en formato character es usando \u0026quot;\u0026quot; alrededor del texto:\nchar \u0026lt;- \u0026#34;some text\u0026#34; char ## [1] \u0026#34;some text\u0026#34; class(char) ## [1] \u0026#34;character\u0026#34; Si deseas forzar a que cualquier tipo de dato sea almacenado como character, puedes hacerlo con la función as.character():\nchar2 \u0026lt;- as.character(children) char2 ## [1] \u0026#34;1\u0026#34; \u0026#34;3\u0026#34; \u0026#34;2\u0026#34; \u0026#34;2\u0026#34; \u0026#34;4\u0026#34; \u0026#34;4\u0026#34; \u0026#34;1\u0026#34; \u0026#34;1\u0026#34; \u0026#34;1\u0026#34; \u0026#34;4\u0026#34; class(char2) ## [1] \u0026#34;character\u0026#34; Hay que notar que cualquier elemento entre \u0026quot;\u0026quot; será considerado como character, sin importar si luce como character o no. Por ejemplo:\nchars \u0026lt;- c(\u0026#34;7.42\u0026#34;) chars ## [1] \u0026#34;7.42\u0026#34; class(chars) ## [1] \u0026#34;character\u0026#34; Además, en la medida que exista al menos un valor character dentro de una variable o vector, este será considerado como character:\nchar_num \u0026lt;- c(\u0026#34;text\u0026#34;, 1, 3.72, 4) char_num ## [1] \u0026#34;text\u0026#34; \u0026#34;1\u0026#34; \u0026#34;3.72\u0026#34; \u0026#34;4\u0026#34; class(char_num) ## [1] \u0026#34;character\u0026#34; Por último, pese a que los espacios no importen en datos numéricos, estos sí son relevantes en datos character:\nnum_space \u0026lt;- c(1) num_nospace \u0026lt;- c(1) # ¿Es num_space igual a num_nospace? num_space == num_nospace ## [1] TRUE char_space \u0026lt;- \u0026#34;text \u0026#34; char_nospace \u0026lt;- \u0026#34;text\u0026#34; # ¿Es char_space igual a char_nospace? char_space == char_nospace ## [1] FALSE Como pueden ver en los resultados anteriores, un espacio en datos de tipo character (por ejemplo, entre \u0026quot;\u0026quot;) lo convierte en un string diferente para R\nFactor Las variables Factor son un caso especial de variables character, en el sentido de que también contienen texto.Sin embargo, las variables factor son utilizadas cuando existe un número limitado de strings character únicas. Usualmente representan una variable categórica. Por ejemplo, el sexo usualmente toma sólo dos valores, \u0026ldquo;masculino\u0026rdquo; y \u0026ldquo;femenino\u0026rdquo; (y será considerado una variable factor), mientras que el nombre generalmente presentará montones de posibilidades (de modo que será considerado una variable character). Para crear un factor, empleamos la función factor() :\ngender \u0026lt;- factor(c(\u0026#34;female\u0026#34;, \u0026#34;female\u0026#34;, \u0026#34;male\u0026#34;, \u0026#34;female\u0026#34;, \u0026#34;male\u0026#34;)) gender ## [1] female female male female male ## Levels: female male Para conocer los diferentes niveles (levels) de una variable factor, ocupamos la función levels():\nlevels(gender) ## [1] \u0026#34;female\u0026#34; \u0026#34;male\u0026#34; De manera predeterminada, los niveles son ordenados alfabéticamente. Estos pueden ser reordenados con el argumento levels de la función factor():\ngender \u0026lt;- factor(gender, levels = c(\u0026#34;male\u0026#34;, \u0026#34;female\u0026#34;)) levels(gender) ## [1] \u0026#34;male\u0026#34; \u0026#34;female\u0026#34; Las strings character pueden convertirse en factores con la función as.factor():\ntext \u0026lt;- c(\u0026#34;test1\u0026#34;, \u0026#34;test2\u0026#34;, \u0026#34;test1\u0026#34;, \u0026#34;test1\u0026#34;) # Crear un vector character class(text) # Conocer la clase ## [1] \u0026#34;character\u0026#34; text_factor \u0026lt;- as.factor(text) # Transformar a factor class(text_factor) # Re-conocer la clase ## [1] \u0026#34;factor\u0026#34; Las strings character han sido transformadas en factor, como muestra su clase de tipo factor.\nLogical Una variable logical (lógica) es una variable que incluye sólo dos valores: TRUE or FALSE:\nvalue1 \u0026lt;- 7 value2 \u0026lt;- 9 # ¿Es value1 mayor a value2? greater \u0026lt;- value1 \u0026gt; value2 greater ## [1] FALSE class(greater) ## [1] \u0026#34;logical\u0026#34; # ¿Es value1 menor o igual a value2? less \u0026lt;- value1 \u0026lt;= value2 less ## [1] TRUE class(less) ## [1] \u0026#34;logical\u0026#34; También es posible transformar datos logical en datos numeric. Luego de transformar de logical a numeric con la función as.numeric(), los valores FALSE equivaldrán a 0, y los valores TRUE equivaldrán a 1:\ngreater_num \u0026lt;- as.numeric(greater) sum(greater) ## [1] 0 less_num \u0026lt;- as.numeric(less) sum(less) ## [1] 1 Por su parte, datos numeric pueden convertirse en datos logical, con FALSE para todos los valores iguales a 0 y TRUE para todos los otros valores.\nx \u0026lt;- 0 as.logical(x) ## [1] FALSE y \u0026lt;- 5 as.logical(y) ## [1] TRUE ¡Gracias por leer! Esperamos que este artículo les ayude a entender los tipos básicos de datos en R y sus particularidades. Si desean aprender más sobre diferentes tipos de variables desde un puntos de vista estadístico, lean Tipos de variables y ejemplos.\nComo siempre, si tienen alguna pregunta o sugerencia relacionada con el tópico cubierto en este artículo, por favor coméntenlo por los canales de comunicación del curso, para que otras/os lectoras/es puedan beneficiarse de la discusión.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6de79fc9aa9ca506561adf3132a1c948","permalink":"/resource/r-datatypes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/r-datatypes/","section":"resource","summary":"La presente entrada es una traducción del artículo Data types in R elaborado por Antoine Soetewey (2019).\nEste artículo presenta los diferentes tipos de datos (data types) en R. Para aprender sobre diferentes tipos de variables desde un punto de vista estadístico, diríjanse a la entrada Tipos de variables y ejemplos, disponible en la sección Recursos.","tags":null,"title":"Tipos de datos en R","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\rLa presente entrada es una traducción del artículo Variable types and examples elaborado por Antoine Soetewey (2019).\nEste artículo presenta los diferentes tipos de variables desde un punto de vista estadístico. Para aprender sobre los diferentes tipos de datos en R, revisen Tipos de datos en R.\nImágen panorámica En estadística, las variables son clasificadas en 4 tipos diferentes:\n\r{\"x\":{\"diagram\":\"digraph {\\n\\n\\n\\n\\n \\\"1\\\" [label = \\\"Variable\\\", style = \\\"filled,rounded\\\", shape = \\\"box\\\", fontname = \\\"helvetica\\\", tooltip = \\\"- name: Variable\\\", fillcolor = \\\"LightGray\\\", fontcolor = \\\"#000000\\\"] \\n \\\"2\\\" [label = \\\"Cualitativa\\\", style = \\\"filled,rounded\\\", shape = \\\"box\\\", fontname = \\\"helvetica\\\", tooltip = \\\"- name: Cualitativa\\\", fillcolor = \\\"LightGray\\\", fontcolor = \\\"#000000\\\"] \\n \\\"3\\\" [label = \\\"Nominal\\\", style = \\\"filled,rounded\\\", shape = \\\"box\\\", fontname = \\\"helvetica\\\", tooltip = \\\"- name: Nominal\\\", fillcolor = \\\"LightGray\\\", fontcolor = \\\"#000000\\\"] \\n \\\"4\\\" [label = \\\"Ordinal\\\", style = \\\"filled,rounded\\\", shape = \\\"box\\\", fontname = \\\"helvetica\\\", tooltip = \\\"- name: Ordinal\\\", fillcolor = \\\"LightGray\\\", fontcolor = \\\"#000000\\\"] \\n \\\"5\\\" [label = \\\"Cuantitativa\\\", style = \\\"filled,rounded\\\", shape = \\\"box\\\", fontname = \\\"helvetica\\\", tooltip = \\\"- name: Cuantitativa\\\", fillcolor = \\\"LightGray\\\", fontcolor = \\\"#000000\\\"] \\n \\\"6\\\" [label = \\\"Discreta\\\", style = \\\"filled,rounded\\\", shape = \\\"box\\\", fontname = \\\"helvetica\\\", tooltip = \\\"- name: Discreta\\\", fillcolor = \\\"LightGray\\\", fontcolor = \\\"#000000\\\"] \\n \\\"7\\\" [label = \\\"Continua\\\", style = \\\"filled,rounded\\\", shape = \\\"box\\\", fontname = \\\"helvetica\\\", tooltip = \\\"- name: Continua\\\", fillcolor = \\\"LightGray\\\", fontcolor = \\\"#000000\\\"] \\n \\\"1\\\"-\\\"2\\\" \\n \\\"1\\\"-\\\"5\\\" \\n \\\"2\\\"-\\\"3\\\" \\n \\\"2\\\"-\\\"4\\\" \\n \\\"5\\\"-\\\"6\\\" \\n \\\"5\\\"-\\\"7\\\" \\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\rCuantitativas Una variable cuantitativa es aquella que refleja una noción de magnitud, es decir, cuyos valores posibles son números. Así, una variable cuantitativa representa una medida y es numérica.\nLas variables cuantitativas se dividen en dos tipos: discretas y continuas. La diferencia entre ambas se explicará en las siguientes dos secciones.\nDiscretas Variables cuantitativas discretas son aquellas cuyos valores posibles pueden ser contabilizados y tienen un número finito de posibilidades. Los valores tienden a ser (aunque no siempre) enteros. Aquí hay algunos ejemplos de variables discretas:\n Número de hijas/os por familia Número de estudiantes en una clase Número de ciudadanos/as en un país  Pese a que pueda tomar un largo tiempo el contar a las y los ciudadanas/os de un gran país, esto es técnicamente factible. Más aún, para todos los ejemplos, el número de posibilidades es finito. Cualquiera sea el número de hijas/os en una familia, este nunca será 3.58 o 7.912, de modo que el número de posibilidades es un número finito y, de esa manera, contabilizable.\nContinuas Por otra parte, las variables cuantitativas continuas son aquellas cuyos valores no son contabilizables, teniendo un número infinito de posibilidades. Por ejemplo:\n Edad Peso Altura  Para simplificar, usualmente nos referimos a años, kilogramos (libras) y centímetros (o pies y pulgadas), para edad, peso y altura respectivamente. Sin embargo, una persona de 28 años puede realmenter tener 28 años, 7 meses, 16 días, 3 horas, 4 minutos, 5 segundos, 31 milisegundos, 9 nanosegundos de edad.\nPara todas las mediciones, usualmente nos detenemos en un nivel estándar de granularidad, pero nada (excepto nuestras herramientas medición) nos impide ir más allá, llevándonos a un número infinito de valores potenciales. El hecho de que los valores puedan tomar un número infinito de posibilidades lo hace incontabilizable.\nCualitativas En oposición a las variables cuantitativas, las variables cualitativas (también referidas como variables categóricas o factores en R) son variables que no son numéricas y cuyos valores encajan en categorías.\nEn otras palabras, una variable cualitativa es aquella que toma como valores modalidades, categorías o incluso niveles, en contraste con variables cuantitativas que miden una cantidad en cada individuo.\nLas variables cualitativas se dividen en dos tipos: nominales y ordinales.\nNominales Una variable cualitativa nominal es aquella en que ordenar no es posible ni está implicado en los niveles (levels). Por ejemplo, la variable género es nominal porque no hay orden en los niveles femenino/masculino. El color de ojos es otro ejemplo de una variable nominal, pues no hay orden entre ojos azules, cafés o verdes.\nUna variable nominal puede contemplar dos niveles (por ejemplo ¿eres fumador/a? Sí/No, o ¿cuál es tu género? Femenino/Masculina), o un extenso número de niveles (¿cuál es tu licenciatura universitaria? donde cada tipo de licenciatura (sociología, psicología, física, entre otras) constituye un nivel).\nOrdinales Por otra parte, una variable cualitativa ordinal implica un orden asignado a los niveles. Por ejemplo, si la gravedad de accidentes de tránsito es medida en una escala como leve, moderada y fatal, esta variable es cualitativa ordinal en tanto hay un claro orden entre los niveles.\nOtro buen ejemplo es la salud, cuyos valores posible son pobre, razonable, buena o excelente. De nuevo, hay un claro orden en estas variables, de modo que la salud en este caso constituye una variable ordinal cualitativa.\nTransformación de variables Hay dos formas principales de transformación de variables:\n De variable continua a variable discreta De variable cuantitativa a variable cualitativa  De continua a discreta Digamos que estamos interesados/as en edades de bebés. Los datos coleccionados es la edad de los bebés, siendo una variable cuantitativa continua. Sin embargo, trabajaremos sólo con el número de semanas desde el nacimiento, transformando así a la edad en una variable discreta. La variable edad sigue siendo cuantitativa, pero la variable que estamos trabajando (en este caso, el número de semanas desde el nacimiento) es una variable cuantitativa discreta.\nDe cuantitativa a cualitativa Digamos que estamos interesadas/os en el Índice de Masa Corporal (IMC). Para esto, las/los investigadoras/os coleccionaron datos sobre altura y peso de individuos, calculando su IMC. El IMC es una variable cuantitativa continua, pero las/los investigadoras/os desean transformarla en una variable cualitativa, categorizando a las personas bajo cierto límite en bajo peso, sobre cierto límite en sobre peso, y al resto como peso normal. El IMC inicial es una variable cuantitativa continua, pero la categorización del IMC la transforma en una variable cualitativa (ordinal), cuyos niveles son bajo peso \u0026lt; normal \u0026lt; sobre peso.\nLo mismo sucede cuando la edad es transformada en una variable cualitativa ordinal con niveles como menores de edad, adultos y adultos mayores. También suele ser el caso (especialmente en encuestas) cuando la variable salario (cuantitativa continua) es transformada n una variable cualitativa ordinal que contempla diferentes rangos de salarios (por ejemplo, $0 - $100.000, $100.001 - $200.000, etc.)\nNotas adicionales Diferentes tipos de variables para diferentes tipos de análisis estadísticos La razón por la cual usualmente clasificamos variables en diferentes tipos es que no todos los análisis estadísticos pueden realizar para todos los tipos de variables. Por ejemplo, es imposible calcular una media de la variable “color de cabello,” al no poder sumar cabello castaño y cabello rubio.\nPor otra parte, hallar la moda de una variable continua no hace mucho sentido, pues la mayor parte del tiempo no habrá dos valores exactamente iguales, de modo que no existirá moda. Por ejemplo, intentar encontrar la moda de la altura de las y los estudiantes de un curso. Si se tiene suerte, un par de estudiantes medirán lo mismo. No obstante, la mayor parte del tiempo, cada estudiante tendrá un tamaño diferente (especialmente si las alturas han sido medidas en milímetros), de modo que no habrá moda. Para ver que tipo de análisis es posible en cada variable, pueden hacer una revisión más detallada en los artículos “Descriptive statistics by hand” y “Descriptive statistics in R.”\nDe forma semejante, algunos tests estadísticos sólo pueden realizarse en cierto tipo de variables, Por ejemplo, una correlación sólo puede calcularse para variables cuantitativas, mientras que un test Chi-cuadrado de independencia se realiza con variables cualitativas, y un test T-Student o ANOVA requiere una combinación de variables cuantitativas y cualitativas.\nCodificación engañosa de datos Por último, pero no menos importante, es usual que en algunos set de datos se empleen números para variables cualitativas. Por ejemplo, un/a investigador/a puede asignar el número “1” a mujer y el número “2” a hombre (o “0” a la respuesta “No” y “1” a la respuesta “Sí). Pese a la clasificación numérica, la variable género sigue siendo una variable cualitativa, y no una discreta, como pareciera. La clasficación numérica sólo es utilizada para facilitar la recolección y tratamiento de datos. Es, de hecho, más sencillo escribir”1\u0026quot; o “2” en lugar de “mujer” y “hombre,” disminuyendo la posibilidad de errores de codificación.\nSi te enfrentas a este tipo de configuración, no olvides transformar la variable en el tipo correcto antes de realizar análisis estadísticos. Usualmente, un análisis descriptivo básico (y el conocimiento sobre las variable que han sido medidas) previo a los análisis estadísticos principales basta para identificar si el tipo de las variables es correcto.\nGracias por leer. Esperamos que este artículo les ayude a comprender los diferentes tipos de variables. Si desean aprender más sobre los distintos tipos de datos en R, lean la entrada Tipos de datos en R.\nComo siempre, si tienen alguna pregunta o sugerencia relacionada con el tópico cubierto en este artículo, por favor coméntenlo por los canales de comunicación del curso, para que otras/os lectoras/es puedan beneficiarse de la discusión.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9fb708a6edc989f6f8540c248aa445af","permalink":"/resource/r-datatypes-example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/r-datatypes-example/","section":"resource","summary":"La presente entrada es una traducción del artículo Variable types and examples elaborado por Antoine Soetewey (2019).\nEste artículo presenta los diferentes tipos de variables desde un punto de vista estadístico.","tags":null,"title":"Tipos de variables y ejemplos","type":"docs"},{"authors":null,"categories":null,"content":"Debido a que los Rproject de RStudio normalmente consisten en múltiples archivos (scripts de R, conjuntos de datos, salida gráfica, etc.) la forma más fácil de distribuirlos para los ejemplos, tareas y proyectos es combinar todos los diferentes archivos en una sola colección comprimida llamada archivo comprimido.\nCuando descomprimes un archivo comprimido, tu sistema operativo extrae todos los archivos que contiene en una nueva carpeta de tu ordenador.\nDescomprimir archivos en macOS es trivial, pero descomprimir archivos en Windows puede ser molesto, si no sigues los siguientes pasos. Aquí tienes una guía útil para descomprimir archivos tanto en macOS como en Windows.\nDescomprimir archivos en macOS Haz doble clic en el archivo .zip descargado. macOS creará automáticamente una nueva carpeta con el mismo nombre que el archivo .zip, y todo el contenido del archivo estará dentro. Haz doble clic en el archivo de proyecto de RStudio (.Rproj) para empezar.\nknitr::include_graphics(\u0026#34;/img/unzipping/unzip-mac.png\u0026#34;, error = FALSE) Descomprimir archivos en Windows tl;dr: Haz clic con el botón derecho del ratón en el archivo .zip, selecciona \u0026ldquo;Extraer todo\u0026hellip;\u0026rdquo;, y trabaja con la carpeta descomprimida resultante.\nA diferencia de macOS, Windows no descomprime automáticamente las cosas por ti. Si haces doble clic en el archivo .zip, Windows te mostrará lo que hay dentro, pero lo hará sin extraer nada. ¡Esto puede ser increíblemente confuso! Esto es lo que parece: las únicas pistas de que esta carpeta es realmente un archivo .zip son que hay una pestaña de \u0026ldquo;Herramientas de carpetas comprimidas\u0026rdquo; en la parte superior, y hay una columna de \u0026ldquo;Ratio\u0026rdquo; que muestra cuánto está comprimido cada archivo.\nEs muy tentador intentar abrir archivos desde esta vista. Sin embargo, si lo hace, las cosas se romperán y no podrá trabajar correctamente con ninguno de los archivos de la carpeta comprimida. Si abre el archivo del Proyecto R, por ejemplo, RStudio apuntará a un extraño directorio de trabajo enterrado en alguna carpeta temporal:\nLo más probable es que no puedas abrir ningún archivo de datos ni guardar nada, lo cual será frustrante.\nEn lugar de eso, tienes que hacer clic con el botón derecho del ratón en el archivo .zip y seleccionar \u0026ldquo;Extraer todo\u0026hellip;\u0026quot;:\nA continuación, elige dónde quieres descomprimir todos los archivos y haz clic en \u0026ldquo;Extraer\u0026rdquo;\nFinalmente deberías tener una carpeta real con todo el contenido del archivo comprimido. Abre el archivo del proyecto R y RStudio apuntará al directorio de trabajo correcto y todo funcionará.\n","date":1628812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628812800,"objectID":"f1b04d7939933ed26af8d5a9fe95387f","permalink":"/resource/unzipping/","publishdate":"2021-08-13T00:00:00Z","relpermalink":"/resource/unzipping/","section":"resource","summary":"Debido a que los Rproject de RStudio normalmente consisten en múltiples archivos (scripts de R, conjuntos de datos, salida gráfica, etc.) la forma más fácil de distribuirlos para los ejemplos, tareas y proyectos es combinar todos los diferentes archivos en una sola colección comprimida llamada archivo comprimido.","tags":null,"title":"Descomprimir archivos","type":"docs"},{"authors":null,"categories":null,"content":"Objetivo del taller Este taller tiene por objetivo conocer el software Zotero para facilitar la incorporación de citas y referencias en archivos RMarkdown.. Para ello veremos las razones de por qué usar este software y por qué usarlo en conjunto a RMarkdown, finalizando con el proceso de instalación del programa y sus componentes.\nEl proceso de referenciar es uno de los más relevantes dentro de la vida académica, sin embargo este puede ser difícil y sujeto a muchos errores. Por ello, el sistematizar y facilitar este proceso no sólo puede ahorrar tiempo en trabajos, investigaciones, entre otros. Sino que potenciará el proceso volviéndolo más expedito.\nPara ello hay distintas formas de faciltarlo, uno de ellos es Zotero, pero ¿por qué utilizar Zotero y no otro gestor?\n1. Qué es Zotero Zotero (www.zotero.org) es un software libre que almacena y administra las referencias bibliográficas, este no sólo es útil como aplicación sino que también tiene extensiones para navegadores como Chrome, Mozilla Firefox, Safari y Opera. Estos sincronizan la aplicación mientras se navega guardando los recursos a utilizar.\nSus ventajas son:\n La automatización del almacenamiento de las referencias bibliográficas La colaboración y fácil sincronización de referencias Es un software de acceso abierto y gratis  1.1 Zotero + RMarkdown RMarkdown es un archivo que logra integrar código R (mediante chunks) y texto en Markdown (lenguaje que brinda un formato de escritura de texto simple).\nSus ventajas son\n  La incorporación de reportes estadísticos, tablas y análisis directamente en un archivo con escritura en texto plano\n  Facilita la reproducibilidad y la colaboración académica\n  Facilita la apertura y acceso de información\n  Entonces, RMarkdown más Zotero, significan no sólo un aumento de lo reproducible y la colaboración, sino que también una automatización del proceso de referenciar, volviéndolo más simple y sujeto a menos errores.\nEntonces, al almacenar las referencias dentro de Zotero, queda a disposición un conjunto de archivos o librería que puede exportarse, compartirse o sincronizarse directamente al documento a utilizar o presentar.\nPara que este proceso de almacenamiento y exportación de referencias pueda utilizarse, el software debe transformarlo a un tipo de archivo y uno de ellos es BibTeX.\n1.1 BibTeX BibteX es un tipo archivos con un formato .bib, los cuales funcionan en conjunto a Latex (es un sistema de composición de textos) para el almacenamiento de referencias bibliográficas.\nUna entrada BibTeX inicia con una palabra después de @ y una serie de etiquetas que definen las características de la entrada específica. Entre esas etiquetas pueden estar elementos como: autor, título, año, entre otros. Algunas etiquetas son obligatorias para ciertos tipos de entradas de BibTeX, otras son opcionales.\nEtiquetas En BibTeX las etiquetas son especificadas por su nombre seguido de un signo igual y su contenido, se debe considerar que las etiquetas no distinguen entre mayúsculas y minúsculas y que el contenido debe ir entre comillas, por ejemplo:\n@book`{\u0026quot;marx_1867\u0026quot;,\rtitle = {El Capital}, volume = {I}, author = {Marx, Karl}, year = {1867}, pages = {255–276}, file = {ruta}}`\r Dentro del ejemplo es relevante la primera línea, ya que este nombre es el que nos permitirá traerla al texto. Si bien es útil conocer este formato de referencias, es un poco complejo al principio. Lo bueno es que Zotero administra estas referencias y las convierte automáticamente al formato .bib\n1. 2 Better BibTeX (BBT) Better BibTeX cumple las funciones de BibTeX pero la ventaja es que se puede sincronizar para una actualización automática desde los software que gestionan las referencias. Para esto presentaremos la aplicación Better(bib)tex (BBT), que funciona dentro de Zotero. Las ventajas de esto es que ambos son de código abierto\nBBT genera una colección con formtao .bib en base a librerías construidas en Zotero, estas se configuran una vez y luego se mantiene sincronizada.\n¡Pero antes de ver como funcionan debemos asegurarnos de tener todo instalado!\n2. Instalación de Zotero Para instalar Zotero deben ir al link y apretar el botón Download\n Luego, deben abrir el archivo descargado   Una vez abran el archivo descargado, les aparecerá esta ventana donde deben apretar el botón Continuar o Next \u0026gt;   Deben seleccionar la opción Standard   Luego establecer la ubicación del programa deben apretar Upgrade   finalmente deben apretar en Finish   Al abrirlo les aparecerá la interfaz del software  Ahora ya tenemos instalado Zotero, sin embargo no es suficiente, también debemos instalar la extensión BBT para facilitar la sincronización de los datos con el informe que queramos crear.\n2.1 Zotero y BBT Para descargar BBT deben ir al link y en la sección More ir a Download\n Luego deben hacer click en el archivo con extensión .xpi, pero no deben abrirlo  Dentro de BBT hay varias versiones las cuales pueden irse actualizando, estas se encuentran en el botón compare\n\rPara incorporarlo deben ir a Zotero en Tools y Add-ons / En español es en Herramientas y complementos\n Les aparecerá una ventana emergente, deben ir a la esquina superior derecha, al icono de tuerca   Luego deben ir a Install Add-on from file, encontrar el archivo descargado (.xpi) de BBT   Una vez se encuentra se debe apretar el boton Install Now   Luego se debe reiniciar con el botón Restart Now  Ahora ya tenemos el software que gestiona las referencias y la extensión para mantener sincronizadas las referencias. Sin embargo previo a ver como funcionan dejaremos instaladas las extensiones\n2.2 Instalación de extensión Para incluir la extensión de navegador de Zotero hay varias opciones según el navegador que utilicen\n  Chrome\n  Firefox\n  Microsoft Edge\n  class: title title-8\n2.3 Creación de cuenta Para crearse una cuenta deben ir al siguiente link\nNo es necesario crearse una cuenta para usar Zotero, pero si es recomendable\n3. Puente entre Rstudio y Zotero Para conectar Zotero con Rstudio y facilitar la incorporación de referencias en RMarkdown, necesitamos un conector y para ello tenemos dos opciones: el paquete citr y el editor visual.\nOpción 1:\ncitr este es un paquete que nos facilitara la conexión entre Zotero y Rstudio\nSe puede instalar de varias formas\n  con install.packages\n  Mediante devtools::install_github(\u0026quot;crsh/citr\u0026quot;)\n  O descargando una antigua versión del CRAN\n  Se reinicia R y luego podrán verlo en la sección Addins\n Editor visual  Lo más probable es que citr genere problemas en su instalación, debido a que fue removido del CRAN, sin embargo la opción más factible es usar el editor visual o utilizar una versión antigua del paquete\r\r3. Flujo de trabajo Una vez teniendo instalado el software y todo lo necesario para empezar estableceremos el flujo de trabajo. Se debe considerar que este proceso es cíclico.\nEs importante entender el flujo de trabajo de Zotero + RMarkdown, porque resume todo lo visto, mientras más nos acostumbremos a este flujo de trabajo más simple se hará el proceso de referenciar a través de Zotero.\n4. Video tutorial en Youtube Recuerden que el video de asociado a este tutorial y muchos más podrán encontrarlos en el canal de youtube del curso\n","date":1628812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628812800,"objectID":"8369f88727ff6da672a08174806fd9d8","permalink":"/resource/install-zotero/","publishdate":"2021-08-13T00:00:00Z","relpermalink":"/resource/install-zotero/","section":"resource","summary":"Objetivo del taller Este taller tiene por objetivo conocer el software Zotero para facilitar la incorporación de citas y referencias en archivos RMarkdown.. Para ello veremos las razones de por qué usar este software y por qué usarlo en conjunto a RMarkdown, finalizando con el proceso de instalación del programa y sus componentes.","tags":null,"title":"Instalación Zotero","type":"docs"},{"authors":null,"categories":null,"content":"0. Objetivo del taller Este taller tiene por objetivo conocer el software Zotero para facilitar la incorporación de citas y referencias en archivos RMarkdown.\n1. Recursos del práctico Para este práctico utilizaremos una colección hecha para el taller de Zotero, que nos facilitará la realización de los ejercicios.\n  material-taller.zip  2. Flujo de trabajo Como se vio en el tutorial de instalación, una vez teniendo instalado el software y sus complementos, es necesario tener en cuenta el flujo de trabajo.\nEs importante entender el flujo de trabajo de Zotero + RMarkdown, ya que resume todo lo visto, mientras más nos acostumbremos a este flujo de trabajo más simple se hará el proceso de referenciar a través de Zotero.\n3 Almacenar El primer paso es almacenar los datos que se han leído y recopilado. El almacenamiento inmediato de estos datos será de utilidad para el reporte.\n Una de las ventajas de realizar el proceso de almacenar de esta forma es que se lleva un registro de lo leído, evitando la pérdida de información.  Para esto Zotero, no sólo tiene la solución, sino que también existen diversas formas de hacerlo. Las cuales veremos a continuación\n3.1 Almacenar referencias de forma manual Una de las formas más comunes (aunque no más fácil) es almacenar las referencias de forma manual.\nSe debe considerar que si bien esto facilita el proceso, hay formas más expeditas de almacenamiento.\nPara esto debemos seguir los siguientes pasos:\n  Paso 1: Abrir Zotero\n  Paso 2: Dirigirse al botón verde con un signo “+” y seleccionar el tipo de archivo a almacenar (artículo, libro, vídeo, etc.)\n   Paso 3: Finalmente, deben llenar las secciones que aparecen en el lado derecho.  3.2 Almacenar a través de la extensión de navegador Almacenar a través de la extensión del navegador web, es una de las opciones más simples de almacenamiento, solo debes seguir los siguientes pasos:\n  Paso 1: Dirigirte al artículo, noticia, vídeo que quieras almacenar\n  Paso 2: Apretar el botón de la extensión\n  Paso 3: Seleccionar la carpeta donde se almacenará\n  ¡Listo!\n3.3 Almacenar a través del identificador Otra de las opciones que ofrece Zotero es el almacenamiento a través del identificador (DOI, ISBN, PMID o arXiv ID), los pasos a seguir son los siguientes:\n  Paso 1: Tener el identificador copiado (para este ejemplo utilizaremos este 978-84-459-0745-0, ustedes también pueden probar con ese ISBN)\n  Paso 2: Abrir Zotero Paso 3: Ir a al dibujo de una “varita”\n  Paso 3: Ingresar el identificador\n  ¡Listo!\n3.4 Almacenar por archivo Una última forma de almacenar referencias es a través de archivos.\n  Paso 1: Tener un archivo para almacenar\n  Paso 2: Moverlo a Zotero\n  ¡Listo!\n4. Exportar y formatos Una vez almacenados, se viene la siguiente etapa de nuestro flujo: la de exportación y hay dos opciones para exportar los archivos\nOpción 1: Exportar archivos con formato .bib\n  Paso 1: Botón derecho a la carpeta a exportar\n  Paso 2: Apretar en “Exportar colección”\n  Paso 3: Seleccionar formato BibTeX\n  Paso 4: Seleccionar carpeta donde alojaremos el archivo (input) y guardar\n  Opción 2: Exportar archivos con BetterBibTeX\nCon esta opción Rstudio automáticamente reconoce la biblioteca, los pasos son los siguientes:\n  Paso 1: Botón derecho a la carpeta a exportar\n  Paso 2: Apretar en “Exportar colección”\n  Paso 3: Seleccionar formato BibTeX y opción keep updates\n  Paso 4: Seleccionar carpeta donde alojaremos el archivo (input) y guardar\n  4.1 Carpeta 4.2 YAML: bibliography y csl Para incluir las citas en un documento RMarkdown se debe tener en consideración dos aspectos, el archivo que almacena las citas y el formato en el que queremos referenciar. Por eso en el YAML se deben especificar estos dos aspectos\n4.2.1 Especificar carpeta de donde se extraen las referencias Para este aspecto en el encabezado (YAML) debe especificarse con bibliography la ruta hacia el archivo, el nombre del archivo y su extensión\nNuestro YAML quedaría así\n---\rtitle: \u0026quot;taller zotero\u0026quot;\rauthor: \u0026quot;Dafne Jaime Vargas\u0026quot;\rdate: \u0026quot;30-09-2021\u0026quot;\routput: html_document\rbibliography: input/taller.bib\rlink-citations: yes\r---\r 4.2.2 formato de citación Tan relevante como el reverenciar, lo es el formato en el que se referencia, para ello debemos ir al siguiente link y descargar el formato con el que se quiere citar\n¿Cómo se descarga?, para este proceso hay más de una opción:\nOpción 1: Descargar el archivo\n Paso 1: Poner en el buscador el estilo de citación y hacerle click    Paso 2: Una vez les salga el mensaje de “Zotero Connector,” apretar en cancel\n  Les descargará un archivo con extensión .csl\n  Finalmente, en su archivo RMarkdown, en la sección del YAML deben dejar la ruta hacia el archivo, el nombre del archivo y su formato\n  --- title: \u0026#34;taller zotero\u0026#34; author: \u0026#34;Dafne Jaime Vargas\u0026#34; date: \u0026#34;30-09-2021\u0026#34; output: html_document bibliography: input/taller.bib csl: input/cambridge-university-press-numeric.csl --- ¡Listo!\nOpción 2:\n  Paso 1: Poner en el buscador el estilo de citación y hacerle click\n  Paso 2: Una vez les salga el mensaje de “Zotero Connector,” apretar en OK\n  Luego ir a preferencias de Zotero\n    En la sección “Exportar” deben elegir formato predeterminado\n  Actualizar los datos en caso de ser BetterBibTeX o volver a exportar en caso de archivo BibTeX\n  En esta ocasión nuestro en nuestro YAML no habría que especificar un estilo de citación\n  ¡Listo!\n5. Citar en RMarkdown   Ahora ya podemos citar, y es muy simple sólo debemos abrir nuestro RMarkdown\n  Hacer click en Addins \u0026gt; insert citations o citr:::insert_citation()\n  Luego hacer knit\n  ¡Listo!\n{{\u0026lt; div “note” \u0026gt;}}\nBONUS En Zotero no sólo se puede almacenar los datos de la referencia y sus archivos, sino que se pueden añadir notas, apuntes, etiquetas, entre otros\n{{\u0026lt; /div \u0026gt;}}\nYa puedes volver a leer, Zotero hará todo lo demás por ti. Solo recuerda los pasos a seguir\n Luego, deben abrir el archivo descargado   Una vez abran el archivo descargado, les aparecerá esta ventana donde deben apretar el botón Continuar o Next \u0026gt;   Deben seleccionar la opción Standard   Luego establecer la ubicación del programa deben apretar Upgrade   finalmente deben apretar en Finish   Al abrirlo les aparecerá la interfaz del software  Ahora ya tenemos instalado Zotero, sin embargo no es suficiente, también debemos instalar la extensión BBT para facilitar la sincronización de los datos con el informe que queramos crear.\n2.1 Zotero y BBT Para descargar BBT deben ir al link y en la sección More ir a Download\n Luego deben hacer click en el archivo con extensión .xpi, pero no deben abrirlo  {{\u0026lt; div “note” \u0026gt;}}\nDentro de BBT hay varias versiones las cuales pueden irse actualizando, estas se encuentran en el botón compare\n{{\u0026lt; /div \u0026gt;}}\nPara incorporarlo deben ir a Zotero en Tools y Add-ons / En español es en Herramientas y complementos\n Les aparecerá una ventana emergente, deben ir a la esquina superior derecha, al icono de tuerca   Luego deben ir a Install Add-on from file, encontrar el archivo descargado (.xpi) de BBT   Una vez se encuentra se debe apretar el boton Install Now   Luego se debe reiniciar con el botón Restart Now  Ahora ya tenemos el software que gestiona las referencias y la extensión para mantener sincronizadas las referencias. Sin embargo previo a ver como funcionan dejaremos instaladas las extensiones\n2.2 Instalación de extensión Para incluir la extensión de navegador de Zotero hay varias opciones según el navegador que utilicen\n  Chrome\n  Firefox\n  Microsoft Edge\n  class: title title-8\n2.3 Creación de cuenta Para crearse una cuenta deben ir al siguiente link\nNo es necesario crearse una cuenta para usar Zotero, pero si es recomendable\n3. Puente entre Rstudio y Zotero Para conectar Zotero con Rstudio y facilitar la incorporación de referencias en RMarkdown, necesitamos un conector y para ello tenemos dos opciones: el paquete citr y el editor visual.\nOpción 1:\ncitr este es un paquete que nos facilitara la conexión entre Zotero y Rstudio\nSe puede instalar de varias formas\n  con install.packages\n  Mediante devtools::install_github(\u0026quot;crsh/citr\u0026quot;)\n  O descargando una antigua versión del CRAN\n  Se reinicia R y luego podrán verlo en la sección Addins\n Editor visual  {{\u0026lt; div “note” \u0026gt;}}\nLo más probable es que citr genere problemas en su instalación, debido a que fue removido del CRAN, sin embargo la opción más factible es usar el editor visual o utilizar una versión antigua del paquete\n{{\u0026lt; /div \u0026gt;}}\n3. Flujo de trabajo Una vez teniendo instalado el software y todo lo necesario para empezar estableceremos el flujo de trabajo. Se debe considerar que este proceso es cíclico.\nEs importante entender el flujo de trabajo de Zotero + RMarkdown, porque resume todo lo visto, mientras más nos acostumbremos a este flujo de trabajo más simple se hará el proceso de referenciar a través de Zotero.\n4. Video tutorial en Youtube Recuerden que el video de asociado a este tutorial y muchos más podrán encontrarlos en el canal de youtube del curso\n","date":1628812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628812800,"objectID":"a3a923b6f1f9a39e6c3cd466536a8ad1","permalink":"/resource/zotero-rmd/","publishdate":"2021-08-13T00:00:00Z","relpermalink":"/resource/zotero-rmd/","section":"resource","summary":"0. Objetivo del taller Este taller tiene por objetivo conocer el software Zotero para facilitar la incorporación de citas y referencias en archivos RMarkdown.\n1. Recursos del práctico Para este práctico utilizaremos una colección hecha para el taller de Zotero, que nos facilitará la realización de los ejercicios.","tags":null,"title":"Zotero + RMarkdown","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones   Hadley Wickham, “Data Science: How is it Different To Statistics?”  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"5d439166d6a0e49335e0267500e133e3","permalink":"/content/10-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/10-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Relaciones no lineales","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones   Hadley Wickham, “Data Science: How is it Different To Statistics?”  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"b5fe8e1e81202db02e58eeaf682fa1b4","permalink":"/content/11-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/11-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Supuestos","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones   Hadley Wickham, “Data Science: How is it Different To Statistics?”  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"c4082d10941ce0754d43d2dd1dcfe629","permalink":"/content/12-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/12-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Errores medicion","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones   Hadley Wickham, “Data Science: How is it Different To Statistics?”  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"176b514abc466b90c13990f765764ae7","permalink":"/content/13-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/13-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Omision de variables independientes","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\rDetalles del curso\r\r\r\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones    Hadley Wickham, “Data Science: How is it Different To Statistics?”\n   Tutoriales, “Learn-R”\n Ver Tutorial N°1 Instalación de softwares Ver Tutorial N°2 GitHub y GitHub Class Room    ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"24bdef858b9ebc83bb0134c283e06cf1","permalink":"/content/01-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/01-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\rDetalles del curso\r\r\r\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ?","tags":null,"title":"Introduccion","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones    Hadley Wickham, “Data Science: How is it Different To Statistics?”\n   Tutoriales, “Learn-R”\n Ver Tutorial N°1 Instalación de softwares Ver Tutorial N°2 GitHub y GitHub Class Room    ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"41e89a34ca2fdd432a89cf4ae93cfcc3","permalink":"/content/02-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/02-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Muestras","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones    Hadley Wickham, “Data Science: How is it Different To Statistics?”\n   Práctico 10 - curso R\n  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"0316e4026587433def89bf10f5c614d0","permalink":"/content/03-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/03-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Metodo cientifico - regresiones","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones    Hadley Wickham, “Data Science: How is it Different To Statistics?”\n   Práctico 10 - curso R\n  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"b0405fb0975b8cdddb0454677282c9f2","permalink":"/content/04-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/04-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Regresion lineal simple","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones    Hadley Wickham, “Data Science: How is it Different To Statistics?”\n   Práctico 11 - curso R\n  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"b4d9dbb6ba244e4ebcb0ce95e47cebc7","permalink":"/content/05-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/05-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Regresion lineal - Supuestos","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones    Hadley Wickham, “Data Science: How is it Different To Statistics?”\n   Práctico 11 - curso R\n  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"ab54958bbaea5fe381467c40300e6fb1","permalink":"/content/06-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/06-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Regresion lineal multiple","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones    Hadley Wickham, “Data Science: How is it Different To Statistics?”\n   Práctico 10 - curso R\n  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"708d5afb1e280ebc34cec655dde7f978","permalink":"/content/07-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/07-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Predictores categoricos","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones   Hadley Wickham, “Data Science: How is it Different To Statistics?”  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"ac6f46f70a7f6537961cc77658f6cfcc","permalink":"/content/08-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/08-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Inferencia","type":"docs"},{"authors":null,"categories":null,"content":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.\r\rMateriales de la clase Rprojects   Práctico  Recomendaciones   Hadley Wickham, “Data Science: How is it Different To Statistics?”  ","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"2e7abf6f521ec7257264b0f3edde6da9","permalink":"/content/09-content/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/content/09-content/","section":"content","summary":"Slides  Ver las slides en una nueva ventana  Descargar las slides en PDF\nIntroducción\r\r\r\r\r\r\r¿Cómo ocupar: Si presionas ? (o shift + /) mientras estas viendo las slides, podrás ver los comandos específicos para navegar en ellas.","tags":null,"title":"Transforsformaciones funcionales","type":"docs"},{"authors":null,"categories":null,"content":"Descripción general El Proyecto de investigación es la instancia de evaluación final e individual del curso de Estadistica II. Su objetivo es evaluar los conocimientos y aprendizajes obtenidos en el curso de manera integra. Para ello deberán elaborar una investigación simple cuyo centro está en evaluar su capacidad de hacer una investigación aplicando regresiones y en R.\nDatos Para ello pueden elegir uno de los siguientes datos (aquellos que tienen un asterisco pueden ser escogidos por dos estudiantes)\nInstituciones y organizaciones gubernamentales\n Encuesta de Presupuestos Familiares Encuesta Suplementaria de Ingresos ICMO-IR Encuesta Caracterización Laboral (ENCLA) * Encuesta Nacional de Empleo Encuesta Bienestar Social * Encuesta Nacional de Salud Encuesta Financiera de Hogares ENUSC IV Encuesta de Violencia contra la Mujer en el Ámbito de Violencia Intrafamiliar y en Otros Espacios (ENVIF-VCM)  Instituciones y organizaciones académicas\n ELSOC * OHL * Observatorio Conflictos Termómetro Social Latinobarómetro MOVID-IMPACT * CEP (2019)  Para todas las encuestas deben elegir la última versión disponible\nUna vez definidos sus datos, pueden inscribirse con estos hasta el viernes 24 de junio en el siguiente link\nAnálisis Deben construir un reporte donde analicen algún fenómeno que consideraran de interés y que puede ser abordado desde los datos que seleccionaron. Este reporte debe ser reproducible y coherente con el fenómeno que analizaran. Ahora bien, el centro no será evaluar su manejo en el tema, sino que su capacidad de poder presentar un análisis de datos de un fenómeno de interés utilizando herramientas básicas de R.\nDescripción específica En este apartado encontrarán algunas de las instrucciones para su investigación.\nProcesamiento (.R)  La base final debe contener al menos 5 variables finales Las variables finales deben estar transformadas debidamente, incluyendo los casos perdidos. Poner atención a filtrar observaciones según el fenómeno que están analizando (si trabajarán con un subset o con toda la data)  Análisis (.Rmd)  Estructura: Título, Abstract (100-150 palabras), Introducción (200-250 palabras), Análisis (300-500 palabras), Conclusión (150-200 palabras) y Referencias. Debe indicar su nombre, profesora y ayudantes   El centro está en que al leer este breve resumen de investigación, a la docente le quede claro que tipo de transformaciones deberían haber hecho a los datos, junto con qué análisis debieron reportar. Por ejemplo, si su investigación trata sobre el \u0026ldquo;Impacto de la educación sobre los salarios no tiene sentido que elijan unos datos que no tiene la variable educación y salarios, que ocupen la educación como una variable continua si sus hipótesis implica comparar grupos y/o que hagan un análisis descriptivo.  Análisis de regresión lineal múltiple  Deben utilizar regresiones múltiples y deben construir al menos dos regresiones y compararlas (por ejemplo, cambiando sus formas funcionales o agregando más variables)\nPara reportar estos análisis deben hacer al menos 1 tabla y 2 gráficos.\nLos análisis deben ocupar de alguna forma al menos las 5 variables procesadas.   No siempre las utilizarán para hacer una regresión, quizás les sirve alguna de ellas para filtrar algún grupo y comparar regresiones.  El archivo debe ser compilado a formato html o pdf.  Proyecto  Para acceder a la tarea Deben aceptar el repositorio en el link de GitHub Class Room Deben hacer un README.md explicando aspectos generales del repositorio  Criterios de evaluación Condiciones de suficiencia En este apartado se indican aquellas condiciones que *en caso de no cumplirse se considerará todo el resto del examen no válido. Esto permite corroborar aspectos básicos del curso por lo que se consideran como suficientes para aprobar este. Además, permiten verificar que efectivamente hicieron el proyecto.\nEn caso de caer en alguna de las condiciones de suficiencia serán evaluados con la nota mínima (1,0). El examen solo puede ser entregado hasta la fecha estipulada.\nProyecto en general  Existe un Rproject Se identifica un flujo de trabajo  Procesamiento   Presenta un código de proceso que se puede ejecutar integramente (no presenta problemas para llegar al resultado final de la base procesada).\n  La base original y final son distintas, es decir, que al menos se haya hecho un procesamiento en términos de selección y transformación de variables.\n  Análisis   Existencia de un RMarkdown que haga uso de los datos procesados en el procesamiento.\n  Las imágenes y tablas deben ser creadas en este archivo. Si se necesitan cargar referencias a imágenes externas estas deben estar contenidas dentro de alguna de las carpetas del flujo de trabajo\n  Criterios de evaluación generales Además de los criterios de suficiencia tome nota de los siguientes puntos\n Existencia de flujo de trabajo README.md permite presentar sus trabajos debidamente (debe contener sus nombres, profesora y ayudantes) Código de R y .Rmd sigue orden lógico y presentado en el curso Utiliza paquetes vistos en el curso. En caso de ocupar adicionales deben ser justificados en el README.md Cumplir límite de palabras  Criterios adicionales (0,1 décimas por cada uno)  Colaborar ayudando a compañeros/as por el canal #examen Código ordenado y debidamente comentado Repositorio ordenado y debidamente documentado en README.md Archivo de .RMD a html o pdf tiene un tema especial Realiza análisis para algún otro ramo, tesis o práctica (debe indicarlo en el README.md) Hace fork a su examen final y lo deja en su repositorio final  Entregas Primera entrega   Primera entrega está agendada para la semana del 18 de abril\n  En esta entrega deben entregar introducción y base procesada\n  Examen   Entrega final esta definida para la semana del 27 de junio.\n  La entrega final considera todo el informe + poster que puede ser entregado hasta el 6 de julio. Ese poster final consiste en un resumen ejecutivo de su investigación y que será impreso y pegado en la Universidad.\n  Otros Recursos  No olvide revisar los recursos de la clase (prácticos, complementarios, talleres), pueden serles útil en esta etapa (sobre todo las primeras clases cuando les indicamos la importancia de la autonomía buscando soluciones)   Prácticos Tutoriales Material complementario y talleres  Horarios de consulta y trabajo conjunto Hay dos prácticos dedicados a trabajar en la investigación\n  Práctico 3\n  Práctico 14\n  Los repositorios de esta evaluación final quedarán disponibles para el futuro\nEjemplos de trabajos (pronto)   Informe\n  Poster\n  ","date":1636329600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636329600,"objectID":"de15740154c48278bdd367fb00d501c4","permalink":"/assignment/examen/","publishdate":"2021-11-08T00:00:00Z","relpermalink":"/assignment/examen/","section":"assignment","summary":"Descripción general El Proyecto de investigación es la instancia de evaluación final e individual del curso de Estadistica II. Su objetivo es evaluar los conocimientos y aprendizajes obtenidos en el curso de manera integra.","tags":null,"title":"Examen. Proyecto de investigación final","type":"docs"},{"authors":null,"categories":null,"content":"0. Objetivo del práctico El objetivo de este práctico es crear nuestro primer reporte en RMarkdown y contener en este el primer paso de un código en R: cargar paquetes.\nPara ello repasaremos algunos conceptos básicos de R y Markdown, y los pasos necesarios para la creación de su propio archivo en .Rmd. Este práctico será clave para la realización de tu tarea N°1\nMateriales de la sesión Recuerden que los archivos asociados a este práctico se pueden descargar aquí:\n  02-class.zip  1. Conceptos clave RMarkdown es un archivo que puede integrar código de R (mediante chunks) y texto en Markdown a la vez. Todo el sitio web de este curso está creado con RMarkdown (y un paquete llamado blogdown).\nRMarkdown tienen una estructura de al menos 3 partes\n Encabezado (YAML) Texto Código de R  \r¡Vamos a profundizar en cada una de ellas! Pero antes te iremos mostrando el paso a paso para crear un archivo en .Rmd\n2. Paso a paso para crear un RMarkdown Paso 1: Instalación de paquetes Como vimos en la sesión, para la creación de un RMarkdown necesitamos dar una extensión a R que le permita \u0026ldquo;compilar\u0026rdquo; los archivos construidos en .Rmd a formatos como .pdf, .html, .doc. Para ello instalaremos 2 paquetes: knitr y rmarkdown\nUsualmente para cargar paquetes lo hacemos de la siguiente manera:\ninstall.packages(\u0026#34;paquete\u0026#34;) library(paquete) Pero en esta ocasión utilizaremos un paquete llamado pacman, que facilita y agiliza la lectura de los paquetes a utilizar en R. De esta forma lo instalamos 1 única vez así:\ninstall.packages(\u0026#34;pacman\u0026#34;) library (pacman) Luego instalaremos y cargaremos los paquetes de R de la siguiente manera, volviendo más eficiente el procedimiento de carga de paquetes. Para este práctico cargaremos el paquete rmarkdown y knit.\npacman::p_load(rmarkdown, knitr) Paso 2: Crear un nuevo archivo en Rmarkdown  Una vez cargados los paquetes deben dirigirse a File \u0026gt; New File \u0026gt; R Markdown  Luego deben darle un título, poner su nombre y especificar un formato de salida, ya sea en HTML, PDF o Word  Se creará un archivo con un YAML, que tendrá la información general del documento; y un chunk, o trozo de código  Ya pueden comenzar a escribir sus informes en RMarkdown. Veremos en seguida las configuraciones para dejarlo más lindo y presentable  Paso 3: Crear el archivo con formato desde el .Rmd Es el botón que permite compilar (tejer o unir) el documento que hemos escrito. Combinará tanto el código de R (insertado en chunks) y como el texto plano, a partir de las instrucciones que dimos en el YAML (¡por eso es tan importante!)\r\rEs fundamental que sepan que, cuando se hace Knit, RStudio ejecuta cada uno de los trozos secuencialmente. No es necesario entender el proceso posterior a cabalidad (aún) 1: lo importante que debes saber es que, si todo lo que está dentro de tu .Rmd está bien hecho, deberías ver como resultado un archivo en el formato de salida que definiste en tu YAML (.pdf, .doc o .html).\n3. Configuraciones del RMarkdown 3.1 Encabezado (YAML) Al inicio del Markdown siempre especificar cierta información sobre el documento, por ejemplo, el título, la fecha, autor, entre otras. Esta parte del Markdown se llama YAML.\nBásicamente, con esto establecemos las \u0026ldquo;configuraciones\u0026rdquo; del texto.\nPor ejemplo, si queremos que nuestro archivo esté en PDF, colores, si queremos que incluya bibliografía, entre otros. La \u0026ldquo;cabeza\u0026rdquo; del Markdown o YAML está dividida del resto del cuerpo del texto al inicio y al final con tres guiones (---).\n--- title: Título de mi tesis date: \u0026#34;16 de Agosto, 2021\u0026#34; author: \u0026#34;Estudiante UAH\u0026#34; --- Debes poner el texto entre comillas. Si quieres ocupar comillas dentro de tu título, puedes utilizar comillas simples (e.g. mi tesis se titula Mi tesis: la más \u0026quot;genial\u0026quot; de Chile), entonces ponemos\n--- title: `Mi tesis: la más \u0026#34;genial\u0026#34; de Chile` --- Instrucciones de salida en YAML (Output formats) Los formatos de salida se ven en el encabezado (YAML) del documento: aquí puedes especificar en qué formato quieres que te entregue tu archivo. De esta forma, puedes especificar qué tipo de documento creas cuando \u0026ldquo;Kniteas\u0026rdquo; (es como \u0026ldquo;tejer\u0026rdquo;, construir)\n--- title: \u0026#34;Mi documento\u0026#34; output: html_document: default pdf_document: default word_document: default --- También puedes hacer click en la flecha hacia abajo del botón \u0026ldquo;Knit\u0026rdquo; para elegir la salida y generar el YAML apropiado. Si hace click en el icono del engranaje junto al botón \u0026ldquo;Knit\u0026rdquo; y elige \u0026ldquo;Output options\u0026rdquo; (opciones de salida), puede cambiar la configuración para cada tipo de salida en específico, como las dimensiones de las figuras por defecto o si se incluye o no un índice.\nEl primer tipo de salida que aparece en output: será el que se genere al pulsar el botón \u0026ldquo;Knit\u0026rdquo; o al pulsar el atajo de teclado (⌘⇧K en macOS; control + shift + K en Windows). Si elige una salida diferente con el menú del botón \u0026ldquo;Knit\u0026rdquo;, esa salida se moverá a la parte superior de la sección output.\nAdicionales en YAML El encabezado o YAML es importantísimo, especialmente cuando tienes configuraciones anidadas bajo cada tipo de salida. Cuando uno ya está más avanzado así es como una sección output suele verse:\n--- title: \u0026#34;Mi tesis\u0026#34; author: \u0026#34;Valentina Andrade\u0026#34; date: \u0026#34;16 Agosto 2021\u0026#34; output: html_document: theme: cerulean toc: true toc_depth: 2 toc_float: true number_sections: true pdf_document: latex_engine: xelatex  # Para hacer pdf toc: true word_document: toc: true --- En el YAML o encabezado del documento, se puede modificar:\n  title y subtitle: es el título y subtítulo. Como cualquier carácter en R lo mejor es poner entre comillas su contenido\n  author: nombre del autor/a\n  date: fecha, puede ser escrita como ustedes quieran\n  output: opciones de salida (html, pdf, doc, ¡incluso ppt!)\n  toc: \u0026ldquo;Table of contents\u0026rdquo; o, en español, índice. El término depth indica \u0026ldquo;profundidad\u0026rdquo; para ver cuántos títulos mostrar y float para ver si se desliza automáticamente\n  Si quieres ver más opciones, temas para tu documento puedes ver aquí\n3.2 Texto (Markdown) Abajo del YAML ya podrás escribir texto simple. En la siguiente tabla podrás ver un resumen de los formatos básicos de Markdown, sin embargo pueden repasarlo en la sección recursos o acá\n\r\r\r\rEscribe…\r…o…\r…para obtener\r\r\r\rAlgo de texto en el párrafo.\nMás texto\respacio entre lineas.\r\rAlgo de texto.\nAlgo de texto en el párrafo. Siempre utilizando\respacios para dividir párrafos\n\r\r*Cursivas*\r_Cursivas_\rCursivas\r\r**Negrita**\r__Negrita__\rNegrita\r\r# Título 1\r\rTítulo 1\r\r\r## Título 2\r\rTítulo 2\r\r\r### Título 3\r\rTítulo 3\r\r\r(puedes llegar hasta un título N° 6 con ######)\r\r\r\r[Link text](http://www.example.com)\r\rLink text\r\r![Image caption](/path/to/image.png)\r\r\r\r`Inline code` with backticks\r\rInline code with backticks\r\r\u0026gt; Citas\r\r\rCitas\n\r\r- Cosas en\r- listas\r- desordenadas\r* Cosas en\r* listas\r* desordenadas\r\rCosas en\rlistas\rdesordenadas\r\r\r1. Cosas en\r2. listas\r3. ordenadas\r1) Cosas en\r2) listas\r3) ordenadas\rCosas en\rlistas\rordenadas\r\r\rLínea horizontal\r\u0026mdash;\nLínea horizontal\r***\nLínea horizontal\n\r\r\r\r3.3 Código en R (Chunks) Para ingresar trozos de código en R a nuestro documento ocuparemos los chunks. Estos permiten hacer análisis estadísticos dentro del documento visualizando los resultados en el documento final\nLos chunks se ven así dentro del .Rmd:\n```{r}\r# El codigo va aquí\r````\r 3.3.1 Añadir Chunks Hay tres formas de insertar chunks:\n  Pulsar ⌘⌥I en macOS o Control + Alt + I en Windows\n  Pulsa el botón \u0026ldquo;Insert\u0026rdquo; en la parte superior de la ventana del editor\n  Escribirlo manualmente (no recomendado)  3.3.2 Nombrar chunks Se puede añadir nombres a los chunks para hacer más fácil la navegación por el documento. Si haces clic en el pequeño menú desplegable en la parte inferior de tu editor en RStudio, puedes ver una tabla de contenidos que muestra todos los títulos y chunks. Si nombras los chunks, aparecerán en la lista. Si no incluyes un nombre, el chunk seguirá apareciendo, pero no sabrás lo que hace.\nPara añadir un nombre, inclúyelo inmediatamente después de la {r en la primera línea del chunk. Los nombres no pueden contener espacios, pero sí guiones bajos y guiones.\nImportante: Todos los nombres de chunk de tu documento deben ser únicos.\n```{r nombre-chunk}\r# El codigo va aquí\r````\r 3.3.3 Opciones de chunks Hay un montón de opciones diferentes que puedes establecer para cada chunk. Puedes ver una lista completa en la Guía de referencia de RMarkdown o en el sitio web de knitr.\nLas opciones van dentro de la sección {r} del chunk:\n```{r nombre-chunk, message = F, echo = F}\r# El codigo va aquí\r````\r Las opciones de chunk más comunes son estas:\n  fig.width=5 y fig.height=3 (o el número que quieras): Establece las dimensiones de las figuras\n  echo=FALSE: El código no se muestra en el documento final, pero los resultados si\n  message=FALSE: Se omiten los mensajes que genera R (como todas las notas que aparecen después de cargar un paquete)\n  warning=FALSE: Se omiten las advertencias que genera R\n  include=FALSE: El chunk se sigue ejecutando, pero el código y los resultados no se incluyen en el documento final\n  También puedes configurar las opciones del chunk haciendo clic en el pequeño icono del engranaje en la esquina superior derecha de cualquier chunk:\n4. Resumen Dentro de la creación de archivos en RMarkdown, hay algunos conceptos claves que sí o sií debes manejar para ir construyendo tus documentos en RMarkdown.\n  YAML: Es un encabezado al inicio del documento que inicia y acaba con tres guiones \u0026mdash;*. Acá se introducen aspectos básicos del documento, como el título, el autor, la fecha y el formato de salida (output)\n  Chunk: son trozos de códigos de R, que permiten hacer análisis estadísticos dentro del documento, visualizando los resultados directamente en el documento final\n  Knit: Es el botón que permite compilar (tejer o unir) el documento que hemos escrito. Combinará tanto el código de R y el texto, a partir de las instrucciones que dimos en el YAML\n  4.1 Actividad del práctico La actividad tendrá relación con la entrega de la Tarea 1. Esta actividad consiste en la creación de un RMarkdown que contenga lo siguiente:\n  Un encabezado (YAML) con el título: \u0026ldquo;Práctico 2\u0026rdquo;. También deben incorporar su nombre y fecha\n  Este encabezado debe tener una salida (output), deben elegir html_output\n  En el documento deben incorporarla imagen grafico01 (que está en el .zip asociado a la clase)\n  Finalmente, deben crear una tabla simple.\n  5. Recursos  RMarkdown en Ciencia de Datos - Hadley Whickham R Markdown Tutoriales Markdown cheatsheets Para practicar ir a Tutorial de Markdown    Luego de presionar knit, se convierte la salida de cada trozo en un archivo intermedio en Markdown. Posteriormente, RStudio hace \u0026ldquo;pasar\u0026rdquo; ese documento vía pandoc para convertirlo en HTML, PDF o Word (o cualquier salida que haya seleccionado). \u0026#x21a9;\u0026#xfe0e;\n   ","date":1629072000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629072000,"objectID":"015f0143059149950c403a79dcdaaa00","permalink":"/example/032-practico/","publishdate":"2021-08-16T00:00:00Z","relpermalink":"/example/032-practico/","section":"example","summary":"0. Objetivo del práctico El objetivo de este práctico es crear nuestro primer reporte en RMarkdown y contener en este el primer paso de un código en R: cargar paquetes.","tags":null,"title":"RStudio, tidyverse y RMarkdown","type":"docs"},{"authors":null,"categories":null,"content":"Markdown es una clase especial de lenguaje que permite darle formato a texto simple. Por ejemplo, poder hacer cursivas, negritas, incorporar links, etc.\nPara que el formato que se le ha dado pueda ser visto, el archivo en Markdown (.md) pasa por un convertidor universal llamado pandoc. Este, a diferencia de procesadores como los que ocupa Office no es pagado. Por ello, para no solo para editar tus archivos de texto no necesitarás un software, sino que para crear PDF, archivos .doc (Word), presentación (como las de Power Point) o HTML (para hacer sitios web) es completamente gratis. Solo debes encontrar un editor que pueda hacer esto.\nLa buena noticia es que ya lo conoces: ¡nuestro amigo RStudio!\nFormatos básicos de Markdown \r\r\r\rEscribe…\r…o…\r…para obtener\r\r\r\rAlgo de texto en el párrafo.\nMás texto\respacio entre lineas.\r\rAlgo de texto.\nAlgo de texto en el párrafo. Siempre utilizando\respacios para dividir párrafos\n\r\r*Cursivas*\r_Cursivas_\rCursivas\r\r**Negrita**\r__Negrita__\rNegrita\r\r# Título 1\r\rTítulo 1\r\r\r## Título 2\r\rTítulo 2\r\r\r### Título 3\r\rTítulo 3\r\r\r(puedes llegar hasta un título N° 6 con ######)\r\r\r\r[Link text](http://www.example.com)\r\rLink text\r\r![Image caption](/path/to/image.png)\r\r\r\r`Inline code` with backticks\r\rInline code with backticks\r\r\u0026gt; Citas\r\r\rCitas\n\r\r- Cosas en\r- listas\r- desordenadas\r* Cosas en\r* listas\r* desordenadas\r\rCosas en\rlistas\rdesordenadas\r\r\r1. Cosas en\r2. listas\r3. ordenadas\r1) Cosas en\r2) listas\r3) ordenadas\rCosas en\rlistas\rordenadas\r\r\rLínea horizontal\r\u0026mdash;\nLínea horizontal\r***\nLínea horizontal\n\r\r\r\rExpresiones matemáticas Markdown también utiliza LaTeX para crear ecuaciones matemáticas (y no nos complica tanto la vida como el editor de Word). Si para tu tesis o un proyecto las utilizas te dejo esta guía de comando básicos para crear ecuaciones matemáticas.\nPara introducir una ecuación debes poner los símbolos de peso ($)\nLa ecuación cuadratica es la siguiente $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$ **Con ello obtendremos: **\n La ecuación cuadratica es la siguiente\n$$ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$\n  Evidentemente como el símbolo peso sirve para hacer ecuaciones matemáticas, no lo puedes utilizar en un archivo escrito en Markdown para hacer referencia realmente al símbolo peso. Para ello, debes escribir el símbolo antecedido con un (\\). Así obtendrás una frase escrita como \u0026quot; Te hago la tarea de R por \\$100.000. En caso contrario, si pones el símbólo pesos solo y sin \\ entenderá la oración como una ecuación.\nTablas Hacer tablas es muy fácil. Mira el siguiente ejemplo\nSe escribe así\n| Right | Left | Default | Center | |------:|:-----|---------|:------:| | 12 | 12 | 12 | 12 | | 123 | 123 | 123 | 123 | | 1 | 1 | 1 | 1 | Tabla: Descripción de la tabla …to get…\n   Right Left Default Center     12 12 12 12   123 123 123 123   1 1 1 1    Tabla: Descripción de la tabla\nPies de página Para hacer pies de página debes saber cuál es su (1) identificador y (2) lo que quieres escribir en el pie de página. El identificador puede ser lo que tu quieras: pueden ser números como [^1], pero también pueden ser letras.\nDebes escribir…\nAquí escribo una referencia de mi tesis[^1] y aquí otra más [^note-sobre-marx]. [^1]: Esta es una nota [^note-sobre-marx]: Marx, lo más genial. Y bueno, aquí sigo escribiendo Para obtener\n Aquí escribo una referencia de mi tesis1 y aquí otra más.2\nY bueno, aquí sigo escribiendo\n\rEsta es una nota.↩︎\n\rMarx, lo más genial.↩︎\n\r\r\r La \u0026ldquo;cabeza\u0026rdquo; del Markdown Al inicio del Markdown siempre debemos poner algunas informaciones sobre el documento, por ejemeplo, el título, la fecha, autor, etc. Esta parte del Markdown se llama YAML. Básicamente, con esto establecemos las \u0026ldquo;configuraciones\u0026rdquo; del texto.\nPor ejemplo, si queremos que nuestro archivo esté en PDF, colores, si queremos que incluya bibliografía, entre otros. La \u0026ldquo;cabeza\u0026rdquo; del Markdown o YAMLS está dividida del resto del cuerpo del texto al inicio y al final con tres líneas (---).\n--- title: Título de mi tesis date: \u0026#34;13 de Agosto, 2021\u0026#34; author: \u0026#34;Estudiante UAH\u0026#34; --- Debes poner este texto entre comillas. Si quieres ocupar comillas dentro de tu título, puedes utilizar comillas simples (e.g. mi tesis se titula Mi tesis: la más \u0026quot;genial\u0026quot; de Chile), entonces ponemos\n--- title: `Mi tesis: la más \u0026#34;genial\u0026#34; de Chile` --- Otros recursos que te recomendamos revisar En estos links podrás encontrar distintos ejemplos para practicar. También si quieres conocer más sobre quién creó esta maravilla, revisa sobre Aaron Swartz.\n CommonMark\u0026rsquo;s Markdown tutorial: A quick interactive Markdown tutorial. Markdown tutorial: Another interactive tutorial to practice using Markdown. Markdown cheatsheet: Useful one-page reminder of Markdown syntax. The Plain Person’s Guide to Plain Text Social Science: A comprehensive explanation and tutorial about why you should write data-based reports in Markdown.  ","date":1628640000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628640000,"objectID":"50f208c66dd6a2ac7e263653db4153ee","permalink":"/resource/markdown/","publishdate":"2021-08-11T00:00:00Z","relpermalink":"/resource/markdown/","section":"resource","summary":"Markdown es una clase especial de lenguaje que permite darle formato a texto simple. Por ejemplo, poder hacer cursivas, negritas, incorporar links, etc.\nPara que el formato que se le ha dado pueda ser visto, el archivo en Markdown (.","tags":null,"title":"¿Qué es Markdown?","type":"docs"},{"authors":null,"categories":null,"content":"0. Objetivo del práctico El objetivo de este práctico es realizar un breve repaso a ciertos conceptos clave y definiciones básicas de los fundamentos de probabilidad, pasando por la definición de una variable, sus distribuciones, y las formas de medirlas y/o resumirlas.\nRecordar que la idea principal que se encuentra a la base de la probabilidad refiere a que cuando observamos el comportamiento del azar, este resulta impredecible con pocas repeticiones pero presenta un comportamiento regular y predecible con muchas repeticiones.\nMateriales de la sesión Recuerden que los archivos asociados a este práctico los pueden encontrar en: Apéndice A1 y B - Woolridge\n1. Variables aleatorias y sus distribuciones de probabilidad Las Variables Aleatorias (VA) son variables estadísticas en la que sus valores se obtienen a partir del resultado de algún tipo de experimento. En otras palabras, son variables cuyos valores son resultados numéricos de un fenómeno aleatorio. Un ejemplo de experimento puede ser algo tan simple como lanzar una moneda 20 veces y anotar las veces que obtenemos cara. La cantidad de veces que efectivamente salió cara en el experimento constituye una variable aleatoria. Este experimento puede ser realizado infinitas veces, y en otro ensayo se puede obtener un resultado completamente distinto.\nLas variables aleatorias se dividen en discretas y continuas. Una variable aleatoria discreta es una variable que solo toma una cantidad finita o una cantidad infinita contable de valores. ¿Qué significa esto? Significa que aunque la variable pueda tener resultados infinitos, estos solo toman valores enteros positivos. Por ejemplo, si lanzamos un dado y anotamos el resultado, solo podemos tener valores del 1 al 6. En ningún caso tendremos un resultado negativo o con decimales.\nEn ciertas ocasiones, estimaremos eventos que son cualitativos. Por ejemplo, nos interesa estimar la participación de los alumnos de enseñanza media en manifestaciones del estallido social. En ese caso, la variable también toma valores numéricos. Se puede definir la variable como: X = 1 si se participa en la manifestación, X = 0 si no se participa. En esta situación, como podrán notar, nos enfrentamos a una variable aleatoria discreta. Además, cuando una variable solo puede tomar los valores de 0 y 1, hablamos de una variable binaria.\nLas variables aleatorias discretas se describen estadísticamente por su distribución de probabilidad. Esta corresponde a la probabilidad de la ocurrencia de cada valor de la variable. Siguiendo con el ejemplo del lanzamiento de un dado, su distribución de probabilidad consiste en todos los valores que puede tomar la variable (1 al 6) y la probabilidad de obtener cada una de ellas (en este caso, cada valor tiene una probabilidad de 1/6). La suma de la distribución de probabilidad es igual a 1.\nLas variables aleatorias discretas se pueden representar en tablas o cuadros. Por ejemplo, si la variable corresponde a la cantidad de hijos:\nTabla 1: Distribución de Probabilidad Variable Cantidad de Hijos\nGráfico 1: Distribución de Probabilidad Variable Cantidad de Hijos (en porcentaje) Además de la distribución de probabilidad, también existe la distribución de probabilidad acumulada, la cual determina la probabilidad de que una variable sea igual o menor a un valor concreto. Siguiendo con la variable cantidad de hijos:\nTabla 2: Distribución de Probabilidad Variable Cantidad de Hijos Gráfico 2: Distribución de Probabilidad Acumulada (en porcentaje)\nPor su parte, las VA continuas (VAC) indican que X puede tomar ciertos valores con probabilidad cero, es decir, una variable \\(X\\) es una variable aleatoria continua si la probabilidad de que la variable aleatoria tome cualquier valor real sea igual a cero. ¿Cómo es posible esto? La idea es que los valores que puede tomar una variable aleatoria continua son tantos que es imposible contarlos. Es por esto que la probabilidad de que la variable tome cada uno de estos valores es cero.\nEstas se describen por medio de su función de densidad de probabilidad (fdp), la cual resume la información concerniente a los valores que puede tomar \\(X\\) y a sus correspondientes probabilidades. La fdp de una variable continua solo se utiliza para calcular eventos que comprenden un rango de valores. Un ejemplo de una variable continua donde nos podría interesar su rango de valores consiste en los ingresos de un hogar.\nGráfico 3: Función de Densidad de Probabilidad En este gráfico podemos observar que:\n$$ Pr(-2\\leq X \\leq 1) $$\nse encuentra representada por el área debajo de la curva. Es decir, la probabilidad de que X se encuentre entre -2 y 1 es el área bajo la curva entre esos puntos en el gráfico. Como resume probabilidades, toda el área bajo la curva de la fdp debe ser igual a uno.\nPara todas las distribuciones continuas importantes en la probabilidad y en la estadística, las funciones de distribución acumulada ya han sido tabuladas, y la más conocida de estas es la distribución normal, la cual tendrá un rol fundamental a lo largo del curso.\n2. Distribuciones conjuntas, condicionales, marginales e independencia 2.1 Distribución Conjunta En muchos casos, resulta interesante estudiar de manera conjunta el comportamiento de las variables. En dichos caso, se construye lo que se denomina distribución conjunta. Su objetivo consiste en determinar cómo la variación de una variable se relaciona con la de otra. En el caso de que \\((X,Y)\\) sean variables aleatorias discretas, entonces \\((X,Y)\\) tienen una distribución conjunta, descrita completamente por la función de densidad de probabilidad conjunta de \\((X,Y)\\).\nEn palabras más simples, la distribución conjunta corresponde a la probabilidad de que ocurran dos o más variables aleatorias, al mismo tiempo. Un ejemplo de estudio puede ser la relación entre ingreso y el gasto en vestimentas en un mes.\nTabla 3: Distribución Conjunta del Gasto en Vestimenta\nTabla 4: Distribución Marginal del Gasto en Vestimenta Las casillas en color rosado nos muestra la distribución marginal del gasto en vestimenta.\n2.2 Distribución Marginal Las distribuciones de la variable fila y de la variable columna, de forma separada, se llaman distribuciones marginales, ya que aparecen en los márgenes derecho e inferior de la tabla de contingencia. La columna de totales y la fila de totales de una tabla de contingencia dan las distribuciones marginales de las dos variables de forma separada. Las distribuciones marginales no dan información sobre la relación entre las variables.\nCada componente de una variable aleatoria bidimensional es una variable aleatoria unidimensional en sí misma. Es por esto que nos puede interesar conocer la distribución de un componente por separado, sin tener en cuenta el otro componente. Eso se denomina marginar, y la distribución de la variable unidimensional por separado se llama distribución marginal.\nLa distribución marginal del gasto en vestimenta equivale a su distribución unidimensional:\nTabla 5: Distribución Marginal del Gasto en Vestimenta\nLa media es de 2777.5 y la desviación estándar es de 1739.\n2.3 Distribución Condicional En otras ocasiones, es posible que nos interese el efecto que tiene cierta variable sobre otra. Es decir, el efecto que podría tener una variable Y sobre una variable X. Para poder acercarnos a esto recurrimos a la distribución condicional, cuya información se encuentra resumida en la función de densidad de probabilidad condicional.\nPara hallar la distribución condicional de la variable fila con relación a un valor determinado de la variable columna, fíjate sólo en esa columna de la tabla. Expresa cada valor de la columna como un porcentaje del total de la columna. Existe una distribución condicional de la variable fila para cada columna de la tabla. La comparación de estas distribuciones condicionales es una manera de mostrar la asociación entre la variable fila y la variable columna. Es especialmente útil cuando la variable columna es la variable explicativa.\nUna característica importante de las distribuciones condicionales es que, si X y Y son variables aleatorias independientes, conocer el valor que toma X no dice nada acerca de la probabilidad de que Y tome diversos valores (y viceversa). Por ejemplo, si queremos conocer el impacto que tiene el ingreso en el gasto en vestimenta, no nos interesa realmente la variable ingreso como tal, solo su aporte al gasto en vestimenta. Si estas dos variables son independientes (propiedad que revisaremos más adelante), conocer el gasto en vestimenta no nos dirá nada acerca de los valores que podrían tomar los ingresos.\nTabla 6: Distribución Condicional del Gasto en Vestimenta\nLa media condicional para la fila amarilla es de 1815, para la fila verde de 1949.2 y para la fila roja es de 3365.8.\n2.4. Media condicional Una manera sencilla de resumir la distribución condicional entre dos variables corresponde a la esperanza o media condicional. Esta corresponde al valor esperado de una variable aleatoria respecto a una distribución de probabilidad condicional. Pero, ¿qué es el valor esperado?\nEl valor esperado, o esperanza, corresponde a al promedio ponderado de todos los posibles valores de una variable aleatoria X. Este se denota \\(E(X)\\), \\(μX\\) o \\(μ\\). Ahondaremos sobre la esperanza más adelante.\nTabla 7: Media vs media condicional\n[Ventaja:]{.ul} aprovechar la información contenida en la variable ingreso.\n2.5. Independencia La independencia de variables aleatorias es un concepto muy importante. Decimos que X e Y son independientes si conocer el valor de una de las variables no aporta información sobre la otra. En otras palabras, si la distribución condicional de Y dado X es igual a la distribución marginal de Y. Por ejemplo, si lanzamos una moneda y en el primer intento da cara, luego en el segundo lanzamiento vuelve a dar cara, decimos que los sucesos \u0026ldquo;cara en el primer lanzamiento\u0026rdquo; y \u0026ldquo;cara en el segundo lanzamiento\u0026rdquo; son independientes. Esto significa que el resultado del primer lanzamiento no puede influir sobre el del segundo.\nFormalmente,\n$$ Pr(Y=y|X=x)=Pr(Y=y) $$\nSu implicancia es:\n$$ Pr(X=x,Y=y)=Pr(X=x)*Pr(Y=y) $$\n3. Características de las distribuciones de probabilidad 3.1 Medidas de Tendencia Central: Valor esperado o esperanza El valor esperado o la esperanza es uno de los conceptos más importantes de la probabilidad al cual también se le suele llamar media poblacional, en especial cuando se quiere hacer énfasis en que representa una variable poblacional (contenido que revisaremos en el siguiente práctico). Es un promedio ponderado de todos los posibles valores de X, es decir, la suma de todas las puntuaciones de una variable X dividida por el número de observaciones.\nPara manipular los valores esperados, existen ciertas reglas que denominaremos como propiedades. A continuación se exponen las más importantes:\n Propiedad 1: Para cualquier constante \\(c\\) (es decir, cualquier variable que no depende de ninguna otra), su valor esperado será el valor de la misma constante. Matemáticamente:  $$E(c) = c$$ Recordar que como una constante no depende de ninguna otra variable, su valor es siempre el mismo.\nPropiedad 2: Para cualquier par de constantes a y b, el valor esperado de la recta \\(aX + b\\) será igual a:  $$E(aX + b) = aE(X) + b$$ Asimismo,\n$$E(aX) = aE(X)$$\nEsta propiedad es muy importante al momento de interpretar los resultados de una regresión, lo que veremos más adelante.\nPropiedad 3: Si tenemos un conjunto de constantes a y un conjunto de variables aleatorias X, entonces se puede expresar que el valor esperado de una suma es la suma de los valores esperados. Esto es:  $$E(a_1X_1 + a_2X_2 + ... +a_nX_n) = a_1E(X_1) + a_2E(X_2) + ... + a_nE(X_n)$$\n3.2 Medidas de tendencia central: Mediana En general, es la puntuación que se encuentra en la mitad de una distribución de puntuaciones x. Indica el valor bajo el cual se encuentra el 50% de los casos. Su cálculo sólo exige orden en las puntuaciones. En definitiva, es el valor que se ubica en la mitad de la distribución de los datos.\nSi X es continua, entonces la mediana de X, llámese m, es el valor tal que una mitad del área bajo la curva de la Función de Densidad de Probabilidad queda a la izquierda de m y la otra mitad del área queda a la derecha de m. Si X es discreta y toma una cantidad finita de valores, la mediana se obtiene ordenando todos los posibles valores de X y seleccionando después el valor que se encuentra al medio.\nPor ejemplo, si X toma los valores {-4, 0, 2, 8, 10, 13, 17}, entonces la mediana de X es 8.\nSi X toma un número par de valores, como podran imaginar, hay dos valores en el medio. En esos casos, se deben promediar ambos valores para obtener un único valor para la mediana. Por ejemplo, si X toma los valores {-5, 3, 9, 17}, entonces se deben promediar los valores medianos de 3 y 9. La mediana, por lo tanto, es 6.\n3.3 Medidas de tendencia central: Moda El atributo que más se repite o posee mayor frecuencia en una muestra.\nPor ejemplo, si X toma los valores {-2, 0, 5, 5, 7, 8, 8, 8, 8, 17, 20, 20}, la moda es 8.\n3.4 Medidas de Variabilidad o Dispersión: Varianza Aunque conocer la esperanza, la mediana y la moda de una variable es algo valioso, no nos entrega toda la información que deseamos sobre la distribución de una variable aleatoria. Es por esto que también se recurre a las medidas de variabilidad, que nos resumen la dispersión de las variables. Como se evidencia en el siguiente gráfico, tres variables pueden tener la misma media, pero sus distribuciones pueden ser muy distintas.\n(foto del woolridge)\nUna de las medidas de variabilidad más importante es la varianza ($σ²$). Esta resume que tan lejos se encuentra, en promedio, una variable de su media. Esta se calcula:\n$$Var (X) = \\frac{(x_1 - μ)^2 + (x_2 - μ)^2 + ...+ (x_n - μ)^2}{n}$$ Recordemos que x representa las observaciones. Por ejemplo, x_1 representa la observación número 1 de la variable. μ representa la media de la variable. n es el número total de observaciones. La fórmula de la varianza también se puede resumir de la siguiente forma:\n$$Var(X) = \\frac{\\sum_{i=1}^{n} (x_i - μ)^2}{n} $$ A continuación, presentaremos dos propiedades muy importantes de la varianza:\n  Propiedad 1: La varianza de cualquier constante c es cero. Y si \\(Var(X) = 0\\), significa que la variable es una constante.\n  Propiedad 2: Para cualquier constante a y b, \\(Var(aX + b) = a^2Var(X)\\)\n  En palabras simples, esto significa que sumar una constante a una variable aleatoria no modifica la varianza. Por ejemplo, si a todos los valores de una variable le sumo 2, el valor de la varianza se mantiene igual.\nSin embargo, multiplicar una variable aleatoria por una constante aumenta la varianza en un factor igual al cuadrado de la constante.\n3.5 Medidas de Variabilidad o Dispersión: Desviación Estándar La desviación estándar (σ) de una variable aleatoria también nos entrega información sobre la dispersión de una variable aleatoria. Esta es siempre igual o mayor que cero. En definitiva, no es más que la raíz cuadrada de la varianza. O bien, la varianza es la desviación estándar elevada al cuadrado. Sin embargo, la desviación estándar es mucho más intuitiva cuando llega la hora de interpretar resultados. Una desviación estándar baja indica que la mayor parte de los datos se encuentran agrupados alrededor de su media, mientras que una desviación estándar alta indica que la mayor parte de los datos se alejan de la media, o sea, se extienden sobre un rango de valores más amplio.\n$$sd(X) \\equiv + \\sqrt{Var(X)}$$\nDe las propiedades de la varianza, se deducen también dos propiedades sobre la desviacón estándar:\n Propiedad 1: Para toda constante c, su desviación estándar es igual a 0.  2.Propiedad 2: Para todas las constantes a y b ,\n$$sd(aX + b) = |a|sd(X)$$ Cuando a todos los valores de una variable aleatoria se le suma un número, la desviación típica permanece igual. No obstante, cuando todos los valores de la variable son multiplicados por un mismo número, la desviación típica también quedará multiplicada por ese mismo número.\n4. Características de las distribuciones conjuntas y de las condicionales 4.1 Covarianza En el primer apartado, introducimos el concepto de probabilidad conjunta, cuando dos VA pueden tomar simultáneamente ciertos valores concretos. A pesar de esto, es útil tener una medida resumida del promedio de la variación de estas dos variables aleatorias, unas respecto a la otra.\nLa covarianza refleja la relación lineal de dos variables aleatorias. Es una medida de dependencia lineal entre dos variables y si es positiva indica que las dos variables aleatorias se mueven en la misma dirección, mientras que si es negativa indica que las dos variables se mueven en direcciones opuestas.\nFormalmente,\n$$ Cov(X,Y)=E[(X-\\mu_x)(Y-\\mu_y)]= \\sigma_{xy} $$\nDos propiedades importantes de la covarianza son las siguientes:\n Propiedad 1: Si X e Y son independientes, entonces su covarianza es 0.  Es importante recalcar que el inverso no es verdad: cero covarianza entre X e Y no implica que X e Y sean independientes. Esto solo implica que no existe una relación lineal entre ellas.\nPropiedad 2: Para todas las constantes \\(a_1, b_1, a_2\\) y \\(b_2\\),  $$Cov(a_1X + b_1, a_2Y + b_2) = a_1a_2Cov(X, Y) $$ De esto se desprende que la covarianza entre dos variables aleatorias puede alterarse simplemente multiplicando una o las dos variables por una constante.\n4.2 Correlación Como vimos en la segunda propiedad de la covarianza, esta se altera fácilmente al multiplicarla por cualquier constante. Por ejemplo, si queremos calcular la covarianza entre ingresos y cantidad de educación, esta dependerá si ingresos se mide en dólares, miles de dólares, miles de pesos, etc. Asimismo, dependerá también si cantidad de educación se mide en años o meses. Esta deficiencia se supera mediante el coeficiente de correlación, lo que facilita la interpretación de resultados.\nFormalmente,\n$$ corr(X,Y)=\\frac{cov(X,Y)}{\\sqrt{var(X)var(Y)}}=\\frac{\\sigma_{xy}}{\\sigma_{x}\\sigma_{y}}$$ Si X e Y son independientes, entonces su correlación es igual a 0. Pero la correlación cero no implica independencia, solo significa que no existe una relación lineal entre las variables.\nDos propiedades importantes de la correlación son:\n Propiedad 1: $-1\\leq corr(X,Y) \\leq1 $  Esto significa que los valores del coeficiente de correlación van desde -1 a 1. Si \\(Corr(X, Y) = 0\\), se dice que X e Y son variables aleatorias no correlacionadas. De lo contrario, están correlacionadas.\n\\(Corr(X, Y) = 1\\) implica una relación lineal positiva perfecta, mientras \\(Corr(X, Y) = -1\\) implica una relación lineal negativa perfecta. Rara vez se obtienen estos valores, pero mientras más cerca esté la correlación del 1 o el -1, más fuerte es la relación lineal.\nPropiedad 2: Para todas las constantes \\(a_1, b_1, a_2\\) y \\(b_2\\), con \\(a_1, a_2 \u0026gt; 0\\):  $$Corr(a_1X + b, a_2Y + b_2) = Corr(X, Y)$$ Con \\(a_1, a_2 \u0026lt; 0\\):\n$$Corr(a_1X + b, a_2Y + b_2) = - Corr(X, Y)$$ Esto significa que, al multiplicar las variables por una constante, la correlación no sufre cambios. Por ejemplo, tenemos que la correlación entre cantidad de educación e ingresos es 0.15. Este resultado no cambia, es independiente si los ingresos se miden en dólares o millones de pesos, o si la educación se mida en años, meses o semestres.\nGráfico 5: Tipos de correlaciones\n5. Resumen En este práctico realizamos un repaso de algunos conceptos claves que son fundamentales estadística básica e inferencial aplicada a la probabilidad, estos se centraron en:\n  Distribución Conjunta, Marginal, y Condicional\n  Independencia\n  Covarianza y Correlación\n  ","date":1628467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628467200,"objectID":"1c54211c51c2690aaec09991c5ab4895","permalink":"/example/01-practico/","publishdate":"2021-08-09T00:00:00Z","relpermalink":"/example/01-practico/","section":"example","summary":"0. Objetivo del práctico El objetivo de este práctico es realizar un breve repaso a ciertos conceptos clave y definiciones básicas de los fundamentos de probabilidad, pasando por la definición de una variable, sus distribuciones, y las formas de medirlas y/o resumirlas.","tags":null,"title":"Variables aleatorias y distribuciones","type":"docs"},{"authors":null,"categories":null,"content":"0. Objetivo del práctico Este práctico tiene por objetivo el repaso de los contenidos relacionados con la inferencia estadística. Esta hace referencia a los métodos que nos permiten saber algo sobre una población definida, utilizando la información que nos entrega una muestra de esa población.\nRepasaremos, específicamente, las propiedades de los estimadores, test de hipótesis e intervalos de confianza.\n1. Propiedades de Estimadores Al trabajar en una investigación, es muy probable que no podamos acceder a los datos de la población entera que nos interesa estudiar. Hasta ahora, hemos estudiado propiedades y estadísticos útiles para sacar conclusiones acerca de los datos que poseemos. Pero, ¿Qué pasa cuando necesitamos saber algo acerca de una población?\nComo población se entiende cualquier grupo definido de elementos que buscamos estudiar. Este grupo puede ser las personas de un país, los estudiantes de una ciudad, las empresas de determinado rubro, etc. Una población puede ser de interés para investigaciones, diseños de políticas públicas, sondeos de opinión, investigaciones de mercado, entre muchas otras posibilidades.\nNo obstante, resulta muy difícil acceder a una población para estudiarla. Por ejemplo, si buscamos estudiar a la población chilena mayor de 18 años, es imposible aplicar una encuesta a todas las personas que conforman esta población. Es por esto que se recurre a una muestra, la que constituye una selección de una parte de la población que nos interesa. A través de una muestra, podemos conocer algo sobre la población.\nPero, ¿qué es ese algo?. A las constantes que determinan direcciones y fortalezas de las relaciones entre variables de una población les denominamos parámetros.\nPara conocer estos parámetros, es necesario recurrir a los estimadores.\nDada una muestra aleatoria { \\(Y_1,Y_2, ..., Y_n\\) } extraída de una población que depende de un parámetro desconocido θ, un estimador de θ es un estadístico que asigna a cada resultado posible de la muestra un valor de θ. El valor de un estimador entrega una estimación puntual del parámetro poblacional.\nUn ejemplo de estimador es el promedio de una muestra aleatoria, que recibe el nombre de promedio muestral. Anteriormente tratamos al promedio como un estadístico descriptivo de un conjunto de datos, pero ahora se trata de un estimador, en el sentido de que funciona como un estadístico que busca acercarse a la media poblacional ($\\mu$)\nFormalmente, la media muestral es: $$\\overline{y} = \\frac{1}n\\sum_{i=1}^{n}Y_i$$\nOtro ejemplo de estimador corresponde a la varianza muestral, que busca estimar la varianza poblacional ($σ²$).\nFormalmente, la varianza muestral es:\n$$S_Y^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(Y_i - \\overline{Y})^2$$\nPara poder escoger un estimador, es necesario evaluarlos mediante distintas propiedades de su distribución de probabilidades. Estas propiedades dependen de los datos que poseamos: existen propiedades para muestras pequeñas o finitas, y propiedades para muestras grandes. A continuación repasaremos las más importantes.\nPropiedades en muestras finitas Las propiedades que revisaremos a continuación corresponden a muestras finitas o pequeñas.\na) Insesgamiento Un estimador es insesgado cuando su valor esperado es igual al parámetro que buscamos estimar. Si pudieramos calcular muestras aleatorias infinitas de nuestra población de interés, calcular el estimador para cada una de ellas y después promediar, obtendríamos el parámetro. Que un estimador sea insesgado es muy importante, pues nos asegura que la estimación calculada sea la más aproximnada al valor poblacional real.\nEn otros términos, si \\(t(x)\\) es un estimador de un parámetro θ, y sea f(t,θ) la función de densidad de probabilidad de t. Entonces, t es insesgado si \\(E(t) =\\) θ\nLa media muestral es un ejemplo de estimador insesgado de la media poblacional de una población determinada. Al incrementar el tamaño muestral, su varianza puede acercarse mucho al cero.\nEn términos matemáticos,sea \\(Y_1, Y_2, ..., Y_n\\) una muestra aleatoria de una población media \\(\\mu_y\\):\n$$ \\overline{y} = \\frac{1}{n} (Y_1 +Y_2 + \u0026hellip; + Y_n) = \\frac{1}{n}\\sum_{i=1}^{n} Y_i $$\nReemplazamos en la fórmula del valor esperado:\n$$E(\\overline{y}) = E(\\frac{1}{n}\\sum_{i=1}^{n} Y_i) = \\frac{1}{n}\\sum_{i=1}^{n}E(Y_i) $$ $$= \\frac{1}{n}\\sum_{i=1}^{n}\\mu_y = \\mu_y$$\nPara un estimador \\(W\\) que no es insesgado, o sea, que es sesgado de un parámetro θ, su sesgo se define como:\n$$Sesgo(W) = E(W) - θ$$\nPropiedades asintóticas Estas propiedades se encuentran relacionadas con el comportamiento de los estimadores a medida que el tamaño de la muestra aleatoria crece sin límites. También se les suelen denominar propiedades de muestra grande ($n → ∞$). Estas se encuentran basadas en la idea de que mientras más grande es el tamaño de la muestra, mejor es el procedimiento de estimación.\na) Consistencia La consistencia hace referencia a qué tan lejos es probable que el estimador se encuentre del parámetro, a medida que el tamaño de la muestra aumente de manera indefinida. Es decir, un estimador consistente se concentra cada vez más alrededor del valor del parámetro, lo que significa que en las muestras mayores, es cada vez menos probable que el estimador se aleje del parámetro.\nEn otras palabras, un estimador consistente posee un sesgo que se aproxima a cero cuando el tamaño de la muestra es grande o tiende al infinito.\nSi un estimador no es consistente, entonces no es útil saber sobre el parámetro. Es por esta razón que que la consistencia es un requisito mínimo de un estimador.\nUn estimador consistente es el promedio de una muestra aleatoria, extraído de una población. Esto es porque, mientras más grande sea el tamaño de la muestra, su varianza se acercará al 0. Por tanto, \\(Var(\\overline{y}) → 0\\) cuando \\(n → ∞\\), así que \\(\\overline{y}_n\\) es consistente de \\(\\mu\\), además de ser insesgado.\nb) Precisión Un estimador es más preciso cuando más pequeña la varianza de su distribución muestral. La precisión del estimador aumentará mientras más grande sea la muestra con la que trabajemos. De hecho, la varianza puede acercarse mucho al cero cuando se incrementa el tamaño muestral.\nMientras más pequeña sea la varianza, y por lo tanto más precisio nuestro estimador, nuestro error de estimación será menor.\nc) Teorema Central del Límite Si poseemos una muestra aleatoria de determinada población, su distribución de medias muestrales se acercará cada vez más a una distribución normal a medida que el tamaño de la muestra aumente y tienda al infinito.\nSea \\(Y_1, Y_2, ..., Y_n\\) una muestra aleatoria de una población con media \\(\\mu\\) y varianza \\(σ²\\). Entonces,\n$$\\sqrt{n}(\\overline{y} - \\mu) →^d N(0,σ²) $$ donde \\(d\\) significa que la expresión converge en distribución normal cuando \\(n\\) tiene al infinito ($n → ∞$)\nEste teorema es muy importante, pues para realizar diversos procesos estadísticos como las pruebas de hipótesis, es necesario asumir que las medias muestrales se distribuyen de manera normal.\nAdemás, es importante recalcar que este teorema se aplica independientemente de la distribución que presente la población.\n2. Test de Hipótesis Hasta ahora hemos abordado estimadores puntuales, en el sentido de que nos entregan un valor poblacional específico. No obstante, esta información no es suficiente para probar teorías , analizar diversas políticas o realizar una investigación social.\nCuando necesitamos una respuesta definitiva de \u0026ldquo;sí\u0026rdquo; o \u0026ldquo;no\u0026rdquo;, recurrimos a una prueba o test de hipótesis. Esta técnica permite evaluar la información contenida en los datos, y poder realizar conclusiones acerca de la población que estamos estudiando.\nUna pregunta de investigación que puede ser respondida, por ejemplo, a través de una prueba de hipótesis corresponde a: ¿Las personas negras sufren discriminación en el proceso de contratación? Mediante esta técnica y un set de datos, podemos llegar a una respuesta.\na) Planteamiento de Hipótesis El primer paso para realizar una prueba es establecer una hipótesis. Esta puede ser una respuesta tentativa a una pregunta de investigación, o un planteamiento sobre una población a estudiar. En definitiva, la hipótesis nos dice algo sobre la población, y mediante la prueba de hipótesis podemos evaluar y concluir si ese algo es válido o no.\nUna de las hipótesis es la hipótesis nula (H~0~). Esta es la hipótesis que queremos contrastar, y siempre se asume que es verdadera hasta que se pruebe lo contrario de manera contundente a través de los datos. Siguiendo el ejemplo, una hipótesis nula es que las personas negras tienen las misma probabilidad de recibir ofertas de trabajo que las personas blancas. En otras palabras, no existiría diferencia entre las personas negras y las personas blancas en un proceso de contratación laboral.\nFrente a esta hipótesis, se plantea una hipótesis alternativa (H~1~), que es la hipótesis que buscamos probar utilizando un set de datos. Esta hipótesis anticipa la existencia de una diferencia entre los grupos. Siguiendo el ejemplo, una hipótesis alternativa es que las personas negras poseen una probabilidad menor de recibir ofertas de trabajo frente a las personas blancas.\nb) Tipos de Error Cuando se realiza una prueba de hipótesis, se pueden cometer dos tipos de errores. Uno de ellos es rechazar la hipótesis nula H~0~ cuando de hecho es verdadera. Este error recibe el nombre de error tipo I. En el ejemplo, un error tipo I sería afirmar que sí existe discriminación hacia las personas negras frente a las personas blancas en un proceso de contratación laboral, cuando en realidad no existe tal cosa.\nOtro tipo de error corresponde a aceptar H~0~ como verdadera cuando en realidad es falsa. A este error se le denomina error tipo II. En el ejemplo, un error tipo II sería afirmar que no existe discriminación hacia las personas negras en comparación con las personas blancas en un proceso de contratación laboral, cuando en realidad sí existe tal discriminación.\nEn la práctica, nunca sabremos con certeza si cometimos un error o no. No obstante, es posible calcular la probabilidad de cometer un error tipo I. Para aquello, se define el nivel de significancia de una prueba, que suele denotarse como \\(\\alpha\\). Se tiene:\n$$\\alpha = P(Rechazar H_0 | H_0 verdadero)$$\nEsto se lee como \u0026ldquo;la probabilidad de rechazar H~0~ cuando H~0~ es verdadera\u0026rdquo;\nc) Estadístico de contraste Una vez definidas las hipótesis, es necesario elegir un estadísito de prueba para comparar la información que nos entrega la muestra con la hipótesis nula. El estadístico de prueba (T) es una variable aleatoria que depende de la muestra, y a partir de su cálculo, se puede definir una regla de rechazo. En otras palabras, utilizando el estadístico T podemos establecer cuándo se rechaza H~0~ en favor de H~1~, y viceversa.\nLas reglas del rechazo están basadas en comparar el valor del estadístico de prueba (t) con un valor crítico (c). Para determinar este valor, se debe definir el nivel de significancia de la prueba ($\\alpha$). Para el nivel de significancia se suelen utilizar los valores de 0,1; 0,05; 0,01. Este valor implica, por ejemplo, que el investigador está dispuesto a rechazar H~0~ incorrectamente un 5% de las veces, si se considera \\(\\alpha\\) = 0,05. En otras palabras, la probabilidad de un error tipo I es de 5%.\nUna vez establecido el nivel de significancia, es posible calcular el valor crítico mediante la distribución de T, suponiendo que H~0~ es verdadera. Los valores de t que resulten en el rechazo de la hipótesis nula se conocen como la región de rechazo.\nTeniendo eso en consideración, la hipótesis nula se expresa como \\(H_0: \\mu = \\mu_0\\), donde \\(\\mu_0\\) es un valor que se especifica. Siguiendo el ejemplo expuesto con anterioridad, la hipótesis nula corresponde a \\(H_0: \\mu = 0\\). Es decir, la diferencia de probabilidades de que las personas negras reciban ofertas de trabajo con relación a las personas blancas es 0.\nSobre la hipótesis alternativa, existen tres opciones. Dos de ellas son test unilaterales o de \u0026ldquo;una cola\u0026rdquo;:\n$$H_1: \\mu \u0026gt; \\mu_0$$\n$$H_1: \\mu \u0026lt; \\mu_0$$\nTambién existe el test bilateral o de \u0026ldquo;dos colas\u0026rdquo;:\n$$H_1: \\mu ≠ \\mu_0$$\nSiguiendo el ejemplo, la hipótesis alternativa corresponde a \\(H_1: \\mu \u0026lt; 0\\). Es decir, la diferencia de probabilidades de que las personas negras reciban ofertas de trabajo con relación a las personas blancas es menor a 0, lo que significaría discriminación en los procesos de contratación. En este caso, $\\mu = θ_B - θ_W $ es la diferencia de probabilidades de que las personas negras recibieran ofertas de trabajo con relación a los blancos.\nSiguiendo este ejemplo, correspondería realizar un test unilateral de cola izquierda.\nTest Bilateral En este tipo de test, la regla general para descartar H~0~ es que el valor absoluto del estadístico t sea mayor al valor absoluto crítico c. Es decir:\n$$|t| \u0026gt; |c|$$\nTest Unilateral Derecho En este tipo de test, la regla general para descartar H~0~ es que el valor del estadístico t sea mayor al valor crítico c. Es decir:\n$$t \u0026gt; c$$\nTest Unilateral Izquierdo En este tipo de test, la regla general para descartar H~0~ es que el valor del estadístico t sea menor al valor negativo crítico c. Es decir:\n$$t \u0026lt; -c$$\nSupongamos que el valor de estadístico t para probar que \\(H_0: \\mu = 0\\) en el ejemplo de discriminación laboral es -4.29. El valor crítico, con un nivel de significancia de 0.05, es -2.58. El valor t de -4.29 es una evidencia grande en contra de la hipótesis nula, pues se encuentra a la izquierda del valor crítico. Por lo tanto, se aprueba \\(H_1\\) y se concluye que existe discriminación en la contratación entre personas negras y personas blancas.\nd) Estimación de T Al realizar una prueba de hipótesis sobre la media muestral, nos podemos encontrar con 3 casos distintos.\nUn primer caso corresponde a que, al momento de realizar la prueba, conocemos que Y se distribuye normalmente y, además, conocemos el valor de la varianza poblacional \\(σ_y^2\\). Entonces, asumiendo que H~0~ es verdadera, tenemos:\n$$\\overline{y}\\sim N(\\mu_0,\\frac{σ_y^2}{n})$$ Por lo tanto, el estadístico de prueba corresponde a:\n$$T = \\frac{\\overline{Y} - \\mu_0}{σ_y/\\sqrt{n}} \\sim N(0,1) $$ Un segundo caso corresponde a realiar una prueba de hipótesis sobre la media \\(\\mu\\) de una población cuando la varianza \\(σ_y^2\\) es desconocida, y además sabemos que Y distribuye normalmente. Como primer paso, se debe estimar la varianza muestral:\n$$S_Y^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(Y_i - \\overline{Y})^2$$ Luego, el estadístico de prueba corresponde a:\n$$T = \\frac{\\overline{Y} -\\mu_0}{S_Y / \\sqrt{n}}\\sim t_n-1 $$ Un tercer caso corresponde a cuando no conocemos ni la distribución de \\(Y\\) ni su varianza \\(σ_y^2\\). En este tipo de casos recordamos la propiedad asintótica para muestras grandes denominada como Teorema Central del Límite. La distribución \\(t_{n-1}\\) converge en una distribución normal estándar a medida que \\(n\\) aumenta, por lo que \\(t\\) y los valores críticos normales estándar estarán muy cerca para un \\(n\\) muy grande.\nEntonces, basándonos el el Teorema Central del Límite, la elección entre \\(t\\) y las distribuciones normales estándar suele ser irrelevante debido a que los valores críticos son prácticamente iguales en muestras donde \\(n\u0026gt;120\\).\nPor lo tanto, el estadístico de prueba corresponde a:\n$$T = \\frac{\\overline{Y} -\\mu_0}{S_Y / \\sqrt{n}} →^a N(0,1)$$\ne) Valores -p Debido a que se pueden definir distintos niveles de significancia para realizar una prueba de hipótesis, surge la pregunta: ¿Cuál es el nivel de significancia máximo al cual se puede realizar la prueba y aún así no rechazar la hipótesis nula?\nAnte esa problemática, se puede calcular el valor*-p* de una prueba, que se define como la probabilidad mínima con la que podemos rechazar la hipótesis nula H~0~ sin necesidad de definir de antemano un nivel de significacia \\(\\alpha\\). El valor*-p* depende de la función de distribución del estadístico de contraste.\nDependiendo del tipo de test de hipótesis que queramos realizar, el valor*-p* se calcula:\n$$P-value = P(T \u0026gt; t | H_0)$$\n$$P-value = P(T \u0026lt; t | H_0)$$\n$$P-value = 2P(T \u0026gt; |t| | H_0)$$\nSi el \\(valor-p \u0026lt; \\alpha\\), entonces se rechaza H~0~. En cambio, si el \\(valor-p ≥ \\alpha\\) no se rechaza H~0~. En definitiva, un valor*-p* pequeño es evidencia fuerte en contra de H~0~.\n3. Intervalos de Confianza Debido al error de muestreo, es imposible conocer el valor exacto de la media poblacional a partir de los datos muestrales. Una estimación puntual puede ser una aproximación, pero esta no nos entrega información sobre que tan probable es que ese valor sea realmente cercano al parámetro poblacional.\nEste problema se soluciona mediante los intervalos de confianza. Estos corresponden a un set de valores que contienen el verdadero valor poblacional de un parámetro, para un nivel de probabilidad dado.\nPara el cálculo de intervalos de confianza, se suele usar un nivel de confianza de 95%. Esto significa que, para el 95% de las muestras aleatorias, el intervalo de confianza contendrá a la media poblacional.\nDespués de calcular un intervalo de confianza, se puede realizar una prueba de hipótesis de dos colas. Cuando el intervalo pasa por el valor 0, es posible establecer que se confirma la hipótesis nula \\(H_0\\). Es decir, no existe significancia estadística.\nLas fórmulas para calcular un intervalo de confianza considerando un test bilateral al 95% de confianza son las siguientes:\n  { \\(\\overline{y} ± 1.96 * (σ_y) / \\sqrt{n}\\) }, cuando se conoce la distribución normal de \\(Y\\) y su varianza \\(σ_y^2\\)\n  { \\(\\overline{y} ± t^{n-1}_{\\alpha/2} * SE(\\overline{y})\\) }, cuando se conoce la distribución normal de \\(Y\\), pero se desconoce su varianza \\(σ_y^2\\)\n  { \\(\\overline{y} ± 1.96 * SE(\\overline{y})\\) }, cuando se desconoce tanto la distribución como la varianza de \\(Y\\)\n  Resúmen Prueba de Hipótesis Para finalizar este práctico, haremos un breve repaso acerca del procemiento para realizar una prueba de hipótesis.\n  Identificar las hipótesis. De acuerdo al parámetro que estamos buscando y las suposiciones que surgen respecto a él, debemos identificar la hipótesis nula y la hipótesis alternativa. Importante es recordar que la hipótesis que se pondrá aprueba es la nula ($H_0$).\n  Naturaleza de la prueba. De acuerdo a la hipótesis alternativa establecida, se define la naturaleza de la prueba. Esta puede ser una prueba de dos colas, prueba de una cola izquierda o una prueba de una cola derecha. De acuerdo a la naturaleza, cambia la regla de rechazo para descartar \\(H_0\\).\n  Nivel de confianza de la prueba. El siguiente paso es establecer el nivel de confianza de la prueba de hipótesis, lo que nos permitirá posteriormente calcular el valor del estadístico de prueba. Para el nivel de significancia se suelen utilizar los valores de 0,1; 0,05; 0,01. En la mayoría de situaciones, utilizaremos un \\(\\alpha\\) igual a 0,05 (95% de confianza)\n  Valor crítico de t. A continuación, buscaremos el valor crítico del estadístico de prueba de nuestro test. Para conocer este valor, necesitamos saber el nivel de confianza de la prueba (definido en el paso anterior) y los grados de libertad. Estos últimos, para la distribución t de Student, corresponden a \\(n-1\\). En otras palabras, los grados de libertad a utilizar serán el valor del tamaño de la muestra, menos 1. Con esa información a mano, podemos buscar el valor crítico de nuestra prueba de hipótesis. Estos ya están calculados y se pueden encontrar en diversos softwares de estadística (como R), o bien seguir el método tradicional que es buscarlo en la Tabla de la prueba T de Student.\n  Por ejemplo, si establezco un nivel de confianza de 95% (0,05) y el valor de los grados de libertad es 14, el valor crítico para una prueba de una cola corresponde a 1.761. Si este valor es positivo o negativo depende del tipo de prueba que esté realizando. Si es una prueba de cola izquierda, el valor es -1.761, mientras si es una prueba de cola derecha, el valor es 1.761.\nSiguiendo el mismo ejemplo, el valor crítico para una prueba de dos colas corresponde a ±2.145.\n¡Recordar! Como vimos anteriormente, el valor crítico de muestras superiores a 120 es practicamente igual en la distribución t como en la distribución normal estándar. Es por esto que la tabla termina formalmente en el valor de 120 grados de libertad, y el siguiendo valor corresponde a un símbolo infinito ∞. Esto significa que se considera a los valores mayores a 120 como muestras grandes y, por lo tanto, se aplica el Teorema Central del Límite.\n Cálculo estadístico de contraste. De acuerdo a la información que tengamos disponible, seleccionamos la fórmula para calcular el estadístico de contraste. Esta elección dependerá de si poseemos el valor de la varianza y/o conocemos que la media poblacional se distribuye de manera normal. Como vimos anteriormente, existen 3 casos posibles.\n  Comparar estadístico de prueba y valor crítico. Una vez calculado nuestro estadístico t, corresponde compararlo con el valor crítico de la prueba, siguiendo la regla de rechazo de \\(H_0\\) anteriormente escogida. De acuerdo a esto, se acepta o rechaza la hipótesis nula.\n  Opcional. También podemos utilizar el valor-p, como revisamos anteriormente. Para aquello, debemos seguir las fórmulas expuestas arriba y comparar tal valor con nuestro nivel de significancia escogido. Recordar que mientras más pequeño sea el valor-p, más evidencia existe en contra de \\(H_0\\).\nSacar conclusiones. Si bien ya terminamos con la parte más pesada de la prueba de hipótesis, es muy importante detallar nuestras conclusiones y explicar nuestros hallazgos de manera concreta y sencilla.  ","date":1628467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628467200,"objectID":"1acd8542f65cf3cff8f2eec98b604361","permalink":"/example/02-practico/","publishdate":"2021-08-09T00:00:00Z","relpermalink":"/example/02-practico/","section":"example","summary":"0. Objetivo del práctico Este práctico tiene por objetivo el repaso de los contenidos relacionados con la inferencia estadística. Esta hace referencia a los métodos que nos permiten saber algo sobre una población definida, utilizando la información que nos entrega una muestra de esa población.","tags":null,"title":"Inferencia","type":"docs"},{"authors":null,"categories":null,"content":"0. Objetivo del práctico El objetivo del práctico es introducirnos en herramientas que permiten establecer un flujo de trabajo en R. Para ello, aprenderemos cómo abrir un nuevo script y a crear un nuevo proyecto de R (o Rproject). Además, utilizaremos GitHub, que es una plataforma que permite alojar los .Rproj y códigos de cada uno de ustedes. De hecho, tal como mostraremos en el práctico, utilizaremos GitHubClassRoom para que ustedes puedan subir sus tareas.\nPrevio a esto, deben ver el Tutorial de instalación de R.\nAhora aprenderemos a crear scripts, proyectos, colaborar y resolver las tareas.\n1. Crear un nuevo script (.R) Para que empecemos a trabajar en el lenguaje R, lo primero es saber cómo abrir un nuevo script; pero ¡¿qué es un script?! Dicho en términos simples, el script es la \u0026ldquo;hoja\u0026rdquo; sobre la cual escribiremos y guardaremos cada uno de los códigos que trabajemos cuando estemos trabajando con datos cuantitativos. Si bien podemos ejecutar los códigos directamente desde la consola, estos se eliminarán una vez que cerremos la sesión en RStudio:\nAsí, cuando escribamos en nuestro script, podremos archivar los códigos que vayamos ejecutando, para poder reproducirlos posteriormente, compartirlos con otras personas, entre otros. Ahora, lo que nos convoca: ¿cómo puedo abrir un nuevo script?\nHacerlo es bastante sencillo. En la sección superior izquierda de RStudio, debe hacerse click en la hoja con un signo + verde y, luego, seleccionar la opción R Script en el menú desplegado:\nOtra manera de abrir un nuevo script es hacer click en la opción File de la barra superior\npara, posteriormente seleccionar New File \u0026gt; R Script en los menús desplegados:\nPor último, podemos mantener presionadas las teclas Ctrl + Shift + N en Windows, o ⌘ + Shift + N en Mac.\nYa hemos abierto un nuevo script (¡Genial!), que se debe ver de la siguiente manera:\nPodemos escribir en él los códigos, que se ejecutarán en la consola una vez mantengamos presionadas las teclas Control + Enter al inicio de la línea\nAhora, por supuesto, debemos guardar nuestro script una vez terminemos de trabajar en él, a modo de no perder el trabajo avanzado. Para ello, podemos hacer click en el disquete situado en la barra que se encuentra sobre el código\nPara luego, elegir el directorio donde deseamos almacenar nuestro script, y asignarle un nombre determinado (en este caso script1) que, ojalá, tenga que ver con los procedimientos ejecutados en este (por ejemplo, procesamiento o análisis). La extensión de los archivos que almacenan scripts es .R (¡no lo olvides!)\nUna vez almacenado en una carpeta, cada vez que clickeemos en los casetes o mantengamos presionadas las teclas Control + S, el archivo se actualizará a la última versión que hayamos guardado.\n2. Crear un nuevo proyecto de R (.Rproj) ¡Todavía nos falta algo para iniciarnos en el flujo de trabajo del curso! debemos crear un nuevo Proyecto de R o R Project (.Rproj). ¿Qué es esto, se preguntarán ustedes? en pocas palabras, será la semilla de nuestra carpeta de trabajo, es decir, constituye el centro a partir del cual estaremos trabajando el resto de archivos incluidos en nuestro trabajo con los datos, como los scripts, los datos con los que trabajamos, los gráficos que generaremos durante el análisis, y todo aquello vinculado a los procesos que ejecutemos en un trabajo en específico. A lo largo del curso aprenderemos a trabajar adecuadamente con los .Rproj, manteniendo un flujo de trabajo que facilita la reproductibilidad de los procesos con los que aprenderemos los contenidos, así como de las tareas que ustedes rendirán durante el semestre. Sin embargo, ahora nos limitaremos a aprender a crear un nuevo proyecto.\n¿Cómo lo hacemos? Es bastante sencillo, y se asemeja a la creación de scripts. No obstante, esta vez nos dirigiremos a la sección superior derecha de RStudio, donde se encuentra una R inscrita a un cubo\nHaremos click en ella, y se desplegará un panel con opciones. Clickearemos en New Project\u0026hellip;\nEmergerá una ventana que nos preguntará en qué carpeta queremos alojar nuestro nuevo proyecto. Podemos elegir crear una nueva carpeta haciendo click en New Directory, o elegir una carpeta ya existente en nuestro computador, clickeando en Existing Directory\nSi optamos por lo primero, se nos preguntará qué tipo de proyecto deseamos crear. En este caso, elegiremos New Project\nAparecerá una ventana que nos pregunta el nombre que queremos asignarle a la nueva carpeta que crearemos, y en qué carpeta se alojará esta. Si hacemos click en Browse, podemos buscar un directorio específico en el cual queramos alojar la nueva carpeta\nEn caso de elegir lo segundo, se nos solicitará directamente en qué carpeta (ya existente) queremos alojar nuestro proyecto. Una vez más, podemos utilizar Browse para navegar entre las carpetas de nuestro computador, hasta hallar aquella en que deseamos alojar este nuevo archivo\n¡Listo! ahora sólo debemos ir a nuestra carpeta y buscar el proyecto que hemos creado. Es un archivo de extensión .Rproj, cuyo ícono es una R inscrita en un cubo.\nEs fundamental que, de aquí en adelante, siempre que vayamos a trabajar en alguna tarea con R, creemos el nuevo proyecto y lo abramos para empezar a trabajar. Ello setearé nuestro directorio de trabajo directamente en la carpeta donde se encuentra el archivo .Rproj, lo cual nos permitirá trabajar colaborativamente con mayor facilidad (¡algo fundamental en el curso!). Además, cada vez que vayamos a retomar nuestro trabajo en algún proyecto, debemos siempre abrir el proyecto antes que cualquier cosa, para lo cual debemos hacer doble click sobre su ícono.\n3. GitHub Es un sistema de control de versiones en línea que rastrea los cambios de códigos, facilita la colaboración y el acceso abierto. En este curso será un programa esencial para el desarrollo tanto de clases como prácticos, por lo que vamos a aprender a utilizarlo repasando aspectos básicos. Esto además será profundizado y detallado en clases.\nVentajas: Las principales ventajas son:\n  Facilita el flujo del trabajo y la colaboración entre usuarios\n  Es de acceso abierto\n  Permite hacer seguimiento a los errores\n  Tiene variedades de funciones y plataformas\n  No obstante, la plataforma central en el curso será GitHub Classroom\n4. Github Classroom Es una plataforma de Github que facilita la interacción y aprendizaje entre estudiantes y profesores. Utilizaremos esta plataforma a lo largo del curso, principalmente porque permite que las y los estudiantes trabajen individual y colectivamente usando los repositorios de Github. En esta plataforma entregarán sus tareas, recibirán comentarios y retroalimentaciones pudiendo trabajar colaborativamente.\n Pasos para ingresar a Github classroom    Crear cuenta:\n  Dirigirse al Link\n   Clickear en “Crea una cuenta”\n  Introduce tu correo electrónico\n  Crea una contraseña\n  Introduce el nombre de usuario (similar a su nombre)\n  Clickear en Crear una cuenta\n   Ve al correo electrónico que pusiste anteriormente\n  Copia el código e introdúcelo en la página\n  Recuerda que el correo que uses debe ser el mismo correo que usaste en pasos anteriores. Ver tutorial 1.\r\r3. Github Desktop Esta es una aplicación que permite trabajar los repositorios de Github en los computadores, de forma local e intuitiva, facilitando la coordinación entre las modificaciones realizadas a nivel local y en la plataforma web. Para utilizarlo, debemos\na. Instalar Github Desktop\nb. Dirigirse a Link\nc. Crear una carpeta para los contenidos del curso\nd. Vincular la dirección de la carpeta\nPara Windows   Clickear en Download for Windows (64bit)\n  Ejecutar el archivo descargado\n  Introduce tu usuario y contraseña\n  Para Mac   Clickear en Download for macOS\n  Ejecutar el archivo descargado\n  Introduce tu usuario y contraseña\n  \r4. Botones principales en GitHub Desktop:   Clone repository: Copia un repositorio a tu computador\n  Create new repository: crea un nuevo repositorio\n  Add existing repository: incorpora un repositorio existente\n    Open the repository in Rstudio: Abre todo el proyecto en RStudio\n  View the files of your repository in explorer: Muestra los archivos en la carpeta que se encuentra\n  Open the repository on Github: abre el repositorio en la página\n  Commit to master: forma de guardar los cambios\n  Push origin: manda los cambios al repositorio en línea\n  5. Conceptos claves de Github   Repositorios: Es donde se alberga el trabajo; una carpeta que contiene todos los archivos y el historial de cambios realizados. Estos se almacenan en la nube.\n  Cloning: Los repositorios pueden clonarse creando copias locales que extraen toda la información y antiguas versiones del repositorio. Posteriormente podemos modificar los archivos del repositorio clonado, para sincronizar la copia local con la copia en Github.\n  Commit: Es la forma de guardar el estado de tu proyecto, como una captura en la que se deja un mensaje informativo.\n  Push: Esta es la forma en la que se puede incorporar (subir) los cambios locales al repositorio de Github.\n  README: Se utiliza a modo de presentación o introducción de los repositorios.\n  Pull: Esta es la forma en la que se puede sincronizar (bajar) los cambios del repositorio de Github al repositorio local.\n  Flujo de trabajo colectivo y de acceso abierto   Forks: Es otra forma de copiar un repositorio, permitiendo hacer cambios sin afectar al proyecto original.\n  Pull requests: Es una forma de solicitar que sean incorporados los cambios que has hecho desde un repositorio local, al repositorio original.\n  6. GitHub Class Room del curso (learn-R-UAH) Pasos para las dinámicas del curso\n6.1 Recibir una tarea 6.2 Ingresa el link a. El link contiene la tarea, ustedes deben aceptar la tarea la cual creará un repositorio que contendrá la información y las instrucciones de la tarea.\nb. Para eso deben ir a GitHub Desktop, clonar el respositorio desde internet.\nc. Luego deben escoger el repositorio de la tarea, escoger la carpeta en la que se encontrará y clonarlo\nd. Después deben abrir el repositorio creado a través de RStudio, ahí verán el mismo contenido pero en un archivo .md\n6.3 Resolver una tarea a. Ahora resolveremos la Tarea 0 en conjunto, una vez abierto el repositorio clonado. Recuerden que es en este repositorio donde deben completar y subir la tarea\nb. La tarea se encuentra en un archivo llamado *README* con información de los conceptos básicos y el flujo de GitHub, deben leerlo detalladamente.\nc. Una vez leido deberán ir al final del archivo en Tarea 0 y responder las preguntas correspondientes\n6.4 Tarea 0 ¡Puedes ver las instrucciones de la tarea en el siguiente link o en GitHub Class Room\n6.5 Subir una tarea a. Una vez listo, deberán subir la tarea al repositorio remoto a través de GitHub Desktop\n6.6 Recibir comentarios a. Les llegará un correo con los comentarios y retroalimentación de su tarea\n7. Video tutorial en Youtube Recuerden que el video de asociado a este práctico y muchos más podrán encontrarlos en el canal de youtube del curso\n\r\r","date":1628467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628467200,"objectID":"63ac3bb2c13d1c040f2504a8ef534581","permalink":"/example/03-practico/","publishdate":"2021-08-09T00:00:00Z","relpermalink":"/example/03-practico/","section":"example","summary":"0. Objetivo del práctico El objetivo del práctico es introducirnos en herramientas que permiten establecer un flujo de trabajo en R. Para ello, aprenderemos cómo abrir un nuevo script y a crear un nuevo proyecto de R (o Rproject).","tags":null,"title":"Bienvenido/a a R, RStudio y Github","type":"docs"},{"authors":null,"categories":null,"content":"\r\rPauta proyecto de investigación, examen del curso\rEl objetivo central del proyecto de investigación es analizar un fenómeno que consideran de interés y que puede ser trabajado desde la información disponible en bases de datos. El centro de su trabajo, no obstante, es el análisis de datos mediante modelos de regresión lineal utilizando los softwares R y RStudio. Este trabajo debe ser entregado el martes 27 de junio hasta las 23:59 hrs.\nSe deben construir al menos dos regresiones lineales múltiples y compararlas entre sí. El foco debe estar en considerar el ajuste de ambos modelos y sus errores de especificación. Por ejemplo, incluir en un modelo variables irrelevantes u omitir variables relevantes. A partir de aquello, realizar test de significancia estadística para cada coeficiente y de manera global.\nLa aplicación de transformaciones funcionales (logarítmica, cuadrática o efectos de interacción) y el chequeo de los supuestos de regresión no son obligatorios, pero de realizarse, tendrán una bonificación de puntaje.\nA partir de su análisis, deben redactar un informe que contenga los siguientes apartados:\n1. Título\rEl título debe ser breve y referir a la temática escogida.\n\r2. Introducción (800-1000 palabras)\rDefinir la temática escogida, explicar por qué es relevante su estudio y presentar sus conceptos principales, además de definirlos. Estos deben ahondar el objeto de estudio (su origen, definición e investigaciones principales) además de los posibles factores que explican al objeto. Se debe considerar al menos 1 referencia bibliográfica por cada uno de los factores.\n\r3. Objetivo general e hipótesis (300 palabras)\r3.1. Objetivo general (50 palabras)\rEsclarecer la relación entre los conceptos, distinguiendo entre variable dependiente y variables independientes. El objetivo general se formula utilizando un verbo en infinitivo, identifica en su formulación un objeto de estudio, sujetos de estudio y el espacio y tiempo del fenómeno estudiado.\n\r3.2. Hipótesis (250 palabras)\rElaborar una hipótesis por cada variable independiente relacionándola con la variable dependiente. Considerar el sentido y magnitud de la relación.\n\r\r6. Metodología (400 palabras)\r6.1. Datos\rIdentificar la población de estudio, la muestra utilizada y el número de casos. Se debe explicitar el(los) tema(s) del que trata la encuesta seleccionada, así como la institución u organismo que produjo los datos. Además, el objetivo general de la encuesta seleccionada y el año de publicación o levantamiento de los datos.\n\r6.2. Variables\rIdentificar la selección de variables dependiente (cuantitativa) e independientes (cuantitativas o categóricas, mínimo 3).\n\r6.3. Métodos utilizados\rDescribir brevemente el método de regresión utilizado.\n\r\r7. Análisis (máximo 1500 palabras)\r7.1. Análisis descriptivos\rExponer e interpretar brevemente las principales medidas de tendencia central (media, moda o mediana) de cada una de las variables seleccionadas.\n\r7.2. Modelos de regresión\rPresentar los modelos de regresión realizados mediante una tabla en formato APA (la que trabajamos en los prácticos).\nPara cada modelo, interpretar sus coeficientes en cuanto a su magnitud como también de significancia estadística y ajuste global del modelo (\\(R^2\\)). Se debe hacer referencia a cada hipótesis al momento de analizar los coeficientes, además de indicar cuál modelo presenta mayor bondad de ajuste.\n\r\r8. Conclusiones (350 palabras)\rResumir sus resultados principales enfatizando en la relación entre variable dependiente y variables independientes. Señalar limitaciones del estudio y proponer investigaciones sobre la temática hacia el futuro.\n\r9. Referencias\rListado de bibliografía utilizada en formato APA.\n\r10. Formato\r\rArchivo .pdf en tamaño carta\rFuente Times New Roman, tamaño 12, interlineado 1,5 y márgenes normales (2,5 cm * superior e inferior, 3 cm derecho e izquierdo)\rIncluir páginas de portada e índice\rCódigos separados de procesamiento y análisis en formato .R.\rBase de datos utilizada.\r\r\r\r","date":1622332800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622332800,"objectID":"7968e0b2a9740f1f103e20d8ac323ea4","permalink":"/example/14-practico/","publishdate":"2021-05-30T00:00:00Z","relpermalink":"/example/14-practico/","section":"example","summary":"Pauta proyecto de investigación, examen del curso\rEl objetivo central del proyecto de investigación es analizar un fenómeno que consideran de interés y que puede ser trabajado desde la información disponible en bases de datos.","tags":null,"title":"Pauta proyecto de investigación","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo del práctico\rEl objetivo de este práctico es aprender a generar e interpretar modelos con términos de interacción entre variables explicativas con lm().\nMateriales de la sesión\rTal como en la sesión anterior, en este práctico se utilizarán los datos sobre precios de casas utilizados en el libro Introducción a la econometría de J.W. Wooldridge (2015). En este caso, cargaremos los datos ya procesados. Asimismo, la realización de este práctico requiere la carga de diversos paquetes que nos permitirán explorar los datos y presentar los modelos estimados.\nif (!require(\u0026quot;pacman\u0026quot;)) install.packages(\u0026quot;pacman\u0026quot;) # Instalamos pacman en caso de necesitarlo\r## Loading required package: pacman\rpacman::p_load(wooldridge, #Para descargar los datos\rdplyr, #Para procesar datos\rggplot2,#Para graficar\rsjmisc, #Para explorar los datos\rsjPlot, #Para explorar los datos\rtexreg) #Para presentar el modelo de regresión estimado\rdata(\u0026quot;attend\u0026quot;)#Cargamos datos\r\r\r1. Explorando los datos\rEsta vez trabajaremos con los datos hprice2 sobre precio mediano de las casas. En específico, utilizaremos las variables\nVolvemos a encontrarnos con:\n\rprice (\\(y\\)): indica el precio mediano de las casas del barrio.\rlowstat (\\(x_1\\)): indica el porcentaje de personas de bajo estatus socioeconómico del barrio.\rproptax (\\(x_2\\)): indica el impuesto a la propiedad por cada $1000.\rrooms (\\(x_3\\)): indica el número medio de habitaciones de las casas del barrio.\r\rGeneremos el modelo con lm(), y visualicémoslo\nm1 = lm(lprice ~ lowstat + rooms + proptax, data = hprice2)\rscreenreg(m1, custom.model.names = \u0026quot;Modelo 1\u0026quot;)\r## ## =======================\r## Modelo 1 ## -----------------------\r## (Intercept) 9.62 ***\r## (0.13) ## lowstat -0.03 ***\r## (0.00) ## rooms 0.15 ***\r## (0.02) ## proptax -0.01 ***\r## (0.00) ## -----------------------\r## R^2 0.69 ## Adj. R^2 0.69 ## Num. obs. 506 ## =======================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rPodemos ver que todas las variables explicativas tienen un efecto significativo sobre los precio mediano de las casas. Además, el efecto de todas las variables sobre los precio mediano de las casas es negativo, salvo el el del número de habitaciones.\n\r2. Relaciones no lineales y efectos de interacción entre predictores\rLo anterior puede deberse a que, en algunas ocasiones, el efecto parcial, la elasticidad o la semielasticidad de la variable dependiente respecto de una variable explicativa depende de la magnitud de una tercera variable explicativa. A ello se le denomina estimar efectos de interacción. En términos de código con lm(), lo que debemos realizar para incorporar un efecto de interacción en la estimación del modelo es “multiplicar” los predictores, utilizando el signo __*__. Por ejemplo:\nm2 = lm(lprice ~ lowstat + rooms*proptax, data = hprice2)\rscreenreg(list(m1, m2), custom.model.names = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;))\r## ## =====================================\r## Modelo 1 Modelo 2 ## -------------------------------------\r## (Intercept) 9.62 *** 8.18 ***\r## (0.13) (0.25) ## lowstat -0.03 *** -0.03 ***\r## (0.00) (0.00) ## rooms 0.15 *** 0.37 ***\r## (0.02) (0.04) ## proptax -0.01 *** 0.03 ***\r## (0.00) (0.01) ## rooms:proptax -0.01 ***\r## (0.00) ## -------------------------------------\r## R^2 0.69 0.72 ## Adj. R^2 0.69 0.72 ## Num. obs. 506 506 ## =====================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rEn este caso, el modelo con interacción presenta una bondad de ajuste mayor en 3 décimas a la del modelo sin efectos de interacción. Sin embargo, los coeficientes estimados para \\(proptax\\) y \\(rooms\\) son distintos. Por último, podemos notar que el modelo 2 presenta un coeficiente extra: \\(proptax:rooms\\), que representa el efecto de interacción entre ambas variables. Otra cosa interesante es que el efecto de \\(proptax\\) pasa de ser negativo a positivo.\nEste modelo se formula matemáticamente de la siguiente manera\n\\[\r\\begin{equation}\rprice = \\beta_0 + \\beta_1lowstat + \\beta_2rooms + \\beta_3rooms*proptax + \\beta_4proptax\r\\end{equation}\r\\]\nAsí, si queremos calcular el efecto parcial de \\(proptax\\) sobre \\(price\\), ceteris paribus, lo hemos de hacer de la siguiente manera\n\\[\r\\begin{equation}\r\\frac{\\vartriangle price}{\\vartriangle proptax} = \\beta_2 + \\beta_3rooms\r\\end{equation}\r\\]\nEn este caso, \\(\\beta_3=-0.01\u0026lt;0\\); o sea, negativo y más bien bajo en magnitud, aunque significativo en términos estadísticos. En términos analíticos, esto implica que, en barrios con más habitaciones en promedio, un aumento en los impuestos a la propiedad tiende a aumentar en menor proporción el precio mediano de las casas que en barrios con menor número de habitaciones por casa en promedio. Es decir, existe un efecto de interacción (aunque bajo en magnitud) entre el impuesto a la propiedad y el número de habitaciones sobre el precio mediano de las casas de diversos barrios.\nPara hacer la comparación, debemos escoger valores útiles de \\(rooms\\), como su mediana o media. Esto, pues _2 indica el efecto promedio del impuesto a la propiedad sobre el precio mediano de las casas de determinado barrio, cuando el número medio de habitaciones por casa en ese barrio es cero, lo cual no tiene sentido. Debemos recurrir a la siguiente re-parametrización\n\\[\r\\begin{equation}\rprice = \\beta_0 + \\beta_1lowstat + \\beta_2proptax + \\beta_3(proptax-\\bar{proptax})(rooms-\\bar{rooms}) + \\beta_4rooms\r\\end{equation}\r\\]\nEllo indica que, al estimar el efecto parcial de \\(proptax\\) sobre \\(price\\), lo haremos en la media de \\(rooms\\), y vice-versa. En este caso, la media de \\(rooms\\) es 6.2840514, de modo que el efecto de \\(proptax\\) sobre \\(price\\) para barrios con casas que cuentan, como media, con 6.28 habitaciones, sería\n\\[\r\\begin{equation}\rprice = 0.03*-0.01(6.28) = -0.001884,\r\\end{equation}\r\\]\nlo cual es, por supuesto, un efecto relativamente bajo y cercano a cero.\n\r3. Interacción numérico*categórico\r¿Qué pasa si nuestro predictor es categórico? Creemos las variables \\(mlowstat\\) y \\(mrooms\\), que indicarán si los valores de \\(lowstat\\) y \\(rooms\\) son superiores o no a su media\nhprice2$mlowstat = ifelse(hprice2$lowstat \u0026gt; mean(hprice2$lowstat), 1, 0)\rhprice2$mrooms = ifelse(hprice2$rooms \u0026gt; mean(hprice2$rooms), 1, 0)\rAhora estimemos el modelo con estas variables como predictores\nm3 = lm(lprice ~ mlowstat + rooms + proptax, data = hprice2)\rscreenreg(list(m1, m2, m3), custom.model.names = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;))\r## ## =================================================\r## Modelo 1 Modelo 2 Modelo 3 ## -------------------------------------------------\r## (Intercept) 9.62 *** 8.18 *** 8.86 ***\r## (0.13) (0.25) (0.12) ## lowstat -0.03 *** -0.03 *** ## (0.00) (0.00) ## rooms 0.15 *** 0.37 *** 0.23 ***\r## (0.02) (0.04) (0.02) ## proptax -0.01 *** 0.03 *** -0.01 ***\r## (0.00) (0.01) (0.00) ## rooms:proptax -0.01 *** ## (0.00) ## mlowstat -0.27 ***\r## (0.03) ## -------------------------------------------------\r## R^2 0.69 0.72 0.62 ## Adj. R^2 0.69 0.72 0.62 ## Num. obs. 506 506 506 ## =================================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rAhora, generemos un modelo que estime el efecto de interacción entre \\(mlowstat\\) y \\(rooms\\) sobre \\(price\\):\nm4 = lm(lprice ~ mlowstat*proptax + mrooms, data = hprice2)\rscreenreg(list(m3, m4), custom.model.names = c(\u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;))\r## ## ========================================\r## Modelo 3 Modelo 4 ## ----------------------------------------\r## (Intercept) 8.86 *** 10.06 ***\r## (0.12) (0.05) ## mlowstat -0.27 *** 0.12 ## (0.03) (0.08) ## rooms 0.23 *** ## (0.02) ## proptax -0.01 *** -0.00 ## (0.00) (0.00) ## mrooms 0.23 ***\r## (0.03) ## mlowstat:proptax -0.01 ***\r## (0.00) ## ----------------------------------------\r## R^2 0.62 0.57 ## Adj. R^2 0.62 0.57 ## Num. obs. 506 506 ## ========================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rEn este caso, \\(\\beta_{mlowstat:proptax} = -0.19 \u0026lt; 0\\). Ello indica que, en barrios cuyo porcentaje de personas de bajo estatus socioeconómico se encuentra por sobre la media, un mayor impuesto a la propiedad en cada barrio indica un aumento más bajo en los precios medianos de las casas de cada barrio.\n\r4. Interacción categórico*categórico\rPor último, revisemos qué pasa cuando estimamos un efecto de interacción de dos variables categóricas\nm5 = lm(lprice ~ mlowstat*mrooms + proptax, data = hprice2)\rscreenreg(list(m3, m4, m5), custom.model.names = c(\u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;, \u0026quot;Modelo 5\u0026quot;))\r## ## ====================================================\r## Modelo 3 Modelo 4 Modelo 5 ## ----------------------------------------------------\r## (Intercept) 8.86 *** 10.06 *** 10.22 ***\r## (0.12) (0.05) (0.04) ## mlowstat -0.27 *** 0.12 -0.24 ***\r## (0.03) (0.08) (0.04) ## rooms 0.23 *** ## (0.02) ## proptax -0.01 *** -0.00 -0.01 ***\r## (0.00) (0.00) (0.00) ## mrooms 0.23 *** 0.29 ***\r## (0.03) (0.03) ## mlowstat:proptax -0.01 *** ## (0.00) ## mlowstat:mrooms -0.27 ***\r## (0.06) ## ----------------------------------------------------\r## R^2 0.62 0.57 0.56 ## Adj. R^2 0.62 0.57 0.56 ## Num. obs. 506 506 506 ## ====================================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rEn este último caso, \\(\\beta_{mlowstat:mrooms} = -0.27 \u0026lt; 0\\). De ese modo, es posible señalar que, en barrios donde el porcentaje de personas de bajo estatus socioeconómico es superior a la media, el precio mediano de las casas aumenta menos en caso de que la media de habitaciones por casa sea mayor al promedio.\n\rResumen\rEn este práctico aprendimos cómo estimar y analizar modelos de regresión lineal con términos de interacción entre predictores.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d75332e5c297ce54c2c4700c91a529e1","permalink":"/example/10-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/10-practico/","section":"example","summary":"0. Objetivo del práctico\rEl objetivo de este práctico es aprender a generar e interpretar modelos con términos de interacción entre variables explicativas con lm().\nMateriales de la sesión\rTal como en la sesión anterior, en este práctico se utilizarán los datos sobre precios de casas utilizados en el libro Introducción a la econometría de J.","tags":null,"title":"Relaciones no lineales y términos de interacción","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo\rEl objetivo de este práctico es aprender cómo analizar el cumplimiento de supuestos de regresión lineal con performance.\n\r1. Paquetes y datos a utilizar\rEn este caso utilizaremos diversos paquetes, entre los cuales el más relevante será performance, que se utilizará para evaluar la calidad de los modelos estimados. Utilizaremos los datos sobre precios medianos de casas del paquete wooldridge.\npacman::p_load(wooldridge, #Para descargar los datos\rsummarytools, #decriptivos\rsjPlot, #visualización\rperformance, #evaluación de modelos\rlmtest, #Para el test RESET de Ramsey\rsee) # herramientas para la visualización\roptions(scipen=999)\rdata(\u0026quot;hprice2\u0026quot;)\r\r2. El ajuste y la calidad de los modelos de regresión lineal\rEn prácticos anteriores hemos revisado diversas maneras de abordar el ajuste y la calidad de los modelos que estimamos. En el fondo, estadístico como \\(R^2\\), \\(F\\), \\(p-valores\\), entre otros, entregan información acerca de qué tan bien explica nuestro modelo la variabilidad de \\(y\\).\nNo obstante, como hemos revisado a lo largo del curso, para poder asegurar la calidad y robustez de los modelos de regresión lineal que estimamos, debemos demostrar que esto cumplimen con algunos supuestos fundamentales. En este práctico utilizaremos el paquete performance y sus diversas funciones para aprender cómo chequear, comprender y analizar estos supuestos.\nA lo largo de este práctico analizaremos el siguiente modelo\nmod = lm(lprice ~ crime + rooms + stratio + lowstat ,data = hprice2)\rsummary(mod)\r## ## Call:\r## lm(formula = lprice ~ crime + rooms + stratio + lowstat, data = hprice2)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.68869 -0.11254 -0.02062 0.10091 0.92711 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 10.152054 0.161954 62.685 \u0026lt; 0.0000000000000002 ***\r## crime -0.009718 0.001253 -7.754 0.000000000000050 ***\r## rooms 0.127981 0.017370 7.368 0.000000000000719 ***\r## stratio -0.033592 0.004840 -6.940 0.000000000012148 ***\r## lowstat -0.028348 0.001818 -15.589 \u0026lt; 0.0000000000000002 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.2127 on 501 degrees of freedom\r## Multiple R-squared: 0.7319, Adjusted R-squared: 0.7298 ## F-statistic: 342 on 4 and 501 DF, p-value: \u0026lt; 0.00000000000000022\rPodemos ver que todos los coeficientes estimados son estadísticamente significativos. Asimismo, salvo \\(rooms\\), el efecto de todo el resto de variables explicativas sobre los precios medianos de las casas de los barrios analizados es negativo. El estadístico \\(R^2\\) se aproxima a \\(0.73\\), y el estadístico \\(F\\) es estadísticamente significativo. De tal modo, es posible demostrar evidencia respecto de la validez estadística de nuestro modelo, así como de su bondad de ajuste. Revisemos ahora el cumplimiento de supuestos del modelo de regresión lineal propuestos por Gauss-Markov (Wooldridge, 2015).\n\r3. Linealidad\rEl primer supuesto es que la regresión especificada es lineal en sus parámetros. Ello quiere decir que se espera que exista una relación lineal entre las variables explicada e explicativas.\nPodemos saber si se cumple este supuesto a partir de un gráfico de dispersión de datos, que relacione ambas variables, y verificar de manera “intuitiva” si la tendencia de esta relación se puede describir por una línea recta. El paquete performace nos permite hacer esto con su función check_model indicando en el argumento check = \"ncv\ncheck_model(mod, check = c(\u0026quot;ncv\u0026quot;, \u0026quot;linearity\u0026quot;))\rEste gráfico presenta la relación entre los valores predichos para \\(y\\) y los residuos estimados. La línea punteada indica cómo debiesen dispersarse los puntos azules (que corresponden a la intersección de los valores predichos y los residuos estimados para cada individuo) en caso de que existiese linealidad. En este caso es posible apreciar que la relación no se aproxima a la linealidad.\nEn caso de que el cumplimiento no sea claro, una forma numérica para chequear este supuesto es que el valor promedio de los residuos sea cero. En este caso, ese valor es igual a 0. Si esto no fuera así, los residuos estarían sesgados sistemáticamente, por lo cual el supuesto de linealidad no se cumpliría. De suceder aquello, el modelo debiese re-especificarse (medir de otra manera la variable) en algún término de la ecuación de regresión al cuadrado o al cubo. Un modo que se ocupa para testear la necesidad de esta re-especificación es el test RESET de Ramsey que indica que:\n\\(H_0\\) cuando el modelo tiene algún término al cuadrado o cubo, la media de los residuos es cero. Es decir: si no podemos rechazar \\(H_0\\), nuestro modelo está bien especificado (es decir, es lineal).\nUtilizaremos resettest de lmtest para comprobar el cumplimiento del test RESET, estimando un \\(p\\)-valor con el cual podremos rechazar la hipótesis nula\nlmtest::resettest(mod)\r## ## RESET test\r## ## data: mod\r## RESET = 28.484, df1 = 2, df2 = 499, p-value = 0.000000000001933\rAquí podemos ver que no podemos rechazar \\(H_0\\), por lo cual debiésemos re-especificar el modelo.\n\r4. Homocedasticidad\rHomoce ¿qué? Sí, homocedasticidad. Este concepto indica que los residuos se distribuyen de forma homogénea (por eso el sufijo homo). Como ya podrás haber notado este supuesto se vincula con el de linealidad. Y, al igual que este, también puede comprobarse con un gráfico de dispersión entre la variable explicada (\\(y\\)) e explicativa (\\(x\\)), donde podamos ver de manera clara la recta de regresión estimada y la distribución de los residuos. Aceptaremos el supuesto de homocedasticidad si la variación de los residuos es homogénea: es decir, no veremos un patrón claro, sino más bien se distribuirán de forma aleatoria. De manera gráfica veremos una nube de puntos que tiene una forma similar en todo el rango de las observaciones de la variable explicativa.\nPara comprobar el supuesto de homocedasticidad de manera más certera utilizaremos la prueba Breusch-Pagan Godfrey cuya hipótesis nula indica que\n\\(H_0\\): La varianza de los residuos del modelo de regresión no es constante (heterocedasticidad)\nEn este caso, buscaremos que rechazar la \\(H_0\\). Esto implicaría que, “en suma y resta”, si bien hay residuos, estos tienen una variación homogénea en todos los tramos de la relación de la variable explicada con la explicativa.\nA partir de la función check_heteroscedasticity verificaremos qué ocurre con la hipótesis nula\ncheck_heteroscedasticity(mod)\r## Warning: Heteroscedasticity (non-constant error variance) detected (p \u0026lt; .001).\rEn este caso, el test nos indica que la varianza no es homocedástica, por lo cual aceptamos la hipótesis nula de que la varianza de los residuos no es constante.\n\r5. Normalidad de residuos\rAdemás de la linealidad (media 0), la homocedasticidad (varianza mínima y constante), el método de estimación de la regresión lineal (OLS o MCO en español) requiere asegurar una distribución normal de los residuos pues, en caso contrario, el modelo no es consistente a través de las variables y observaciones. Esto significa que los errores no son aleteatorios, sino sistemáticos.\nAl igual que con los otros supuestos, la normalidad de los residuos se puede evaluar con métodos numéricos, utilizando pruebas que ya conocemos de otros cursos como la prueba de Shapiro-Wilk y Kolmogorov-Smirnov\nA partir de la función check_normality utilizaremos la prueba Shapiro-Wilk para ver qué ocurre con la hipótesis nula a\ncheck_normality(mod)\r## Warning: Non-normality of residuals detected (p \u0026lt; .001).\rEn este caso, no podemos rechazar la hipótesis nula de que los residuos no se distribuyen normalmente, por lo cual no podemos afirmar que los errores en nuestras estimación son aleatorios.\n\r6. Independencia\rEvidentemente si los residuos no siguen una distribución normal, es probable que estos no sean independientes entre sí. Esto significa que buscaremos que los errores asociados a nuestro modelo de regresión sean independientes. Para saber si se cumple ese criterio se utiliza la prueba de Durbin-Watson, donde la \\(H_0\\) supone que los residuos son independientes.\nA partir de la función check_autocorrelation utilizaremos la prueba Durbin-Watson para ver qué ocurre con la hipótesis nula a\ncheck_autocorrelation(mod)\r## Warning: Autocorrelated residuals detected (p \u0026lt; .001).\rEl \\(p-valor\\) estimado nos indica que no podemos rechazar la hipótesis nula de que los residuos son independientes.\nEn síntesis, sabemos la regresión lineal requiere de una relación lineal entre sus variables explicativas y explicada. Para ello no solo es importante chequear la distribución de los residuos, sino\rdos posibilidades que pueden tendenciar esa relación lineal: como casos influyentes en la muestra y predictores que están altamente relacionados. Revisaremos la última de estas\n\r7. Multicolinealidad\rLa multicolinealidad es la relación de dependencia lineal fuerte entre más de dos predictores de un modelo.\nEl problema que produce es que será difícil cuantificar con exactitud el efecto de cada predictor sobre la variable explicada, precisamente pues puede ocurrir que el efecto que una variable predictora tenga sobre el fenómeno que se busca estudiar dependa del valor de otra variable del modelo.\nPara la regresión múltiple esto implica un problema, pues suponemos que podemos “controlar” por el otro valor de la variable. Si los predictores están correlacionados fuertemente, entonces el efecto de una variable \\(x_1\\) sobre \\(y\\) estará “contaminado” por el efecto de otra variable \\(x_2\\) sobre \\(y\\), y vice-versa.\nPodemos examinar esta relación endógena entre predictores a partir de la existencia de altas correlaciones (lineales) entre variables. La aproximación numérica más utilizada es el VIF (factor de inflación de varianza), que indica hasta qué punto la varianza de los coeficientes de regresión se debe a la colinealidad (o dependencia) entre otras variables del modelo.\nPara evaluar esto ocuparemos el comando check_collinearity(). Como podemos ver en el gráfico, todos los valores son menores a 5 (como recomienda el paquete).\nplot(check_collinearity(mod))\rAhora bien, dado que sabemos que las correlaciones en ciencias sociales nunca son tan altas, un criterio que se ocupa en nuestras disciplinas para evaluar multicolinealidad es es evitar valores del VIF mayores a 2.5.\ncheck_collinearity(mod)\r## # Check for Multicollinearity\r## ## Low Correlation\r## ## Term VIF Increased SE Tolerance\r## crime 1.29 1.14 0.77\r## rooms 1.66 1.29 0.60\r## stratio 1.23 1.11 0.82\r## lowstat 1.93 1.39 0.52\rLos valores especificados en la columna VIF indican que no existe una fuerte correlación entre las variables explicativas. Para solucionar este problema, se podría eliminar alguno de los predictores problemáticos, o evaluar si es que estas variables más bien son parte de un mismo constructo.\n\r8. Casos influyentes\rUn último supuesto que revisaremos, y es el que probablemente el que más nos enfrentamos en las ciencias sociales, son los casos influyentes (también llamados outliers en inglés). Un ejemplo claro de esto son las variables como ingresos, donde muchas veces tenemos casos extremos con muy bajos salarios y otros muy altos, y que pueden tendenciar nuestras rectas de regresión pese a que no es evidente una relación lineal(o algún tipo de relación) entre la variable explicativa y explicada.\nPara verificar si un caso es influyente, examinaremos si la ausencia o presencia de ese caso genera un cambio importante en la estimación del modelo de regresión. Este enfoque se aborda a partir del cálculo de la Distancia de Cook (Cook,1977)\nPrimero podemos graficar la influencia de los casos con check_outliers() dentro de un plot()\nplot(check_outliers(mod))\rLuego para verificar si la ausencia o presencia de eliminar algunos de estos casos que presentan mayor distancia producen una diferencia significativa en la estimación del modelo, realizamos\ncheck_outliers(mod)\r## OK: No outliers detected.\r✔️ No se detectaron casos atípicos.\n\rResumen\rEn este práctico aprendimos a analizar los supuestos del teorma de Gauss-Markov a través del paquete performance.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2eb3ced2be87a146ca57fc473f2769f8","permalink":"/example/11-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/11-practico/","section":"example","summary":"0. Objetivo\rEl objetivo de este práctico es aprender cómo analizar el cumplimiento de supuestos de regresión lineal con performance.\n\r1. Paquetes y datos a utilizar\rEn este caso utilizaremos diversos paquetes, entre los cuales el más relevante será performance, que se utilizará para evaluar la calidad de los modelos estimados.","tags":null,"title":"Chequeo de supuestos","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo\rLos objetivos de este práctico son\nComprender las distintas fuentes que pueden producir errores de medición en un modelo de regresión lineal.\n\rAprender a procesar las variables analizadas para reducir el error de medida.\n\r\r\r1. Paquetes y datos a utilizar\rUtilizaremos los datos sobre salarios del paquete wooldridge.\npacman::p_load(wooldridge,\rtexreg,\rperformance,\rtidyverse) # Universo de paquetes\roptions(scipen=999)\rdata(\u0026quot;wage1\u0026quot;)\r\r2. El error de medida\rA veces, las variables con las que trabajamos no necesariamente son una medición precisa de los fenómenos que estamos investigando. Cuando esto sucede, los modelos con los cuales buscaremos analizar la relación de diversas variables contendrán un error de medición. Así, podemos estar en presencia de errores de medición tanto en las variables explicativas como en las explicadas.\nTrabajaremos con el siguiente modelo a modo de ejemplo:\nmod = lm(lwage ~ educ+exper+tenure+female, data = wage1)\rscreenreg(mod)\r## ## =======================\r## Model 1 ## -----------------------\r## (Intercept) 0.50 ***\r## (0.10) ## educ 0.09 ***\r## (0.01) ## exper 0.00 ** ## (0.00) ## tenure 0.02 ***\r## (0.00) ## female -0.30 ***\r## (0.04) ## -----------------------\r## R^2 0.39 ## Adj. R^2 0.39 ## Num. obs. 526 ## =======================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\ra) El error de medición en variables explicadas \\(y\\)\rSea \\(y*\\) la variable que se desea explicar para la población. En este caso, serán los salarios por hora wage. Como hemos revisado, este modelo tendría la forma\n\\[\r\\begin{equation}\ry* = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_{k}x_{k} + u,\r\\end{equation}\r\\]\nsuponiendo que satisface los supuestos de Gauss-Markov revisados en clases previas. Sea \\(y\\) el valor observado para los salarios por hora. Es razonable considerar que los informantes no necesariamente reportarán sus salarios por hora con exactitud, pudiendo sobre o subestimarlo al aproximar el valor de su salario a lo largo de su proceso cognitivo de respuesta. En ese caso, podríamos esperar que \\(y \\neq y*\\), al menos en un conjunto de los informantes.\nAsí, el error de medición en la población está definido como la diferencia entre el valor observado y el valor real que adopta la variable\n\\[\r\\begin{equation}\re_{0} = y-y*\r\\end{equation}\r\\]\nLo relevante será analizar cómo el error de medición en la población se asocia con otros factores. La pregunta en este caso sería los años de escolaridad, los años de experiencia laboral, la antiguedad en la empresa o el género están asociados a un sobre o subreporte de los salarios por parte de los informantes. Para un modelo estimable, tenemos que \\(y* = y-e_{0}\\), por lo cual\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_{k}x_{k} + u + e_{0}.\r\\end{equation}\r\\]\nEn esta ecuación, el error es \\(u + e_{0}\\). Como \\(y,x_1, x_2, ..., x_k\\) son observados, podemos estimar el modelo MCO, ignorando el error de medición de \\(y*\\).\nSi el modelo formulado cumple con los supuestos de Gauss-Markov, la media de \\(u=0\\), y no está corrrelacionada con las \\(x_j\\). Podemos suponer, entonces, que la media del error de medición \\(e_0\\) sea igual a 0. De no cumplirse esto, tan sólo estimaríamos un estimador sesgado de \\(\\beta_0\\), lo cual no necesariamente es causa de preocupación. En ese sentido, es más relevante el supuesto sobre la relación entre \\(e_0\\) e \\(x_1, x_2, ..., x_k\\). El supuesto es que el error de medición en \\(y\\) sea estadísticamente independiente de cada una de las variables explicativas incorporadas. De cumplirse esto, entonces los estimadores de MCO son insesgados y consistentes.\nEn caso de que \\(e_0\\) y \\(u\\) no estén correlacionados, entonces \\(Var(u+e_0) = \\sigma_u^2 + \\sigma_0^2 \u0026gt; \\sigma_u^2\\). Ello implica que el error de medición de la variable explicada significa una mayor varianza del error que cuando no existe error de medición. La consecuencia de lo anterior es una mayor varianza en los estimadores de MCO. Lo único que puede hacerse frente a ello es recolectar datos mejores, es decir, con menor error de medición. No obstante, si el error de medición no está asociado con las variables explicativas, entonces la estimación por MCO tiene propiedades adecuadas.\nEn caso de que la variable explicada esté en forma logarítmica \\(log(y*)\\), el error de medición de la ecuación adoptará la forma\n\\[\r\\begin{equation}\rlog(y) = log(y*) + e_0,\r\\end{equation}\r\\]\rlo cual sigue de un error de medición multiplicativo para \\(y\\): \\(y = y*a_0\\), donde \\(a_0\u0026gt;0\\) y \\(e_0 = log(a_0)\\).\nEn síntesis, el error de medición en la variable explicada puede causar un sesgo en MCO, en caso de estar correlacionado de manera sistemática con al menos uno de los predictores. Si este es sólo un error aleatorio asociado únicamente al reporte de los datos, entonces MCO es un método de estimación apropiado, pese a \\(e_0\\).\n\rb) Error de medición en variables explicativas \\(x_j\\)\rEn general, un error de medición en \\(x_j\\) tiende a ser un problema mayor a un error de medición en \\(y\\).\nPara simplificar la explicación, consideremos en modelo simple\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x^*_1 + u,\r\\end{equation}\r\\]\rque satisface al menos los cuatro primeros supuestos de Gauss-Markov, a partir de lo cual podemos suponer que dará estimadores insesgados y consistentes de \\(\\beta_0\\) y \\(\\beta_1\\). No obstante, tenemos que \\(x^*_1\\) no es observada. En su reemplazo, tenemos la medición \\(x_1\\). En este caso, \\(x^*_1\\) será el ingreso por hora real, y \\(x_1\\) el ingreso por hora reportado por los informantes. El error de medición sería\n\\[\r\\begin{equation}\re_1 = x_1 - x^*_1,\r\\end{equation}\r\\]\npudiendo adoptar valores positivos y negativos además del cero. Suponemos que, en la población, la media del error de medición es cero: \\(E(e_1) = 0\\). Asimismo, suponemos que \\(u\\) no está correlacionado con \\(x^*_1\\) ni \\(x_1\\). O sea, \\(E(y|x^*_1,x_1) = E(y|x^*_1)\\): \\(x_1\\) no afecta a \\(y\\) cuando controlamos por \\(x^*_1\\).\nCuando sustituimos \\(x^*_1\\) por \\(x_1\\), y queremos conocer las propiedades de MCO, debemos asumir una serie de supuesto sobre el error de medición. El primero es que \\(e_1\\) no está correlacionado con \\(x_1\\):\n\\[\r\\begin{equation}\rCov(x_1, e_1) = 0.\r\\end{equation}\r\\]\nSi esto es verdadero, entonces \\(e_1\\) debe estar correlacionado con \\(x^*_1\\). Para determinar las propiedades de MCO en este caso, escribimos \\(x^*_1 = x_1 - e_1\\), sustituyéndolo en la ecuación inicial\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x_1 + (u - \\beta_1e_1).\r\\end{equation}\r\\]\nComo suponemos que \\(u\\) y \\(e_1\\) tienen media cero y no están correlacionado con \\(x_1\\), entonces \\((u - \\beta_1e_1)\\) tiene media cero y no está correlacionado con \\(x_1\\). De ello se sigue que nuestra estimación con \\(x_1\\) en lugar de \\(x^*_1\\) produce estimadores consistentes e insesgados para \\(\\beta_1\\) y \\(\\beta_0\\).\nDado que \\(u\\) y \\(e_1\\) no están correlacionados, la varianza del error será \\(Var(u-\\beta_1e_1) = \\sigma^2_u + \\beta^2_1\\sigma^2_{e_1}\\). De ese modo, salvo cuando \\(\\beta_1=0\\), el error de medición aumentará la varianza del error. Esto no afecta a las propiedades de MCO, salvo que las varianzas de \\(\\hat\\beta_j\\) sean mayores que si \\(x_1 = x^*_1\\).\nPor otra parte, el supuesto de errores clásicos en las variables (ECV) es que no existe correlación entre el error de medición y la variable explicativa no observada\n\\[\r\\begin{equation}\rCov(x^*_1, e_1) = 0,\r\\end{equation}\r\\]\rlo cual proviene de expresar la medición observada como la suma de su parámetro y el error de medición:\n\\[\r\\begin{equation}\rx_1 = x^*_1 + e_1.\r\\end{equation}\r\\]\nSi ello se satisface, entonces \\(x_1\\) y \\(e_1\\) deben estar correlacionadas\n\\[\r\\begin{equation}\rCov(x_1, e_1) = E(x_1e_1) = E(x^*_1e_1) + E(e^2_1) = 0 + \\sigma^2_{e_1} = \\sigma^2_{e_1}.\r\\end{equation}\r\\]\nDe este modo, bajo el supuesto ECV, la covarianza entre \\(x_1\\) y \\(e_1\\) es igual a la varianza del error de medición. De ese modo, una correlación entre \\(x_1\\) y \\(e_1\\) generará problemas. Como \\(u\\) y \\(x_1\\) no están correlacionados, la covarianza entre \\(x_1\\) y el error compuesto \\(u - \\beta_1e_1\\) es\n\\[\r\\begin{equation}\rCov(x_1, u-\\beta_1e_1) = -\\beta_1Cov(x_1, e_1) = -\\beta_1\\sigma^2_{e_1}.\r\\end{equation}\r\\]\nAsí, en el caso de ECV, la regresión MCO de \\(y\\) sobre \\(x_1\\) da un estimador sesgado e inconsistente. Podemos estimar la magnitud de la inconsistencia de la siguiente forma:\n\\[\r\\begin{equation}\r\\begin{aligned}\rplim(\\hat\\beta_1) = \\beta_1 + \\frac{Cov(x_1, u-\\beta_1e_1)}{Var(x_1)} \\\\\r= \\beta_1 - \\frac{\\beta_1\\sigma^2_{e_1}}{\\sigma^2_{x^*_1} + \\sigma^2_{e_1}} \\\\\r= \\beta_1(1-\\frac{\\sigma^2_{e_1}}{\\sigma^2_{x^*_1} + \\sigma^2_{e_1}}) \\\\\r=\\beta_1(\\frac{\\sigma^2_{x^*_1}}{\\sigma^2_{x^*_1} + \\sigma^2_{e_1}})\r\\end{aligned}\r\\end{equation}\r\\]\nDe ello podemos desprender dos elementos:\n\\(\\frac{Var(x^*_1)}{Var(x_1)}\\) es siempre menor a uno, por lo que plim\\((\\hat\\beta_1)\\) se encuentra más cercano a cero que \\(\\beta_1\\). A ello se le denomina sesgo de atenuación en MCO: en promedio, el efecto estimado será atenuado. Por ejemplo, si \\(\\beta_1\u0026gt;0\\), tenderá a subestimarlo.\n\rSi la varianza de \\(x^*_1\\) es grande en relación con la varianza del error de medición, la inconsistencia de MCO será pequeña, pues \\(\\frac{Var(x^*_1)}{Var(x_1)}\\) tendrá un valor cercano a 1 cuando \\(\\frac{\\sigma^2_{x^*_1}}{\\sigma^2_{e_1}}\\) es grande.\n\r\rTodo se complica cuando trabajamos con modelos múltiples. Consideremos el modelo ilustrativo\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x^*_1 + \\beta_2x_2 + \\beta_{3}x_{3} + u,\r\\end{equation}\r\\]\ndonde la primera variable se ha medido con error. Suponemos que no eixste correlación entre \\(e_1\\) y \\(x_2\\) y \\(x_3\\). Lo relevante es saber si \\(e_1\\) está correlacionado con \\(x_1\\). De ser así, la regresión MCO genera estimadores consistentes. Esto es más sencillo escribiendo\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_{3}x_{3} + u - \\beta_1e_1,\r\\end{equation}\r\\]\ndonde \\(u\\) ni \\(e_1\\) están relacionados con ningún predictor. Siguiendo el supuesto ECV, MCO será sesgado e inconsistente cuando \\(e_1\\) esté correlacionado con \\(x_1\\), lo cual tiene como consecuencia que todos los estimadores \\(\\beta_k\\) serán sesgados.\nEl error de medición puede presentarse en más de una variable explicativa. Lo esperable es que no exista una correlación entre el error de medición \\(e_1\\) y el valor real \\(x^*_1\\). Por ejemplo, que no exista una correlación entre el valor real de años de escolaridad y el error de medición asociado.\nEn síntesis, debemos situarnos en un punto intermedio, de modo que MCO será inconsistente en caso de que \\(e_1\\) esté correlacionado con \\(x^*_1\\) o \\(x_1\\).\n\r\r3. Solucionando los problemas ocasionados por el error de medida\rEl problema del error de medición puede ser considerado como un problema de datos. Además, si \\(x_1\\) está correlacionada con \\(u - \\beta_1e_1\\), se violan los supuestos de Gauss-Markov. Por su parte, la multicolinealidad o correlación entre variables explicativas no viola ningún supuesto. Ahora revisaremos algunos de los problemas clásicos que pueden dificultar el cumplimiento del teorema de Gauss-Markov, y cómo solucionarlos.\na) Datos faltantes\rEs posible que, para alguna de nuestras observaciones, no tengamos algún dato en alguna variable de interés. Por ejemplo, podría suceder que las personas no declaren sus ingresos, por la falta de confianza que existe para entregar información sensible. De ser así, no podemos emplear esta observación en un análisis de regresión múltiple. Por ello, en la mayoría de los casos, ignoraremos las observaciones con ausencia en variables de interés.\nSin embargo, existen maneras de recuperar casos perdidos. Por ejemplo, para el caso de los ingresos, dado que tiende a ser información sensible para los informantes, se genera una pregunta “salvavidas” con tramos de ingreso, para que las personas se posicionen en alguno de ellos sin necesidad de indicar el monto exacto de sus ingresos.\nLuego, es posible estimar la marca de clase de los intervalos propuestos, a modo de imputar el valor de la marca de clase a quienes no hayan declarado sus ingresos en la variable original. La marca de clase se estima como el promedio de los límites inferior y superior de cada intervalo\n\\[\r\\begin{equation}\rmc = \\frac{LI+LS}{2}\r\\end{equation}\r\\]\n\rb) Ausencia de linealidad\rEn algunos casos, la relación entre nuestras variables explicativa y explicada no es lineal. Ello viola el supuesto de linealidad del teorema Gauss-Markov, revisado en el práctico anterior. En este caso, el test RESET de Ramsey nos indica la necesidad de una re-especificación de los predictores:\nlmtest::resettest(mod)\r## ## RESET test\r## ## data: mod\r## RESET = 7.5488, df1 = 2, df2 = 519, p-value = 0.0005867\rIntentemos generando un modelo con la antiguedad al cuadrado:\nwage1$educ2 = (wage1$educ)^2\rmod2 = lm(lwage ~ educ+educ2+exper+tenure+female, data = wage1)\rscreenreg(list(mod, mod2))\r## ## ===================================\r## Model 1 Model 2 ## -----------------------------------\r## (Intercept) 0.50 *** 1.03 ***\r## (0.10) (0.19) ## educ 0.09 *** -0.01 ## (0.01) (0.03) ## exper 0.00 ** 0.00 ** ## (0.00) (0.00) ## tenure 0.02 *** 0.02 ***\r## (0.00) (0.00) ## female -0.30 *** -0.29 ***\r## (0.04) (0.04) ## educ2 0.00 ** ## (0.00) ## -----------------------------------\r## R^2 0.39 0.40 ## Adj. R^2 0.39 0.40 ## Num. obs. 526 526 ## ===================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rPodemos ver que los coeficientes y \\(R^2\\) se han ajustado un poco en sus valores. Realizando el test RETEST de Ramsey una vez más, nos daremos cuenta de que ahora el modelo está bien especificado, a partir de su p-valor.\nlmtest::resettest(mod2)\r## ## RESET test\r## ## data: mod2\r## RESET = 0.86008, df1 = 2, df2 = 518, p-value = 0.4237\rEn algunos casos, logaritmizar la variable dependiente también permite solucionar problemas de linealidad.\n\rc) Dicotomizar variable dependiente\rMuchas veces, en ciencias sociales trabajamos con variables que no siguen una distribución normal, como sucede con las ítems tipo escala Likert. Podemos re-especificar nuestra variable dependiente como dicotómica utilizando la mediana o la media como punte de corte, según corresponda. Por ejemplo, para wage:\nwage1$med_wage = ifelse(wage1$wage \u0026gt;= median(wage1$wage), 1, 0)\rwage1$mean_wage = ifelse(wage1$wage \u0026gt;= mean(wage1$wage), 1, 0)\rLuego, en lugar de estimar modelos de regresión lineal, estimaremos modelos de regresión logística binomial, lo cual va más allá de los contenidos de este curso.\n\rd) Heterocedasticidad\rEn este caso, podemos robustecer los errores estándar estimados, de la siguiente manera:\nmod_r \u0026lt;- lmtest::coeftest(mod, vcov=sandwich::vcovHC(mod))\r\re) Multicolinealidad\rCuando nuestros predictores están muy correlacionados, lo más probable es que esas distintas variables realmente estén midiendo el mismo constructo. Podemos construir índices de distintos tipos para solucionar este problema. Por ejemplo:\nÍndices sumativos: variables formativas donde se suma el valor de las distintas variables correlacionadas. Suele ser útil cuando se trabaja con variables categóricas, como dummies o ítems tipo Likert.\n\rÍndices a través de promedios: variables formativas donde promediamos los valores observados para los predictores correlacionados. Esto se puede realizar si a) ambas variables son numéricas; y b) el rango de las variables es el mismo. Por ello, siempre es recomendable estandarizar las variables antes de crear un índice a través de promedios.\n\r\r\rf) Casos influyentes\rPodemos identificar y filtrar a los casos influyentes de la distribución de la sigueinte manera:\nn\u0026lt;- nobs(mod) #n de observaciones\rk\u0026lt;- length(coef(mod)) # n de parametros\rdcook\u0026lt;- 4/(n-k-1) #Punto de corte\r# Datos donde se filtran los valores sobre el punto de corte\rwage1_ni \u0026lt;- broom::augment_columns(mod,data = wage1) %\u0026gt;% filter(.cooksd\u0026lt;dcook)\rmod_ni = lm(lwage ~ educ+exper+tenure+female, data = wage1_ni)\rscreenreg(list(mod, mod_ni))\r## ## ===================================\r## Model 1 Model 2 ## -----------------------------------\r## (Intercept) 0.50 *** 0.46 ***\r## (0.10) (0.09) ## educ 0.09 *** 0.09 ***\r## (0.01) (0.01) ## exper 0.00 ** 0.00 ** ## (0.00) (0.00) ## tenure 0.02 *** 0.02 ***\r## (0.00) (0.00) ## female -0.30 *** -0.30 ***\r## (0.04) (0.03) ## -----------------------------------\r## R^2 0.39 0.47 ## Adj. R^2 0.39 0.46 ## Num. obs. 526 496 ## ===================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\r\r\r4. Resumen\rEn este práctico aprendimos\nLas implicancias conceptuales y empíricas del error de medición en \\(x\\) e \\(y\\).\rCómo solucionar algunos problemas que singifican el incumplimiento de los supuestos del teorema Gauss-Markov.\r\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"609fca9114938f0b965c7f1201dc8be8","permalink":"/example/12-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/12-practico/","section":"example","summary":"0. Objetivo\rLos objetivos de este práctico son\nComprender las distintas fuentes que pueden producir errores de medición en un modelo de regresión lineal.\n\rAprender a procesar las variables analizadas para reducir el error de medida.","tags":null,"title":"Errores de medida y procesamiento","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo\rLos objetivos de este práctico son comprender a identificar y solucionar problemas asociados a la mala especificación de nuestros modelos.\n\r1. Paquetes y datos a utilizar\rUtilizaremos los datos sobre salarios del paquete wooldridge.\npacman::p_load(wooldridge,\rtexreg,\rperformance,\rtidyverse) # Universo de paquetes\roptions(scipen=999)\rdata(\u0026quot;wage1\u0026quot;)\r\r2. Introducción\rEn ocasiones, dada la disponibilidad y calidad de los datos con los que contamos, o por problemas teóricos en el diseño de nuestros modelos, es posible que incluyamos variables que no son relevantes para comprender el fenómeno o, al revés, que omitamos variables que sí lo son. En ambos casos, nuestros modelos pueden presentar problemas de ajuste y validez estadística, o bien, no nos permitirán explicar de manera parsimoniosa y robusta el fenómeno que estamos analizando.\nTrabajaremos con el siguiente modelo a modo de ejemplo:\nmod = lm(lwage ~ educ+exper+tenure+female, data = wage1)\rscreenreg(mod)\r## ## =======================\r## Model 1 ## -----------------------\r## (Intercept) 0.50 ***\r## (0.10) ## educ 0.09 ***\r## (0.01) ## exper 0.00 ** ## (0.00) ## tenure 0.02 ***\r## (0.00) ## female -0.30 ***\r## (0.04) ## -----------------------\r## R^2 0.39 ## Adj. R^2 0.39 ## Num. obs. 526 ## =======================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\r\r3. Inclusión de variables irrelevantes en un modelo de regresión\rEl problema de sobreespecificación del modelo significa que al menos una de las variables explicativas que incluimos no tiene ningún efecto parcial sobre \\(y\\). Pensemos en el siguiente modelo:\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_{3}x_{3} + u,\r\\end{equation}\r\\]\rque satisface los supuestos 1-4 del teorema de Gauss-Markov. No obstante, puede suceder que \\(x_3\\) no tenga ningún efecto sobre \\(y\\) al controlar por \\(x_1\\) y \\(x_2\\). O sea, \\(\\beta_3=0\\). En términos de esperanza condicional: \\(E(y|x_1,x_2,x_3) = E(y|x_1,x_2) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\). Pensando en nuestro modelo, \\(\\beta_{exper}=0\\) con un nivel de confianza del 99%, por lo cual podríamos considerar que la experiencia laboral en años es irrelevante para explicar las variaciones en los salarios por hora.\n¿Qué efectos puede tener el incluir variables irrelevantes? Esto no genera sesgos en \\(\\beta_j\\). Por ello, podemos asumir que, pese a incluir variables irrelevantes, \\(E(\\hat\\beta_j) = \\beta_j\\). Esto puede, sin embargo, tener efectos indeseables en la varianza de los estimadores de MCO, lo cual puede ser perjudicial para nuestras inferencias.\n\r4. Sesgo de variable omitida\rSi, en lugar de incluir variables irrelevantes, no incluimos variables relevantes, estamos subespecificando el modelo. Esto hará que nuestros estimadores sean sesgados. Podemos determinar la dirección y magnitud de este sesgo. Esa identificación es un ejemplo de análisis de error de especificación. Pensemos el siguiente modelo, que satisface los supuestos 1-4 del teorema de Gauss-Markov:\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + u.\r\\end{equation}\r\\]\nPensemos que este modelo busca explicar la variación promedio en los salarios por hora (\\(y\\)) a partir de la variación de los años de escolaridad (\\(x_1\\)) y el CI del individuo (\\(x_2\\)). Si estimamos el modelo de regresión de \\(y\\) sobre \\(x_1\\) y \\(x_2\\), obtendremos estimadores insesgados de \\(\\beta_0\\), \\(\\beta_1\\) y \\(\\beta_2\\). No obstante, es posible que no contemos con la variable de CI en nuestra base de datos, por lo cual estimamos el modelo considerando sólo a \\(x_1\\). En cuyo caso, el modelo se especificaría\n\\[\r\\begin{equation}\r\\tilde{y} = \\tilde\\beta_0 + \\tilde\\beta_1x_1 + v,\r\\end{equation}\r\\]\rdonde \\(v = \\beta_2x_2 + u\\).\nPara obtener el sesgo de \\(\\tilde\\beta_1\\), tenemos que \\(\\tilde\\beta_1 = \\hat\\beta_1 + \\hat\\beta_2\\tilde\\delta_1\\), donde \\(\\hat\\beta_1\\) y \\(\\hat\\beta_2\\) son los estimadores de la pendiente de regresión múltiple\n\\(y_i\\) sobre \\(x_{i1}, x_{i2}, i = 1, ..., n\\)\ny \\(\\tilde\\delta_1\\) es la pendiente de la regresión simple\n\\(x_{i2}\\) sobre \\(x_{i1}, i = 1,...,n.\\)\nDado que \\(\\tilde\\delta_1\\) sólo depende de los predictores de la muestra, al calcular \\(E(\\tilde\\beta_1)\\) se considera fija o no aleatoria. Dado que suponemos que se cumplen los supuestos del teorema Gauss-Markov, sabemos que \\(\\hat\\beta_1\\) y \\(\\hat\\beta_2\\) son estimados insesgados de \\(\\beta_1\\) y \\(\\hat\\beta_2\\), respectivamente. Así:\n\\[\r\\begin{equation}\r\\begin{aligned}\rE(\\tilde\\beta_1) = E(\\hat\\beta_1 + \\hat\\beta_2\\tilde\\delta_1) = E(\\hat\\beta_1) + E(\\hat\\beta_2)\\tilde\\delta_1\r\u0026amp; = \\beta_1 + \\beta_2\\tilde\\delta_1,\r\\end{aligned}\r\\end{equation}\r\\]\nde modo que el sesgo en \\(\\tilde\\beta_1\\) es\n\\[\r\\begin{equation}\rBias(\\tilde\\beta_1) = E(\\tilde\\beta_1) - \\beta_1 = \\beta_2\\tilde\\delta_1.\r\\end{equation}\r\\]\nA este término se le denomina sesgo de la variable omitida.\nHay dos casos en que \\(\\tilde\\beta_1\\) es insesgado:\nCuando \\(\\beta_2=0\\), o\rCuando \\(\\tilde\\delta_1=0\\), aun cuando \\(\\beta_2\\neq0\\). Dado que \\(\\tilde\\delta_1\\) es la covarianza muestral de \\(x_1\\) y \\(x_2\\) sobre la varianza muestral de \\(x_1\\), esta sólo será igual a cero cuando no existe correlación entre ambas variables.\r\rEn caso de que \\(x_1\\) y \\(x_2\\) estén correlacionadas, \\(\\tilde\\delta_1\\) tendrá el mismo signo que su correlación. El signo del sesgo de \\(\\tilde\\beta_1\\) depende, por su parte, de los signos de \\(\\beta_2\\) y \\(\\tilde\\delta_1\\). También es importante cuidar la magnitud del sesgo, que también estará determinada por las magnitudes de \\(\\beta_2\\) y \\(\\tilde\\delta_1\\).\nPese a que no podamos conocer su magnitud y su dirección en cuanto \\(\\beta_2\\) es un parámetro desconocido, si la podemos inferir. Por ejemplo, podemos asumir que el efecto del CI sobre el salario por hora es positivo en la medida que permite mejor productividad en los trabajadores, por lo que asumimos que \\(\\beta_2\u0026gt;0\\). Asimismo, podemos inferir que la correlación entre los años de escolaridad y el CI es positiva, en cuanto un mayor nivel educacional puede estar asociado a un mayor desarrollo intelectual. Así, podemos operar bajo el supuesto de que el sesgo es positivo, en cuanto los signos de \\(\\beta_2\\) y \\(\\tilde\\delta_1\\) sean positivos.\nEn términos generales, el análisis del sesgo por no incluir variables relevantes se señala:\nSi \\(E(\\tilde\\beta_1)\u0026gt;\\beta_1\\), \\(\\tilde\\beta_1\\) tiene un sesgo hacia arriba, mientras que\rSi \\(E(\\tilde\\beta_1)\u0026lt;\\beta_1\\), \\(\\tilde\\beta_1\\) tiene un sesgo hacia abajo; y\rSi \\(E(\\tilde\\beta_1)\\) se encuentra más cerca de cero que \\(\\beta_1\\), está sesgado hacia cero.\r\rEl procedimiento anterior se dificulta cuando tenemos modelos múltiples. Para comprenderlo, hemos de recordar que la correlación entre un predictor y el error tiene a generar que todos los estimadores de MCO sean sesgados. Si tenemos el modelo poblacional que satisface los supuestos 1-4 de Gauss-Markov\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + u,\r\\end{equation}\r\\]\npero omitimos \\(x_3\\), obtenemos\n\\[\r\\begin{equation}\r\\tilde{y} = \\tilde\\beta_0 + \\tilde\\beta_1x_1 + \\tilde\\beta_2x_2.\r\\end{equation}\r\\]\nSupongamos que \\(x_2\\) y \\(x_3\\) no están correlacionadas, pero que \\(x_1\\) y \\(x_3\\) sí lo están. En este caso, pese a que \\(x_2\\) no esté asociada a la variable omitida, tanto \\(\\tilde\\beta_1\\) como \\(\\tilde\\beta_2\\) serán sesgados. Ello ocurre salvo que \\(x_1\\) y \\(x_2\\) no estén correlacionadas.\nSin embargo, si asumimos que \\(x_1\\) y \\(x_2\\) no están correlacionadas, podemos estudiar el sesgo de \\(\\tilde\\beta_1\\) como si \\(x_2\\) no se hubiese incluido en los modelos estimado y poblacional. En este caso, podría demostrarse que\n\\[\r\\begin{equation}\rE(\\tilde\\beta_1) = \\beta_1 + \\beta_3 \\frac{\\sum_{i=1}^n(x_{i1}-\\bar{x_1})x_{i3}}{\\sum_{i=1}^n(x_{i1}-\\bar{x_1})^2}\r\\end{equation}\r\\]\nAsí, el sesgo en \\(\\tilde\\beta_1\\) será positivo cuando la correlación de \\(x_1\\) y \\(x_3\\) sea positiva y \\(\\beta_3\u0026gt;0\\); o cuando la correlación de \\(x_1\\) y \\(x_3\\) sea negativa y \\(\\beta_3\u0026lt;0\\), y así.\n\r5. Varianza de estimadores de MCO\rBajo los supuestos 1-5 de Gauss-Markov (es decir, esta vez incluyendo la homocedasticidad), la varianza de los estimadores MCO se calcula\n\\[\r\\begin{equation}\rVar(\\hat\\beta_j) = \\frac{\\sigma^2}{STC(1-R_j^2)},\r\\end{equation}\r\\]\rpara \\(j=1,2,...,k\\), donde \\(STC = \\sum_{i=1}^n(x_{ij}-\\bar{x}_j)^2\\) es la variación muestral total en \\(x_j\\) y \\(R_j^2\\) es la \\(R^2\\) de regresión de \\(x_j\\) sobre todas las variables explicativas, incluyendo un intercepto.\nLa importancia de la varianza de los estimadores MCO proviene de que, si su valor es alto, el estimador es menos preciso, lo cual se traduce en intervalos de confianza más amplios y pruebas de hipótesis menos exactas.\n\r6. Varianzas en modelos mal especificados\rIncluir determinada variable en un modelo de regresión se puede realizar a partir de la disyuntiva entre sesgo y varianza. Cuando dejamos fuera una variable relevante, nuestro modelo presentará un sesgo hacia arriba o hacia abajo. Considerando el modelo poblacional verdadero, que cumple con los supuestos de Gauss-Markov\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + u,\r\\end{equation}\r\\]\rconsideraremos dos estimadores de \\(\\beta_1\\). El primero, \\(\\hat\\beta_1\\) proviene de\n\\[\r\\begin{equation}\r\\hat{y} = \\hat\\beta_0 + \\hat\\beta_1x_1 + \\hat\\beta_2x_2,\r\\end{equation}\r\\]\rmientras que el estimador \\(\\tilde\\beta_1\\) se obtiene omitiendo \\(x_2\\)\n\\[\r\\begin{equation}\r\\tilde{y} = \\tilde\\beta_0 + \\tilde\\beta_1x_1.\r\\end{equation}\r\\]\nComo se vio anteriormente, si \\(\\beta_2 \\neq 0\\), estamos excluyendo una variable relevante, lo cual induce un sesgo en \\(\\tilde\\beta_1\\), salvo que no exista correlacion entre \\(x_1\\) ni \\(x_2\\). Por su parte, \\(\\hat\\beta_1\\) es un estimador insesgado de \\(\\beta_1\\) para cualquier valor de \\(\\beta_2\\), incluyendo 0. Así, si el sesgo es nuestro único criterio, preferiremos a \\(\\hat\\beta_1\\) frente a \\(\\tilde\\beta_1\\).\nEllo no es válido al considerar la varianza. Tenemos que\n\r\\(Var(\\hat\\beta_1) = \\sigma^2/[STC_1(1-R_1^2)]\\), y\r\\(Var(\\tilde\\beta_1) = \\sigma^2/STC_1\\)\r\rDe ese modo, \\(Var(\\tilde\\beta_1)\\) siempre será menor que \\(Var(\\hat\\beta_1)\\), a menos que \\(x_1\\) y \\(x_2\\) no estén correlacionadas. En ese caso, ambos estimadores son iguales. Si ambas variables están correlacionadas, podemos formular lo siguiente:\nSi \\(\\beta_2 \\neq 0\\), \\(\\tilde\\beta_1\\) es sesgado, \\(\\hat\\beta_1\\) es insesgado y \\(Var(\\tilde\\beta_1)\\)\u0026lt;\\(Var(\\hat\\beta_1)\\)\rSi \\(\\beta_2 = 0\\), \\(\\tilde\\beta_1\\) y \\(\\hat\\beta_1\\) son insesgados y \\(Var(\\tilde\\beta_1)\\)\u0026lt;\\(Var(\\hat\\beta_1)\\).\r\rAsí, si \\(x_2\\) no tiene efecto parcial sobre \\(y\\), el incluirla sólo puede aumentar la posibilidad de tener un problema de multicolinealidad, lo cual implica un estimador menos eficiente de \\(\\beta_1\\).\nEn cambio, si \\(x_2\\) sí tiene un efecto sobre \\(y\\), dejarla fuera significará un estimador sesgado de \\(\\beta_1\\). Se ha recomendado comparar la magnitud del sesgo al omitir \\(x_2\\) con la disminución de la varianza expresada en \\(R_1^2\\) para decidir si se incluye aquella variable. Si \\(\\beta_2 \\neq 0\\), lo recomendable es incluir \\(x_2\\) en el modelo, pues el sesgo en \\(\\tilde\\beta_1\\) no disminuirá al aumentar el tamaño muestral. Además, tanto \\(Var(\\tilde\\beta_1)\\) como \\(Var(\\hat\\beta_1)\\) tienden a cero en la medida que \\(n\\) aumenta, por lo que la colinealidad producida por incorporar \\(x_2\\) pierde relevancia en tanto trabajamos con muestras más grandes. En estos casos, preferiremos \\(\\hat\\beta_1\\).\nComprobemos lo anterior comparando nuestro modelo con otras dos versiones:\nUna en la cual eliminamos una variable no relevante, exper, y una variable relevante, educ;\runa en que sólo eliminamos una variable no relevante; y\rotra donde eliminamos una variable relevante, educ\r\rmod2 = lm(lwage ~ tenure+female, data = wage1)\rmod3 = lm(lwage ~ educ+tenure+female, data = wage1)\rmod4 = lm(lwage ~ exper+tenure+female, data = wage1)\rscreenreg(list(mod, mod2, mod3, mod4))\r## ## ===========================================================\r## Model 1 Model 2 Model 3 Model 4 ## -----------------------------------------------------------\r## (Intercept) 0.50 *** 1.69 *** 0.63 *** 1.71 ***\r## (0.10) (0.03) (0.09) (0.04) ## educ 0.09 *** 0.08 *** ## (0.01) (0.01) ## exper 0.00 ** -0.00 ## (0.00) (0.00) ## tenure 0.02 *** 0.02 *** 0.02 *** 0.02 ***\r## (0.00) (0.00) (0.00) (0.00) ## female -0.30 *** -0.34 *** -0.30 *** -0.34 ***\r## (0.04) (0.04) (0.04) (0.04) ## -----------------------------------------------------------\r## R^2 0.39 0.21 0.38 0.21 ## Adj. R^2 0.39 0.20 0.38 0.20 ## Num. obs. 526 526 526 526 ## ===========================================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rPodemos observar dos cosas al comparar los modelos\nMientras que el estadístico \\(R^2\\) de los modelos 1 (con todas las variables) y 2 (sin una variable no relevante) alcanza valores similares, este disminuye al excluir del modelo los años de escolaridad, que es una variable relevante para explicar los salarios por hora.\n\rAl incluir una nueva variable relevante educ en el modelo 3, los errores estándar (\\(\\sigma^2/n\\)) se mantienen relativamente similares, por lo que su inclusión no significa un aumento en la varianza de los estimadores.\n\rEl modelo 4 no presenta diferencias sustantivas respecto del modelo 2: no mejora su ajuste, ni aumenta la varianza en general.\n\r\r\rResumen\rEn la clase de hoy aprendimos a comprender los problemas asociados a la mala especificación de nuestros modelos, a partir de dos casos: uno, en que no incluimos variables relevantes; y otro, donde incluimos variables que no lo son. A través de un ejemplo práctico, pudimos constatar qué sucede al incorporar y excluir tales variables de los modelos.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"127b844464fbfe4851bdc19bb33c9e67","permalink":"/example/13-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/13-practico/","section":"example","summary":"0. Objetivo\rLos objetivos de este práctico son comprender a identificar y solucionar problemas asociados a la mala especificación de nuestros modelos.\n\r1. Paquetes y datos a utilizar\rUtilizaremos los datos sobre salarios del paquete wooldridge.","tags":null,"title":"Omisión de variables relevantes","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo del práctico\rEl presente práctico tiene dos objetivos:\nComprender conceptualmente el análisis de regresión lineal simple estimado a través de Mínimos Cuadrados Ordinarios (MCO) (o Ordinary Least Squares (OLS) en inglés).\n\rAprender a estimar una regresión lineal simple en R a través de la función lm().\n\r\rMateriales de la sesión\rEn este práctico se utilizarán los datos sobre salarios utilizados en el capítulo 2 del libro Introducción a la econometría de J.W. Wooldridge (2015).\nAsimismo, la realización de este práctico requiere la carga de diversos paquetes que nos permitirán explorar los datos y presentar los modelos estimados.\nif (!require(\u0026quot;pacman\u0026quot;)) install.packages(\u0026quot;pacman\u0026quot;) # Instalamos pacman en caso de necesitarlo\rpacman::p_load(wooldridge, #Para descargar los datos\rdplyr, #Para procesar datos\rsjmisc, #Para explorar los datos\rsjPlot, #Para explorar los datos\rtexreg) #Para presentar el modelo de regresión estimado\r\r\r1. Familiarizándose con los datos\rComo se señalo anteriormente, se trabajará con datos sobre salarios. Para cargarlos, utilizamos la función data(\"wage1\")\ndata(\u0026quot;wage1\u0026quot;)\rNos daremos cuenta de que en nuestro ambiente ha aparecido un dataframe con 526 observaciones y 24 columnas. Particularmente, en este caso trabajaremos con dos variables:\n\rwage: indica el salario por hora en miles de pesos de cada persona en los datos.\reduc: indica el número de años de escolaridad de cada persona en los datos.\r\rLas seleccionaremos utilizando la función select() de dplyr, a modo de trabajar con un set de datos más acotado\nwage1 = select(wage1, wage, educ)\rComo se ha revisado en las clases, el análisis de regresión busca cuantificar la relación entre dos variables \\(x\\) (independiente, predictora, explicativa, entre otros) e \\(y\\) (dependiente, predicha, explicada, entre otros). En particular, se busca\n\rExplicar \\(y\\) en términos de \\(x\\), o bien\rAnalizar cómo varía \\(y\\) cuando varía \\(x\\).\r\rEn este práctico se busca estimar un modelo de regresión lineal de wage (\\(y\\), variable explicada) sobre educ (\\(x\\), variable explicativa). Antes de adentrarse directamente en la comprensión y estimación de los modelos de regresión lineal simple, es relevante explorar uni y bivariadamente los datos por analizar. Para ello, nos valdremos de las funciones descr() del paquete sjmisc, que permite describir variables cuantitativas; plot_frq() y plot_scatter de sjPlot para análisis uni y bivariados;y cor() del paquete base de R.\nDescriptivos univariados con sjmisc::descr() y sjPlot::plot_frq()\rEn general, variables de niveles de medición intervalar o de razón (también denominadas genéricamente como variables cuantitativas) permiten emplear una serie de propiedades de los números que se traducen en la posibilidad de realizar con ellos operaciones aritméticas como sumar, restar, multiplicar y dividir. Así, es posible estimar para ellas no sólo medidas de posición, sino también otras medidas de tendencia central de gran importancia como, en particular, la media, así como medidas de dispersión tales como la varianza. Ambos estadísticos son fundamentales en la estimación de modelos de regresión lineal.\nEn particular, los descriptivos para la variable wage se obtienen\nsjmisc::descr(wage1$wage)\r## ## ## Basic descriptive statistics\r## ## var type label n NA.prc mean sd se md trimmed range\r## dd numeric dd 526 0 5.9 3.69 0.16 4.65 5.24 24.45 (0.53-24.98)\r## iqr skew\r## 3.55 2.01\rSiguiendo lo presentado es posible distinguir que, en la muestra, los salarios por hora oscilan entre los .53 y los 24.98 mil pesos chilenos. El promedio es de 5.9 mil pesos por hora, mientras que la desviación estándar corresponde a 3.69 mil pesos por hora. Además, la mediana (4.65 mil pesos por hora) es inferior a la media, lo cual indicaría una asimetría positiva en los datos. Considerando una jornada laboral de 44 horas semanales, lo anterior nos indica que, en promedio, los trabajadores de la muestra obtienen un salario mensual promedio de 1038400 pesos.\nUn histograma también puede ser útil para identificar la distribución de la variable:\nsjPlot::plot_frq(wage1$wage,\rtitle = \u0026quot;Histograma de salarios por hora en miles de pesos\u0026quot;,\rtype = \u0026quot;histogram\u0026quot;)\rEn este caso, es posible apreciar que la distribución de la variable presente una asimetría positiva, lo cual indica que la mayoría de los datos se concentran en la zona inferior de la distribución (es decir, hay una mayor proporción de salarios por hora bajos en relación con salarios por hora muy altos).\nEn el caso de los años de escolaridad, la media corresponde a 12.56 años, con una mediana de 4.65 años y una desviación estándar de 3.69. Ello indica que al menos un 50% de las personas en la muestra completaron la enseñanza media.\ndescr(wage1$educ)\r## ## ## Basic descriptive statistics\r## ## var type label n NA.prc mean sd se md trimmed range iqr skew\r## dd integer dd 526 0 12.56 2.77 0.12 12 12.69 18 (0-18) 2 -0.62\rEn lo que respecta a la distribución de la variable educ, es posible constatar que la mayoría de los casos se encuentran en torno a la media, que corresponde a 12.56 años de escolaridad, lo cual corresponde a un nivel educacional medio.\nsjPlot::plot_frq(wage1$educ,\rtitle = \u0026quot;Histograma de años de escolaridad\u0026quot;,\rtype = \u0026quot;histogram\u0026quot;)\r\rAnálisis bivariado con base::cor() y sjPlot::plot_scatter()\rEntre otros elementos, algo fundamental que tenemos que considerar a la hora de plantear la estimación de un modelo que busque analizar el efecto de \\(x\\) sobre \\(y\\) es que estas deben estar relacionadas entre sí, al menos de forma moderada. Para estimar la correlación entre dos variables utilizamos base::cor()\ncor(wage1$wage, wage1$educ)\r## [1] 0.4059033\rEn este caso la correlación es de 0.41, lo cual corresponde a una relación moderada-fuerte en ciencias sociales. Es posible graficar esta relación con sjPlot::plot_scatter() para analizar con mayor detalle la asociación entre salarios por hora y años de escolaridad\nsjPlot::plot_scatter(wage1, x = educ, y = wage,\rtitle = \u0026quot;Relación entre salarios (en miles de pesos) por hora y años de escolaridad\u0026quot;,\rfit.line = \u0026quot;lm\u0026quot;)\r## `geom_smooth()` using formula = \u0026#39;y ~ x\u0026#39;\rSi bien no hay claridad de que la relación entre ambas variables sea lineal dada la recta de regresión presentada (lo cual es el supuesto fundamental del análisis de regresión lineal), si se puede identificar una relación positiva entre salarios por hora y años de escolaridad. Ello apoya la hipótesis planteada al inicio del práctico: una mayor escolaridad estará asociada, en promedio, a salarios por hora más elevados.\n\r\r2. Estimando un modelo de regresión lineal simple con lm()\rEn general, la estimación de modelos de regresión lineal simple en R es sencilla en términos de código. Antes de ello, sin embargo, consideremos la formalización del modelo de regresión lineal por estimar\n\\[\r\\begin{equation}\r\\hat{wage} = \\beta_0 + \\beta_1educ_{i} + u_{i}\r\\end{equation}\r\\]\rEs decir: el salario por hora predicho corresponde a la suma del intercepto de regresión \\(\\beta_0\\), más el valor estimado para el coeficiente de regresión \\(\\beta_1\\) estimado para la variable educ por el valor observado en esa variable para cada sujeto, más el error \\(u_{i}\\) asociado a cada observación. En términos generales:\n\r\\(\\beta_0\\): Corresponde al valor estimado para \\(\\hat{y}\\) para alguien con cero años de escolaridad.\n\r\\(\\beta_1\\): Corresponde a la pendiente estimada para la función de regresión lineal de \\(\\hat{y}\\) sobre \\(x\\). Así, por cada unidad que aumente \\(x\\) (en este caso, por cada año de escolaridad extra), el valor estimado \\(\\hat{y}\\) para los salarios por hora aumentará o disminuirá en \\(\\beta_1\\).\n\r\\(u_{i}\\): Corresponde al error en la estimación, generado por la no incorporación en el modelo de variables que estén relacionadas con wage. En este caso, incluir variables como el área de actividad económica, la ocupación, la capacidad de liderazgo o resolución de problemas, entre otros, puede disminuir el error causado por la no observación de efectos estadísticamente significativos de estas variables sobre los salarios por hora.\n\r\rSin embargo, para simplificar el análisis, en el práctico sólo nos enfocaremos en \\(\\beta_0\\) y \\(\\beta_1\\). Para estimar un modelo de regresión simple, debe utilizarse el siguiente código\nmod = lm(wage ~ educ, data = wage1)\rEn términos sencillos, el anterior código indica a R que\n\rCree un nuevo objeto llamado mod (recordemos que = indica asignación);\rEste nuevo objeto será un modelo de regresión lineal estimado con lm(),\rEn el cual la variable explicada \\(y\\) corresponde a wage (lo que antecede a ~),\rMientras que la variable explicativa \\(x\\) corresponde a educ (lo que sucede a ~),\rUtilizando los datos del objeto wage1.\rEs decir: lm(\\(y\\) ~ \\(x_1\\), datos).\r\rLuego de ejecutar ese código, se generará en el ambiente un objeto llamado mod, que corresponde a una lista con 12 elementos. No nos adentraremos en ello en esta clase, pues el foco está en la estimación y comprensión estadística de los modelos de regresión lineal simple.\n\r3. Comprendiendo el output de lm()\rLuego de haber creado el objeto que contiene el modelo de regresión lineal simple estimado, debemos proceder a presentarlo para poder analizar los resultados. Para ello utilizaremos la función screenreg() de texreg.\nscreenreg(mod)\r## ## =======================\r## Model 1 ## -----------------------\r## (Intercept) -0.90 ## (0.68) ## educ 0.54 ***\r## (0.05) ## -----------------------\r## R^2 0.16 ## Adj. R^2 0.16 ## Num. obs. 526 ## =======================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rEn la tabla se presentan diversos estadísticos. Revisemos los resultados con mayor atención, fila por fila:\n\rModel 1: Indica el modelo presentado. Esto es útil en casos donde presentamos más de un modelo.\n\r(Intercept): Indica el valor estimado para el intercepto de regresión o \\(\\beta_0\\). Ello indica que, cuando \\(educ_i = 0\\), el salario por hora predicho corresponde a -.9 mil pesos. El valor en paréntesis que le sigue corresponde al error estándar estimado para el intercepto.\n\reduc: Corresponde al coeficiente de regresión estimado para la variable explicativa educ, o \\(\\beta_1\\). De ese modo el modelo estima que, por cada año de escolaridad que se aumente, el salario por hora predicho aumentará en .54 mil pesos. El valor en paréntesis que le sigue corresponde al error estándar estimado para el coeficiente.\n\rR^2 y Adj. R^2: Corresponden a las medidas de ajuste del modelo. Esto se revisará con detención en el práctico 5.\n\rNum. obs: Número de observaciones con las cuales se estimó el modelo. En este caso, se utilizó la totalidad de la muestra, que cuenta con 526 casos. Es fundamental considerar que la estimación de modelos de regresión lineal sólo utiliza observaciones que cuenten con casos válidos en \\(x\\) y en \\(y\\), por lo cual el trabajo de procesamiento de datos es fundamental para lograr un buen análisis.\n\r*** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05: Indican el p-valor estimado para cada coeficiente. Esto se abordará con profundidad en el práctico 8.\n\r\rAsí, siguiendo la formalización planteada anteriormente y los resultados obtenidos, es posible plantear que\n\\[\r\\begin{equation}\r\\hat{wage} = -.9 + .54 educ_{i}\r\\end{equation}\r\\]\n\r4. Interpretando un modelo de regresión lineal simple\rAhora sólo nos falta interpretar el modelo estimado. Para ello hay que tomar en cuenta los valores estimados para \\(\\beta_0\\) y \\(\\beta_1\\)\n\r\\(\\beta_0\\): Como se señaló anteriormente, el intercepto corresponde al valor predicho \\(\\hat{y}\\) cuando \\(x_1 = 0\\). En este caso, indica el salario por hora predicho en promedio para personas con 0 años de escolaridad.\n\r\\(\\beta_1\\): en este caso, el valor positivo del coeficiente (\\(\\beta_1 \u0026gt; 0\\)) indica que existe un efecto positivo de los años de escolaridad sobre el salario por hora predicho: mientras más años de escolaridad se tengan, más alto debiese ser el salario por hora percibido. En términos concretos: se espera que, en promedio, una persona con 11 años de escolaridad perciba un salario por hora .54 mil pesos más alto que alguien con 10 años de escolaridad. Es posible estimar los valores predichos para corroborarlo:\n\r\r\\[\r\\begin{equation}\r\\hat{wage_1} = -.9 + .54 educ_{i} = -.9 + .54*10 = 4.5\r\\end{equation}\r\\]\r\\[\r\\begin{equation}\r\\hat{wage_2} = -.9 + .54 educ_{i} = -.9 + .54*11 = 5.04\r\\end{equation}\r\\]\rLuego, \\(5.04-4.5 = .54 = \\beta_1\\).\nDe lo anterior se sigue que\n\rSe espera que \\(\\beta_1 \\neq 0\\) pues, de lo contrario, no existiría un efecto estadísticamente significativo de \\(x_1\\) sobre \\(y\\).\rAsimismo, mientras mayor sea \\(|\\beta_1|\\), mayor será la magnitud del efecto de \\(x_1\\) sobre \\(y\\) y viceversa.\rSi \\(\\beta_1 \u0026gt; 0\\), el efecto de \\(x_1\\) sobre \\(y\\) es positivo.\rSi \\(\\beta_1 \u0026lt; 0\\), el efecto de \\(x_1\\) sobre \\(y\\) es negativo.\r\r\r5. ¿Cómo se estima \\(\\beta_{1}\\)?\rComo es posible constatar, la estimación de modelos de regresión lineal simple en R es bastante sencilla en términos de código: lo más relevante es indicar claramente cuál es la variable \\(x\\), y cuál es la variable \\(y\\). Sin embargo, es importante comprender conceptual y matemáticamente cómo se estima \\(\\beta_1\\).\nComo se señaló al inicio del práctico, el método de estimación de Mínimos Cuadrados Ordinarios (MCO) (u OLS en inglés). Ello indica que la estimación busca optimizar una recta que se ajuste a los datos disminuyendo al máximo la suma de los residuos al cuadrado. Los residuos se elevan al cuadrado para sumarlos, lo cual se denomina Suma de residuos al cuadrado o \\(SS_{residual}\\). Esto para evitar que residuos positivos y negativos se anulen entre sí.\nAhora ¿qué son los residuos? Estos corresponden a la diferencia entre el valor predicho y el valor observado. Si, por ejemplo, el salario por horas predicho corresponde a 4 mil pesos, y el valor observado corresponde a 3.7 mil pesos por hora, entonces el residuo de la estimación para esta observación equivale a -.3 mil pesos.\nConsidérese la ecuación\n\\[\r\\begin{equation}\r\\hat{y} = \\beta_0 + \\beta_1x_{i}\r\\end{equation}\r\\]\r, donde\n\r\\(\\beta_0 = \\hat{y} - \\beta_1\\);\r\\(\\beta_1 = \\frac{Cov(XY)}{VarX}\\), donde\r\r\\(Cov(XY) = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{n-1}\\), y\r\\(VarX = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}{n-1}\\)\r\r\rLuego, es posible simplificar de la siguiente manera\n\\[\r\\begin{equation}\r\\beta_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})} = \\frac{\\sum_{i=1}^{n}(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})}\r\\end{equation}\r\\]\nA continuación, crearemos variables que reflejen la diferencia entre los valores observados \\(x_i\\) e \\(y_i\\) y el promedio \\(\\bar{x}\\) y \\(\\bar{y}\\), respectivamente:\nwage1$difx = wage1$educ-mean(wage1$educ)\rwage1$dify = wage1$wage-mean(wage1$wage)\rCon ello procedemos a calcular la diferencia de productos cruzados \\((x_i - \\bar{x})(y_i - \\bar{y})\\), y la diferencia de cada valor observado de \\(x\\) con su promedio al cuadrado \\((x_i - \\bar{x})^2\\)\nwage1$difcru = wage1$difx*wage1$dify\rwage1$difx2 = wage1$difx^2\rhead(wage1)\r## wage educ difx dify difcru difx2\r## 1 3.10 11 -1.5627376 -2.7961028 4.3695751 2.4421489\r## 2 3.24 12 -0.5627376 -2.6561027 1.4946890 0.3166737\r## 3 3.00 11 -1.5627376 -2.8961027 4.5258487 2.4421489\r## 4 6.00 8 -4.5627376 0.1038973 -0.4740562 20.8185748\r## 5 5.30 12 -0.5627376 -0.5961025 0.3354493 0.3166737\r## 6 8.75 16 3.4372624 2.8538973 9.8095938 11.8147725\rAsí, es posible obtener la suma de productos cruzados \\((x_i - \\bar{x})(y_i - \\bar{y})\\), y la suma de cuadrados de X \\((x_i - \\bar{x})^2\\)\nsum(wage1$difcru)\r## [1] 2179.204\rsum(wage1$difx2)\r## [1] 4025.43\rReemplazamos los valores en la fórmula anterior:\n\\[\r\\begin{equation}\r\\beta_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})} = \\frac{2179.204}{4025.43} = 0.54\r\\end{equation}\r\\]\nY estimamos el intercepto reemplazando por valores ficticios\n\\[\r\\begin{equation}\r\\beta_0 = \\hat{y} - \\beta_1x_i = 6.12-(.54*13) = 6.12*7.02 = -.9\r\\end{equation}\r\\]\rAsí, la ecuación estimada manualmente es idéntica a la estimada a través de lm()\n\\[\r\\begin{equation}\r\\hat{y} = -.9 + .54 x_{i}\r\\end{equation}\r\\]\nDesafío: estimando \\(\\beta_{1}\\)\r¡Ahora es su turno! Utilizando la tabla presentada a continuación, deben estimar manualmente el valor de \\(\\beta_1\\), siguiendo los pasos detallados recientemente\nprint(head(wage1[,1:2], 10))\r## wage educ\r## 1 3.10 11\r## 2 3.24 12\r## 3 3.00 11\r## 4 6.00 8\r## 5 5.30 12\r## 6 8.75 16\r## 7 11.25 18\r## 8 5.00 12\r## 9 3.60 12\r## 10 18.18 17\rLa correcta realización del desafío significará una bonificación individual de .5 décimas en la nota obtenida en la prueba del curso ¡mucha suerte!\n\r\rResumen\rEn este práctico comprendimos conceptualmente los modelos de regresión lineal simple, con especial atención en los conceptos de intercepto y pendiente. También aprendimos a estimar este tipo de modelos con lm()\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c3961da1a9fcb2fd721bd682d67a5c5b","permalink":"/example/04-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/04-practico/","section":"example","summary":"0. Objetivo del práctico\rEl presente práctico tiene dos objetivos:\nComprender conceptualmente el análisis de regresión lineal simple estimado a través de Mínimos Cuadrados Ordinarios (MCO) (o Ordinary Least Squares (OLS) en inglés).","tags":null,"title":"Regresión lineal simple","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo del práctico\rEl presente práctico tiene tres objetivos:\nAnalizar la bondad de ajuste de los modelos de regresión lineal simple estimados a través del estadístico \\(R^2\\).\n\rAprender a estimar una regresión lineal simple incorporando el diseño muestral en las estimaciones en R, a través de la función svyglm().\n\rComprender la importancia y las implicancias de realizar las estimaciones de modelos de regresión lineal, considerando u omitiendo el diseño muestral en el análisis.\n\r\rMateriales de la sesión\rTal como en la sesión anterior, en este práctico se utilizarán los datos sobre salarios utilizados en el capítulo 2 del libro Introducción a la econometría de J.W. Wooldridge (2015).\nAsimismo, la realización de este práctico requiere la carga de diversos paquetes que nos permitirán explorar los datos y presentar los modelos estimados.\nif (!require(\u0026quot;pacman\u0026quot;)) install.packages(\u0026quot;pacman\u0026quot;) # Instalamos pacman en caso de necesitarlo\rpacman::p_load(wooldridge, #Para descargar los datos\rdplyr, #Para procesar datos\rsjmisc, #Para explorar los datos\rsjPlot, #Para explorar los datos\rMCMCpack, #Para crear un ponderador ficticio\rsrvyr, #Para crear un objeto encuesta\rsurvey, #Para realizar estimaciones incorporando el diseño muestral\rtexreg) #Para presentar el modelo de regresión estimado\rdata(\u0026quot;wage1\u0026quot;) #Cargamos los datos\rwage1 = select(wage1, wage, educ) #Seleccionamos sólo las variables por analizar\r\r\r1. Recordemos: Estimando un modelo de regresión lineal simple con lm()\rComo recordarán del práctico anterior, lo que buscamos es estimar un modelo de regresión lineal simple de salarios por hora (wage) sobre años de escolaridad (educ). La siguiente ecuación expresará, entonces, el efecto promedio de los años de escolaridad sobre el salario por hora, ceteris paribus\n\\[\r\\begin{equation}\r\\hat{wage} = \\beta_0 + \\beta_1educ_{i}\r\\end{equation}\r\\]\nUtilizando la función lm() del paquete base de R podemos estimar ese modelo de regresión lineal utilizando nuestros datos.\nmod = lm(wage ~ educ, data = wage1)\rLuego de haber creado el objeto que contiene el modelo de regresión lineal simple estimado, debemos proceder a presentarlo para poder analizar los resultados. Para ello utilizaremos la función summary() de base.\nsummary(mod)\r## ## Call:\r## lm(formula = wage ~ educ, data = wage1)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -5.3396 -2.1501 -0.9674 1.1921 16.6085 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.90485 0.68497 -1.321 0.187 ## educ 0.54136 0.05325 10.167 \u0026lt;0.0000000000000002 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 3.378 on 524 degrees of freedom\r## Multiple R-squared: 0.1648, Adjusted R-squared: 0.1632 ## F-statistic: 103.4 on 1 and 524 DF, p-value: \u0026lt; 0.00000000000000022\rLa tabla nos informa que los años de escolaridad tienen un efcto positivo (\\(\\beta_1 = 0.54\\)) sobre el salario por hora. Es decir, se espera que personas con más años de escolaridad tiendan a presentar, en promedio, salarios por hora más altos. Concretamente, por cada año de escolaridad adicional se espera que una persona tenga, en promedio, un salario promedio .54 mil pesos mayor.\nAjuste y residuos\rComo podemos recordar, lo que se espera es que exista una relación lineal entre \\(x\\) e \\(y\\). La recta de regresión presentada en la siguiente figura representa los valores predichos para \\(y\\) por cada valor de \\(x\\). No obstante, no siempre los modelos que estimamos permiten ajustarse de manera perfecta a la variabilidad de los datos, lo que implica que existirá una diferencia entre los valores predichos para \\(y\\), respecto de los valores observados en la muestra. A esta diferencia entre \\(\\hat{y}\\) e \\(y\\) se denomina residuo.\nsjPlot::plot_scatter(wage1, x = educ, y = wage,\rtitle = \u0026quot;Relación entre salarios (en miles de pesos) por hora y años de escolaridad\u0026quot;,\rfit.line = \u0026quot;lm\u0026quot;)\rAquellas observaciones que estén por sobre la recta serán residuos positivos o subestimaciones, pues en estos casos \\(\\hat{y}\u0026gt;y\\), de modo que \\(\\hat{y}-y \u0026gt; 0\\). Por el contrario, las observaciones bajo la recta constituyen residuos negativos o sobrestimaciones. Del mismo modo, los valores que se encuentran sobre la recta de la regresión fueron predichos de forma precisa por el modelo, por lo cual sus residuos tenderán a acercarse a cero.\nEn ese sentido, su objetivo como analistas de datos será hallar una recta que minimice lo más que se pueda el valor de los residuos, en tanto ello es indicativo de un modelo que permite explicar adecuadamente la variabilidad en \\(y\\) en razón de la variabilidad en \\(x\\). Como se señaló al final del práctico anterior, la minimización de la suma de los residuos al cuadrado o \\(SS_{residual}\\) permite optimizar la estimación de la recta de regresión: a esto se denomina método de Mínimos Cuadrados Ordinarios (MCO) (u OLS en inglés). La suma de los residuos se realiza al cuadrado para evitar que residuos positivos y negativos se anulen entre sí.\nSin embargo, dado que un mismo modelo de regresión puede representar distintas distribuciones de datos con distintos residuos, es necesario estimar estadísticos que reflejen la bondad de ajuste del modelo estimado. Así, podemos encontrar información que nos permita afirmar qué tan bien el modelo representa la distribución de los datos, o qué tan buena es la predicción estimada. Si bien para ello se podría simplemente calcular la cantidad de residuos generados por el modelo, ello desembocaría en un valor de difícil interpretación en términos de ajuste. Para ello se recurre a un estadístico llamado \\(R^2\\), que permite representar la bondad de ajuste del modelo de forma sencilla.\nEste estadística varía entre 0 y 1, y da cuenta del porcentaje de la varianza de \\(y\\) que podemos explicar con \\(x\\). Un modelo que genera menos residuos, en consecuencia, también presenta un mayor valor en el estadístico \\(R^2\\). Un modelo donde todos los valores observados se ajustan perfectamente a la recta de regresión estimada presenta un \\(R^2 = 1\\).\n\r\r2. Calculando \\(R^2\\)\rEste estadístico se puede representar de la siguiente forma\n\\[\r\\begin{equation}\rR^2 = \\frac{SS_{reg}}{SS_{tot}}\r\\end{equation}\r\\]\r, donde\n\r\\(SS_{reg}\\): corresponde a la suma de cuadrados de la regresión, y expresa la diferencia entre el valor predicho \\(\\hat{y}\\) y el promedio de la variable explicada \\(\\bar{y}\\). Esta valor se interpreta como la parte de \\(y\\) que es posible conocer si se conoce \\(x\\), o ¿qué tan útil resulta \\(x\\) para saber sobre la variabilidad de \\(y\\), más allá de \\(\\bar{y}\\)? Para ello, sustraemos al valor predicho para cada caso el promedio de \\(y\\) y elevamos ese valor al cuadrado, para después sumar todos esos valores:\r\r\\[\rSS_{reg} = \\sum_{i=1}^{n}(\\hat{y} - \\bar{y})^2\r\\]\n\r\\(SS_{tot}\\): corresponde a la suma total de cudrados, es decir, la suma de las diferencias entre los valores observados de \\(y\\) y su promedio \\(\\bar{y}\\), lo cual representa la varianza total de \\(y\\):\r\r\\[\rSS_{tot} = \\sum_{i=1}^{n}(y - \\bar{y})^2\r\\]\nConsiderando la ecuación de la recta de regresión de salario por hora sobre años de escolaridad\n\\[\r\\begin{equation}\r\\hat{y} = -.9 + .54 x_{i}\r\\end{equation}\r\\]\rEstimamos\n\rpredy: los valores predichos para \\(y\\) para cada una de las observaciones en la muestra,\rdifpredprom: el cuadrado de la diferencia entre los valores predichos para \\(y\\) y el promedio de \\(y\\),\rdifobsprom: el cuadrado de la diferencia entre los valores observados para \\(y\\) y el promedio de \\(y\\),\r\rwage1$predy = -.9+(.54*wage1$educ)\rwage1$difpredprom = (wage1$predy-mean(wage1$wage))^2\rwage1$difobsprom = (wage1$wage-mean(wage1$wage))^2\rUtilizamos sum() para estimar \\(SS_{reg}\\) y \\(SS_{tot}\\)\nsum(wage1$difobsprom)\r## [1] 7160.414\rsum(wage1$difpredprom)\r## [1] 1173.894\rLuego, reemplazamos y obtenemos\n\\[\r\\begin{equation}\rR^2 = \\frac{SS_{reg}}{SS_{tot}} = \\frac{1173.894}{7160.414} = 0.164\r\\end{equation}\r\\]\nEntonces, es posible señalar que el porcentaje de la varianza de los salarios por hora wage que es posible relacionar a los años de escolaridad educ corresponde al \\(16.4\\)%. Asimismo, un \\(83.6\\)% de la varianza de los salarios porn hora no está relacionada a los años de escolaridad.\nPor supuesto, no es necesario realizar todo este cálculo manualmente para conocer la bondad de ajuste de nuestro(s) modelos. Funciones como texreg() (utilizada el práctico pasado) o summary presentan este estadístico en su output:\nsummary(mod)\r## ## Call:\r## lm(formula = wage ~ educ, data = wage1)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -5.3396 -2.1501 -0.9674 1.1921 16.6085 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.90485 0.68497 -1.321 0.187 ## educ 0.54136 0.05325 10.167 \u0026lt;0.0000000000000002 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 3.378 on 524 degrees of freedom\r## Multiple R-squared: 0.1648, Adjusted R-squared: 0.1632 ## F-statistic: 103.4 on 1 and 524 DF, p-value: \u0026lt; 0.00000000000000022\rEn este caso, el estadístico se presenta en la penúltima fila del output, luego del texto Multiple R-squared:. Podemos ver que el valor es bastante similar a la estimación a mano realizada. Como señalamos, lo esperado es obtener un \\(R^2\\) lo más elevado posible. Sin embargo, esto no es lo único que importa a la hora de estimar un modelo de regresión lineal: es fundamental que nuestro modelo esté fundamentado teórica y empíricamente, además de que este y los datos cumplan con una serie de supuestos que permiten asegurar que la estimación realizada es válida en términos estadísticos. Uno de estos supuestos es, por supuesto, que la muestra extraída sea probabilística y representativa de la población, a modo de poder realizar inferencias estadísticamente fundadas respecto de la relación entre \\(x\\) e \\(y\\) a nivel poblacional.\nPara poder incorporar el efecto del diseño muestral en la población, independiente de si este es simple o complejo, debemos acudir a funciones distintas a lm(). Así, utilizaremos los paquetes srvyr y survey para elaborar un objeto encuesta y estimar modelos de regresión\n\r3. Estimando un modelo de regresión lineal simple considerando un diseño muestral simple\rComo hemos visto anteriormente, el modelo de regresión lineal tiene como estadístico base la media de \\(x\\) e \\(y\\). En este caso, \\(\\bar{x} = 12.56\\) y \\(\\bar{y} = 5.89\\). De incorporar el diseño muestral en la estimación de la media de ambas variables ¿se presentarán diferencias? Para saberlo, primero debemos crear un objeto encuesta que nos permita incorporar el diseño muestral de los datos en la estimación. En este caso, asumiremos que se trabaja con datos producidos a partir de un muestreo aleatorio simple. Además, crearemos un ponderador ficticio pond que nos permita realizar este ejercicio adecuadamente. Utilizaremos as_survey_design() de srvyr para crear nuestro objeto encuesta\n#Creamos el ponderador ficiticio\rnpond \u0026lt;- 526\rpond \u0026lt;- MCMCpack::rdirichlet(1, runif(npond)) |\u0026gt; as.vector()\rsum(npond)\r## [1] 526\rall(dplyr::between(pond, 0, 1))\r## [1] TRUE\rwage1 = cbind(wage1, pond)\renc = wage1 %\u0026gt;% as_survey_design(weights = pond) #Especificamos la variable del ponderador\rLuego, utilizamos survey_mean() de survey para estimar la media de ambas variables considerando el diseño muestral de los datos\nenc %\u0026gt;%\rsummarise(x=survey_mean(educ))\r## # A tibble: 1 × 2\r## x x_se\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 12.6 0.202\renc %\u0026gt;%\rsummarise(y=survey_mean(wage))\r## # A tibble: 1 × 2\r## y y_se\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 6.01 0.314\rPodemos ver que, a nivel poblacional, los valores estimados eran 12.56 y 5.89 para \\(x\\) e \\(y\\), respectivamente. Sin embargo, al considerar el diseño muestral en la estimación de estos valores, la media calculada cambia a 12.63 e 6.22, respectivamente. La incorporación de ponderadores en la estimación permite ajustar esta última a la probabilidad de cada uno de los sujetos de ser elegidos en la muestra. De ese modo, podemos estimar los valores de \\(\\bar{x}\\) e \\(\\bar{y}\\) a nivel poblacional, considerando el error muestral en la estimación.\nLo mismo sucede con los valores estimados para \\(\\beta_0\\) y \\(\\beta_1\\): incorporar el diseño muestral en la estimación del modelo de regresión permite ajustar los valores obtenidos para el intercepto y los coeficientes de regresión, acercándolos al parámetro poblacional. Para llevar esto a cabo en R recurrimos a svyglm() de survey, que permite estimar distintos modelos de regresión (que no revisaremos en este curso), entre los cuales se encuentra el modelo de regresión lineal, considerando el diseño muestral de los datos. El código se construye de manera muy similar a como lo hacíamos con lm(). Las únicas salvedades son\n\rEn lugar de especificar los datos, debemos especificar el objeto encuesta generado, y\rDado que esta función permite estimar diversos tipos de modelos lineales generalizados, debemos especificar en el argumento family = que el modelo que deseamos estimar es lineal.\r\rmod_enc = svyglm(wage ~ educ, #Especificamos la fórmula\rdesign = enc, #Especificamos el objeto encuesta\rfamily = gaussian(link = \u0026quot;identity\u0026quot;)) #Especificamos el modelo lineal\rComparemos los modelos con y sin la consideración el diseño muestral en su estimación:\n## ## ====================================\r## Sin Con ## ------------------------------------\r## (Intercept) -0.90 -0.88 ## (0.68) (1.36) ## educ 0.54 *** 0.55 ***\r## (0.05) (0.12) ## ------------------------------------\r## R^2 0.16 ## Adj. R^2 0.16 ## Num. obs. 526 526 ## Deviance 6626.61 ## Dispersion 12.62 ## ====================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rEs posible apreciar que los valores estimados difieren ligeramente para ambos modelos. Ello involucra tanto el intercepto y el coeficiente de regresión, como a sus errores estándar y medidas de ajuste. Esto significa que la inclusión del diseño muestral en la estimación del modelo tiene consecuencias para la inferencia estadística que puede hacerse a partir de él. De este modo se puede justificar la incorporación del diseño muestral en la estimación de modelos de regresión siempre que sea posible, pues mejora su validez al mejorar su precisión, acercando el intercepto y los coeficientes generados a los valores que alcanzan en la población.\n\rResumen\rEn este práctico aprendimos las diferencias de estimar modelos de regresión lineal simple con y sin la incorporación del diseño muestral complejo en sus estimaciones. Además, a través del estadístico \\(R^2\\), aprendimos a analizar la bondad de ajuste de los modelos estimados.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ca59bddfe5ef26a5cc8927f6e3bdd476","permalink":"/example/05-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/05-practico/","section":"example","summary":"0. Objetivo del práctico\rEl presente práctico tiene tres objetivos:\nAnalizar la bondad de ajuste de los modelos de regresión lineal simple estimados a través del estadístico \\(R^2\\).","tags":null,"title":"Regresión lineal simple con diseño muestral y bondad de ajuste","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo del práctico\rEl presente práctico tiene dos objetivos:\nComprender las implicancias de la incorporación de más de un predictor en modelos de regresión lineal.\n\rAprender a estimar una regresión lineal múltiple en R con lm().\n\r\rMateriales de la sesión\rTal como en la sesión anterior, en este práctico se utilizarán los datos sobre salarios utilizados en el capítulo 2 del libro Introducción a la econometría de J.W. Wooldridge (2015).\nAsimismo, la realización de este práctico requiere la carga de diversos paquetes que nos permitirán explorar los datos y presentar los modelos estimados.\nif (!require(\u0026quot;pacman\u0026quot;)) install.packages(\u0026quot;pacman\u0026quot;) # Instalamos pacman en caso de necesitarlo\rpacman::p_load(wooldridge, #Para descargar los datos\rdplyr, #Para procesar datos\rsjmisc, #Para explorar los datos\rsjPlot, #Para explorar los datos\rsrvyr, #Para crear un objeto encuesta\rsurvey, #Para realizar estimaciones incorporando el diseño muestral\rtexreg) #Para presentar el modelo de regresión estimado\rdata(\u0026quot;wage1\u0026quot;) #Cargamos los datos\rwage1 = select(wage1, wage, educ, exper) #Seleccionamos sólo las variables por analizar\r\r\r1. Volviendo a explorar los datos\rSi bien en este práctico volveremos a analizar el efecto de los años de escolaridad sobre los salarios por hora, ahora incorporaremos una nueva variable explicativa: los años de experiencia laboral.\n\rwage (\\(y\\)): indica el salario por hora en miles de pesos de cada persona en los datos.\reduc (\\(x_1\\)): indica el número de años de escolaridad de cada persona en los datos.\rexper (\\(x_2\\)): indica los años de experiencia laboral de cada persona en los datos.\r\rLas seleccionaremos utilizando la función select() de dplyr, a modo de trabajar con un set de datos más acotado\nwage1 = select(wage1, wage, educ, exper) #Seleccionamos sólo las variables por analizar\rRecordemos la distribución de estas variables:\n## Warning: Removed 1 rows containing missing values (geom_bar).\rEn este caso, la variable por explicar sigue siendo wage (\\(y\\)), a partir de la cual estimaremos un modelo de regresión lineal múltiple sobre educ (\\(x_1\\)) y exper (\\(x_2\\)). Un modelo de regresión lineal múltiple se puede expresar a partir de la siguiente ecuación:\n\\[\r\\begin{equation}\r\\hat{y} = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2}\r\\end{equation}\r\\]\rDonde\n\r\\(\\beta_0\\): Corresponde al intercepto de regresión.\n\r\\(\\beta_1\\): Corresponde a la pendiente estimada para la función de regresión lineal de los salarios por hora (\\(y\\)) sobre los años de escolaridad (\\(x_1\\)). Así, por cada unidad que aumente \\(x_1\\) (en este caso, por cada año de escolaridad extra), el valor estimado \\(\\hat{y}\\) para los salarios por hora aumentará o disminuirá en \\(\\beta_1\\).\n\r\\(\\beta_2\\): Corresponde a la pendiente estimada para la función de regresión lineal de los salarios por hora (\\(y\\)) sobre los años de experiencia laboral (\\(x_2\\)). Así, por cada unidad que aumente \\(x_1\\) (en este caso, por cada año de experiencia laboral), el valor estimado \\(\\hat{y}\\) para los salarios por hora aumentará o disminuirá en \\(\\beta_2\\).\n\r\rEn este caso, se podría plantear la hipótesis de que tanto educ como exper debiesen tener un efecto positivo sobre wage. Es decir, que\n\rQuienes tengan más años de escolaridad debiesen tender, en promedio, valores predichos más altos que quienes tengan menos años de escolaridad. Así, se espera que \\(\\beta_1\u0026gt;0\\); y\n\rQuienes tengan más años de experiencia laboral debiesen tender, en promedio, valores predichos más altos que quienes tengan menos años de experiencia laboral. Así, se espera que \\(\\beta_2\u0026gt;0\\).\n\r\rComo sabemos, existe una correlación de 0.41 entre salarios por hora y años de escolaridad:\n## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;\rPor otra parte, esperamos que exista una asociación positiva entre salarios por hora y años de experiencia laboral\nsjPlot::plot_scatter(wage1, x = exper, y = wage,\rtitle = \u0026quot;Relación entre salarios (en miles de pesos) por hora y años de experiencia laboral\u0026quot;,\rfit.line = \u0026quot;lm\u0026quot;)\r## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;\rComo podemos ver, la pendiente de la recta de regresión presentada no tiene una pendiente tan acentuada, lo cual sería indicativo de una baja relación entre ambas variables. Sin embargo, puede surgir la duda respecto de qué tan relacionadas están nuestras dos variables explicativas. Explorémoslo\nsjPlot::plot_scatter(wage1, x = educ, y = exper,\rtitle = \u0026quot;Relación entre años de escolaridad y años de experiencia laboral\u0026quot;,\rfit.line = \u0026quot;lm\u0026quot;)\r## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;\rLa siguiente tabla presenta los coeficientes de correlación de Pearson para todas las variables por analizar:\n\r\rwage\r\reduc\r\rexper\r\r\r\rwage\r\r\r\r\r\r\reduc\r\r0.406***\r\r\r\r\r\rexper\r\r0.113**\r\r-0.300***\r\r\r\r\rComputed correlation used pearson-method with listwise-deletion.\r\r\r\rComo podemos ver, la asociación entre los años de experiencia laboral y los años de escolaridad es negativa y más fuerte que la correlación entre los primeros y el salario por hora. ¿Cómo puede esto afectar a la estimación de nuestro modelo? ¿qué efecto puede tener sobre la magnitud y el sentido de los coeficientes estimados? ¿cómo saber si vale la pena incorporar nuevas variables en el análisis? A continuación abordaremos todas estas inquietudes, retomando los conceptos que hemos estado revisando en las clases anteriores.\n\r2. Estimando modelos de regresión lineal simple y múltiple con lm()\rEn términos de código, la estimación de modelos de regresión lineal simple no distan mucho de la estimación de modelos de regresión lineal múltiple. Estimemos el modelo para salarios por hora sobre años de escolaridad\n\\[\r\\begin{equation}\r\\hat{wage} = \\beta_0 + \\beta_1educ_{i}\r\\end{equation}\r\\]\nm1 = lm(wage ~ educ, data = wage1)\rLuego, el modelo para salarios por hora sobre años de experiencia laboral\n\\[\r\\begin{equation}\r\\hat{wage} = \\beta_0 + \\beta_2exper_{i}\r\\end{equation}\r\\]\nm2 = lm(wage ~ exper, data = wage1)\rPor último, el modelo para salarios por hora sobre años de escolaridad y años de experiencia laboral\n\\[\r\\begin{equation}\r\\hat{wage} = \\beta_0 + \\beta_1educ_{i} + \\beta_2exper_{i}\r\\end{equation}\r\\]\nm3 = lm(wage ~ educ + exper, data = wage1)\rComo podemos ver, la única diferencia entre la estimación de un modelo de regresión lineal simple y uno múltiple con lm() es la incorporación de todas las variables explicativas, una tras otra, separadas por + (signo más).\nComparemos los tres modelos:\n## ## ===============================================\r## Modelo 1 Modelo 2 Modelo 3 ## -----------------------------------------------\r## (Intercept) -0.90 5.37 *** -3.39 ***\r## (0.68) (0.26) (0.77) ## educ 0.54 *** 0.64 ***\r## (0.05) (0.05) ## exper 0.03 ** 0.07 ***\r## (0.01) (0.01) ## -----------------------------------------------\r## R^2 0.16 0.01 0.23 ## Adj. R^2 0.16 0.01 0.22 ## Num. obs. 526 526 526 ## ===============================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rConsiderando las ecuaciones formuladas genéricamente más arriba, los modelos estimados se puede expresar así:\n\rModelo 1\r\\[\r\\begin{equation}\r\\hat{wage} = -.9 + .54educ_{i}\r\\end{equation}\r\\]\rModelo 2\r\r\\[\r\\begin{equation}\r\\hat{wage} = 5.37 + 0.03exper_{i}\r\\end{equation}\r\\]\n\rModelo 3\r\r\\[\r\\begin{equation}\r\\hat{wage} = -3.39 + .64educ_{i} + .07exper_{i}\r\\end{equation}\r\\]\nHay varias diferencias entre los tres modelos que podemos advertir:\n\rEl valor del intercepto de regresión es distinto entre los tres modelos.\n\rLos valores de los coeficientes de regresión estimados para ambas variables son diferentes al incorporar ambas variables en conjunto.\n\rLa bondad de ajuste de los tres modelos expresada a través del estadístico \\(R^2\\) también difiere en los tres modelos, siendo mayor en el modelo 3 (\\(R^2\\) = .22).\n\rMientras que en los modelos 1 y 2 los estadísticos \\(R^2\\) y \\(R^2\\) Ajustado (Adj. \\(R^2\\)) son equivalentes, en el modelo 3 el valor de \\(R^2\\) (.23) y \\(R^2\\) Ajustado (.22) difieren en .01.\n\r\rDe ello podemos deducir que:\n\rLos años de escolaridad permiten explicar mejor que los años de experiencia laboral los salarios por hora promedio. Esto, porque\r\rEl \\(R^2\\) del modelo 1 (.16) es mayor que el del modelo 2 (.01).\rLa magnitud del coeficiente de regresión de años de escolaridad es mayor que la del coeficiente estimado para años de experiencia laboral.\r\rEl efecto estimado de los años de escolaridad y años de experiencia laboral sobre los salarios por hora es positivo, tal como se planteó en la hipótesis al inicio del práctico.\rEl modelo 3 permite explicar mejor la variabilidad de \\(y\\) que los modelos 2 y 1.\rEl valor estimado para el estadístico \\(R^2\\) ajustado tiende a ser penalizado cuando se incorpora más de una variable explicativa; es decir, en modelos de regresión lineal múltiple, \\(R^2 \u0026gt; Adj.R^2\\). Por eso, en modelos múltiples es preferible evaluar la bondad de ajuste en base al estadístico ajustado, en la medida que es un criterio más estricto para definir qué tan bien las variables explicativas en su conjunto permiten explicar la variabilidad de \\(y\\).\r\r¿Por qué sucede todo esto al incorporar una nueva variable explicativa? Para comprenderlo, recurriremos al concepto de parcialización.\n\r3. La parcialización\rComo pudimos ver anteriormente, educ está correlacionado negativa y moderadamente (R = -.3) con exper. Esto tiene como consecuencia que una parte del efecto de educ sobre wage es compartida por exper, y viceversa, lo cual genera cambios tanto en la estimación de los coeficientes de regresión como en la bondad de ajuste. Recordemos que lo que esperamos hacer con un modelo de estas características es aislar el efecto de \\(x_1,x_2,...,x_n\\) sobre \\(y\\). Es decir: poder analizar el efecto de \\(x_1\\) sobre \\(y\\), manteniendo constante el efecto del resto de variables involucradas en la variabilidad de \\(y\\). Considerando nuestro modelo 3 \\(\\hat{wage} = -3.39 + .64educ_{i} + .07exper_{i}\\), ello se leería de la siguiente manera:\n\rPor cada año de escolaridad adicional se espera que, en promedio, el salario por hora predicho aumente en .64 mil pesos, sin importar los años de experiencia que tenga la persona. Así, una persona con 20 años de experiencia, pero con 17 años de escolaridad debiese percibir un salario por hora promedio de 8.89 mil pesos; mientras se espera que, en promedio, alguien con los mismos años de experiencia laboral y 12 años de escolaridad obtenga un salario por hora de 5.69 mil pesos, lo cual expresa una diferencia media de 3.2 mil pesos.\n\rPor cada año de experiencia laboral adicional se espera que, en promedio, el salario por hora predicho aumente en .07 mil pesos, sin importar los años de experiencia que tenga la persona. Así, una persona con 12 años de escolaridad, pero con 20 años de experiencia laboral debiese percibir un salario por hora promedio de 5.69 mil pesos; mientras se espera que, en promedio, alguien con los mismos años de escolaridad y 10 años de experiencia laboral obtenga un salario por hora de 4.99 mil pesos, lo cual expresa una diferencia media de 0.7 mil pesos.\n\r\rPara poder realizar un análisis “manteniendo constante el efecto del resto de factores”, empleamos el procedimiento de parcialización, que consiste en remover la covarianza común que existe entre los predictores. A ello se le denomina efecto parcial, en la medida que estima regresión considerando solamente el efecto de \\(x_n\\) sobre \\(y\\) que no es compartido con los otros predictores.\r¿Cómo saber cuál es la magnitud del efecto común a ambas variables y extraerlo? Para ello podemos modelar una regresión simple en que los predictores son las variables del modelo. En este caso, estimar un modelo que mida el efecto de educ sobre exper. Ello nos permitirá calcular, a su vez, los residuos del modelo entre las variables explicativas, que representa la parte de \\(x_1\\) que no es explicada por \\(x_2\\). A su vez, el coeficiente de regresión \\(\\beta_1\\) representa todo lo compartido entre educ y exper. Estimemos el modelo:\nmod_p = lm(educ ~ exper, wage1)\rsummary(mod_p)\r## ## Call:\r## lm(formula = educ ~ exper, data = wage1)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -12.258 -1.358 -0.236 1.721 6.170 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 13.602708 0.185024 73.519 \u0026lt; 0.0000000000000002 ***\r## exper -0.061113 0.008504 -7.187 0.0000000000023 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 2.644 on 524 degrees of freedom\r## Multiple R-squared: 0.08973, Adjusted R-squared: 0.08799 ## F-statistic: 51.65 on 1 and 524 DF, p-value: 0.000000000002295\rAsí\n\\[\r\\begin{equation}\r\\hat{educ} = 13.60 + 0.06exper_{i}\r\\end{equation}\r\\]\nEstimemos los residuos para cada observación; es decir, la diferencia entre el valor predicho y el observado que, en este caso, representa la varianza no explicada de los años de experiencia laboral sobre los años de escolaridad.\npred = fitted.values(mod_p)\rres = residuals(mod_p)\rwage1 = cbind(wage1, pred, res)\rAhora hagamos una regresión lineal de wage sobre los residuos estimados para el modelo de educ sobre exper\nmod_res = lm(wage ~ res, wage1)\rscreenreg(list(m3, mod_res), custom.model.names = c(\u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;))\r## ## ===================================\r## Modelo 3 Modelo 4 ## -----------------------------------\r## (Intercept) -3.39 *** 5.90 ***\r## (0.77) (0.14) ## educ 0.64 *** ## (0.05) ## exper 0.07 *** ## (0.01) ## res 0.64 ***\r## (0.05) ## -----------------------------------\r## R^2 0.23 0.21 ## Adj. R^2 0.22 0.21 ## Num. obs. 526 526 ## ===================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rPodemos ver que el coeficiente estimado para educ en el modelo 3 es igual que aquel estimada para el modelo 4. Es decir, el coeficiente parcializado para los años de escolaridad estimado en el modelo 3 representa el efecto de la parte de educ que no es explicada por exper sobre wage. Como pueden haber intuido, la parcialización es un procedimiento que lm() realiza automáticamente a la hora de estimar los modelos, pese a lo cual es fundamental comprenderlo adecuadamente para poder entender qué significa analizar el efecto de \\(x_n\\) sobre \\(y\\) ceteris paribus.\nEn síntesis: la parcialización nos permite estimar y analizar el efecto parcial de \\(x_n\\) sobre \\(y\\), controlando el efecto de otras variables sobre \\(y\\).\n\rResumen\rEn este práctico aprendimos las diferencias existentes entre modelos de regresión lineal simple y múltiple, poniendo especial atención al concepto de parcialización.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aef6a50c214467a47ab3bb2d54eee2ab","permalink":"/example/06-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/06-practico/","section":"example","summary":"0. Objetivo del práctico\rEl presente práctico tiene dos objetivos:\nComprender las implicancias de la incorporación de más de un predictor en modelos de regresión lineal.\n\rAprender a estimar una regresión lineal múltiple en R con lm().","tags":null,"title":"Regresión lineal múltiple","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo del práctico\rEl presente práctico tiene dos objetivos:\nAprender a estimar una regresión lineal múltiple en R con lm().\n\rAprender a interpretar modelos de regresión lineal múltiple con variables explicativas categóricas.\n\r\rMateriales de la sesión\rTal como en la sesión anterior, en este práctico se utilizarán los datos sobre salarios utilizados en el capítulo 2 del libro Introducción a la econometría de J.W. Wooldridge (2015). En este caso, cargaremos los datos ya procesados.\ndata = readRDS(url(\u0026quot;https://github.com/statistics-R/practico-7/raw/main/data.rds\u0026quot;))\rAsimismo, la realización de este práctico requiere la carga de diversos paquetes que nos permitirán explorar los datos y presentar los modelos estimados.\nif (!require(\u0026quot;pacman\u0026quot;)) install.packages(\u0026quot;pacman\u0026quot;) # Instalamos pacman en caso de necesitarlo\rpacman::p_load(wooldridge, #Para descargar los datos\rdplyr, #Para procesar datos\rggplot2,#Para graficar\rsjmisc, #Para explorar los datos\rsjPlot, #Para explorar los datos\rtexreg) #Para presentar el modelo de regresión estimado\r\r\r1. Volviendo a explorar los datos\rVolvemos a encontrarnos con:\n\rwage (\\(y\\)): indica el salario por hora en miles de pesos de cada persona en los datos.\reduc (\\(x_1\\)): indica el número de años de escolaridad de cada persona en los datos.\rexper (\\(x_2\\)): indica los años de experiencia laboral de cada persona en los datos.\r\rSin embargo, ahora agregamos una variable categórica:\n\rrama (\\(x_3\\)) : actividad económica a la que se dedica la empresa donde trabaja.\r\rUtilicemos frq() de sjmisc para explorar esta nueva variable. Podemos ver que casi el 50% de la muestra trabaja en comercio.\nLas seleccionaremos utilizando la función select() de dplyr, a modo de trabajar con un set de datos más acotado\nRecordemos la distribución de estas variables:\nPodríamos preguntarnos cómo se distribuyen los salarios por hora en cada actividad económica\nVemos que Información y comunicaciones presenta el promedio más alto (6.86 mil), seguido por Manufactura (6.65 mil) y Construcción (5.96 mil). Por su parte, los promedios más bajos corresponden a Servicios (4.34 mil) y Comercio (4.79 mil).\nEn este caso, la variable por explicar sigue siendo wage (\\(y\\)), a partir de la cual estimaremos un modelo de regresión lineal múltiple sobre educ (\\(x_1\\)), exper (\\(x_2\\)) y rama (\\(x_3\\)). Sin embargo, la inclusión de un predictor categórico requiere de una categoría de referencia con base en la cual sea posible estimar diferencias promedio para cada una de las otras categorías. En el modelo por estimar, esto se reflejará en la estimación de \\(k-1\\) coeficientes de regresión, siendo \\(k\\) el número de categorías que presenta nuestra variable explicativa categórica. En este caso, \\(k_{rama} = 5\\), de modo que el modelo estimado presentará 4 coeficientes de regresión para la actividad económica, donde cada uno de ellos reflejará las diferencias promedio estimadas respecto de la categoría de referencia.\nPero ¿qué es una categoría de referencia? Por defecto, en nuestras variables categóricas corresponde al primer valor de la variable, siguiendo una prioridad alfanumérica. Ello quiere decir que las categorías que inicien con el número “1” tiene más prioridad que las que inician con el número “4”, así como que las categorías que inician con la letra “a” tienen una mayor prioridad frente a las que inician con “d”. Podemos utilizar la función factor() para modificar manualmente el orden de nuestras variables categóricas (cuyo tipo de dato debe ser factor). A modo de ejemplo, crearemos\nUna nueva variable que tenga como categoría de referencia el valor 3. Info. y com., utilizando la función ref_lvl() de sjmisc, y\rUna nueva variable factor cuyos niveles sigan el promedio de salarios por hora para cada categoría de actividad económica:\r\r#Transformamos nuestra variable en factor\rdata$rama = factor(data$rama)\r#Creamos una nueva variable con 3. Info y com. como categoría de referencia\rdata$rama_info = ref_lvl(data$rama, lvl = \u0026quot;3. Info. y com.\u0026quot;)\r#Y otra con la que ordenamos las categorías de forma ascendente a partir de los promedios en wage\rdata$rama_wage = factor(data$rama, levels = c(\u0026quot;5. Servicios\u0026quot;,\r\u0026quot;4. Comercio\u0026quot;, \u0026quot;1. Construccion\u0026quot;, \u0026quot;2. Manufactura\u0026quot;,\r\u0026quot;3. Info. y com.\u0026quot;))\rUn modelo de regresión lineal múltiple con predictores categóricos se puede expresar a partir de la siguiente ecuación:\n\\[\r\\begin{equation}\r\\hat{y} = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{k=k+1}, ..., \\beta_3x_{k=k}\r\\end{equation}\r\\]\rDonde\n\r\\(\\beta_0\\): Corresponde al intercepto de regresión.\n\r\\(\\beta_1\\): Corresponde a la pendiente estimada para la función de regresión lineal de los salarios por hora (\\(y\\)) sobre los años de escolaridad (\\(x_1\\)). Así, por cada unidad que aumente \\(x_1\\) (en este caso, por cada año de escolaridad extra), el valor estimado \\(\\hat{y}\\) para los salarios por hora aumentará o disminuirá en \\(\\beta_1\\).\n\r\\(\\beta_2\\): Corresponde a la pendiente estimada para la función de regresión lineal de los salarios por hora (\\(y\\)) sobre los años de experiencia laboral (\\(x_2\\)). Así, por cada unidad que aumente \\(x_1\\) (en este caso, por cada año de experiencia laboral), el valor estimado \\(\\hat{y}\\) para los salarios por hora aumentará o disminuirá en \\(\\beta_2\\).\n\r\\(\\beta_3x_{k=k+1}\\), …, \\(\\beta_3x_{k=k}\\): Corresponde al coeficiente de regresión estimado para cada una de las categorías de nuestra variable explicativa categórica. En este caso tenemos 5 categorías, de modo que estimaremos 4 coeficientes, que en este caso reflejarán las diferencias promedio de los salarios estimados para quienes se desempeñan en construcción, manufactura, información y comunicaciones, comercio y servicios. Estos, sumados al intercepto \\(\\beta_0\\), indican las diferencias promedio estimadas para cada una de las categorías de actividad económica.\n\r\rEn este caso, lo esperable es que los valores predichos para información y comunicaciones sean mayores que aquellos estimados para el resto de categorías ocupacionales, siguiendo lo presentado en el gráfico de barras anteriormente presentado.\n\r2. Estimando modelos de regresión lineal múltiple con predictores categóricos con lm()\rComo vimos en el práctico anterior, para agregar una nueva variable explicativa a nuestros modelos sólo basta con agregar + variable en nuestro primer argumento. Estimaremos también los modelos con distintas categorías de referencia para compararlos:\n\\[\r\\begin{equation}\r\\hat{wage} = \\beta_0 + \\beta_1educ_{i} + \\beta_2exper_{i} + \\beta_3rama_{2. Manufactura} + \\beta_3rama_{3. Info. y com.} + \\beta_3rama_{4.Comercio} + \\beta_3rama_{5.Servicios} \\end{equation}\r\\]\nm1 = lm(wage ~ educ + exper +rama, data = data)\rm2 = lm(wage ~ educ + exper +rama_info, data = data)\rm3 = lm(wage ~ educ + exper + rama_wage, data = data)\r#Estimamos también los modelos anteriores para comparar ajustes\rm4 = lm(wage ~ educ, data = data)\rm5 = lm(wage ~ exper, data = data)\rm6 = lm(wage ~ educ + exper, data = data)\r## ## ================================================================================================\r## Modelo 1 Modelo 2 Modelo 3 Modelo 4 Modelo 5 Modelo 6 ## ------------------------------------------------------------------------------------------------\r## (Intercept) -0.31 -0.63 -2.45 ** 0.13 4.91 *** -1.83 * ## (0.97) (1.11) (0.93) (0.77) (0.29) (0.87) ## educ 0.48 *** 0.48 *** 0.48 *** 0.42 *** 0.50 ***\r## (0.06) (0.06) (0.06) (0.06) (0.06) ## exper 0.05 *** 0.05 *** 0.05 *** 0.02 0.06 ***\r## (0.01) (0.01) (0.01) (0.01) (0.01) ## rama2. Manufactura -0.18 ## (0.70) ## rama3. Info. y com. -0.33 ## (0.85) ## rama4. Comercio -1.64 ** ## (0.63) ## rama5. Servicios -2.14 ** ## (0.71) ## rama_info1. Construccion 0.33 ## (0.85) ## rama_info2. Manufactura 0.14 ## (0.71) ## rama_info4. Comercio -1.31 * ## (0.65) ## rama_info5. Servicios -1.82 * ## (0.72) ## rama_wage4. Comercio 0.50 ## (0.46) ## rama_wage1. Construccion 2.14 ** ## (0.71) ## rama_wage2. Manufactura 1.96 *** ## (0.54) ## rama_wage3. Info. y com. 1.82 * ## (0.72) ## ------------------------------------------------------------------------------------------------\r## R^2 0.24 0.24 0.24 0.13 0.01 0.18 ## Adj. R^2 0.23 0.23 0.23 0.13 0.01 0.18 ## Num. obs. 311 311 311 311 311 311 ## ================================================================================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rLo primero que hay que observar es que, en los tres modelos, \\(\\beta_1\\) y \\(\\beta_2\\) son iguales. Lo mismo sucede con las medidas de ajuste. Los únicos elementos que se modifican son el intercepto \\(\\beta_0\\) y los coeficientes estimados para cada rama de actividad económica. Ello quiere decir que los modelos son esencialmente los mismos, aunque presentan la información de manera diferente. Entonces, ¿cómo ordenar nuestros factores? ello siempre dependerá de nuestros antecedentes teóricos y empíricos. Por ejemplo, nuestra categoría de referencia puede ser aquella de la cual se esperen los valores más bajos o más altos. Asimismo, nuestra categoría de referencia puede ser aquella en la cual queramos centrar nuestro análisis. Por ejemplo, si alguien nos solicitara un análisis para los asalariados del sector servicios, sería recomendable que aquella fuese nuestra categoría de referencia.\nAsimismo, podemos ver que la inclusión de este predictor categórico permite aumentar el porcentaje de la varianza explicada de \\(y\\) con el modelo en 5 puntos. El \\(R^2\\) de los modelos 1, 2 y 3 es mayor al de los modelos 4, 5 y 6. En este caso, a priori podríamos considerar el que la inclusión de la rama de actividad económica en la explicación de los salarios por hora que reciben las personas de la muestra permite analizar su variabilidad de manera más precisa.\n\r3. Predicción\rUtilicemos el modelo 1 para nuestros análisis\n\\[\r\\begin{equation}\r\\hat{wage} = -0.3 + .48educ_{i} + .05exper_{i} + -0.18rama_{2. Manufactura} + -0.32rama_{3. Info. y com.} + -1.64rama_{4.Comercio} + -2.14rama_{5.Servicios} \\end{equation}\r\\]\nEn base a esa información, podemos señalar que\n\rManteniendo constantes los años de escolaridad y de experiencia laboral se espera que, en promedio, los valores predichos para quienes trabajan en construcción sean los más altos en la muestra. Esto, pues todos los coeficientes de regresión son negativos.\rAsí, en promedio, una persona que trabaje en manufactura gane .18 mil pesos por hora menos que alguien que se emplea en construcción, manteniendo constante el resto de factores.\rDel mismo modo, es espera que una persona que trabaja en servicios reciba una remuneración -2.14 mil pesos inferior a alguien que labora en el sector de construcción.\r\rComo pueden ver, la manera en que ha quedado especificado el modelo permite analizar inmediatamente las diferencias promedio entre la categoría de referencia (en este caso, construcción) respecto de las \\(k-1\\) categorías restantes para las cuales se estimó un coeficiente de regresión. Para comparar el resto de categorías entre sí, podemos a) especificar el modelo con otra categoría de referencia; o b) estimar los valores predichos para cada categoría y comparar ceteris paribus. En este caso, los valores predichos son:\nConstrucción = \\(-0.31\\)\rManufactura = \\(-0.31 - 0.18 = -0.49\\)\rInformación y comunicaciones = \\(-0.31 - 0.18 = -0.63\\)\rComercio = \\(-0.31 - 1.64 = -1.95\\)\rServicios = \\(-0.31 - 2.14 = -2.45\\)\r\rComo podemos ver, los valores esperados indicarían que quienes trabajan en servicios debiese tender a presentar, en promedio, salarios por hora inferiores al resto de actividades económicas. Asimismo, se espera que quienes se desempeñan obtengan, en promedio, salarios \\(-0.63 - -1.95 = 1.32\\) mil pesos inferiores que quienes se dedican a la información y las comunicaciones; y así.\n\rResumen\rEn este práctico aprendimos a analizar predictores categóricos en modelos de regresión lineal múltiple.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3e2e0e520ffafc28ad15380685c0d78e","permalink":"/example/07-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/07-practico/","section":"example","summary":"0. Objetivo del práctico\rEl presente práctico tiene dos objetivos:\nAprender a estimar una regresión lineal múltiple en R con lm().\n\rAprender a interpretar modelos de regresión lineal múltiple con variables explicativas categóricas.","tags":null,"title":"Regresión lineal múltiple y predictores categóricos","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo del práctico\rEl presente práctico tiene dos objetivos:\nAprender a formular y testear hipótesis para coeficientes de regresión lineal.\n\rAprender a formular y testear hipótesis de significancia global para modelos de regresión lineal.\n\r\rMateriales de la sesión\rTal como en la sesión anterior, en este práctico se utilizarán los datos sobre salarios utilizados en el capítulo 2 del libro Introducción a la econometría de J.W. Wooldridge (2015). En este caso, cargaremos los datos ya procesados.\ndata = readRDS(url(\u0026quot;https://github.com/statistics-R/practico-7/raw/main/data.rds\u0026quot;))\rAsimismo, la realización de este práctico requiere la carga de diversos paquetes que nos permitirán explorar los datos y presentar los modelos estimados.\nif (!require(\u0026quot;pacman\u0026quot;)) install.packages(\u0026quot;pacman\u0026quot;) # Instalamos pacman en caso de necesitarlo\rpacman::p_load(wooldridge, #Para descargar los datos\rdplyr, #Para procesar datos\rtexreg) #Para presentar el modelo de regresión estimado\r\r\r1. Volviendo a formular el modelo de regresión lineal múltiple con lm()\rVolvemos a encontrarnos con:\n\rwage (\\(y\\)): indica el salario por hora en miles de pesos de cada persona en los datos.\reduc (\\(x_1\\)): indica el número de años de escolaridad de cada persona en los datos.\rexper (\\(x_2\\)): indica los años de experiencia laboral de cada persona en los datos.\rrama (\\(x_3\\)) : actividad económica a la que se dedica la empresa donde trabaja.\r\rGeneremos el modelo con lm(), y visualicémoslo\nm1 = lm(wage ~ educ + exper +rama, data = data)\rscreenreg(m1)\r## ## ===============================\r## Model 1 ## -------------------------------\r## (Intercept) -0.31 ## (0.97) ## educ 0.48 ***\r## (0.06) ## exper 0.05 ***\r## (0.01) ## rama2. Manufactura -0.18 ## (0.70) ## rama3. Info. y com. -0.33 ## (0.85) ## rama4. Comercio -1.64 ** ## (0.63) ## rama5. Servicios -2.14 ** ## (0.71) ## -------------------------------\r## R^2 0.24 ## Adj. R^2 0.23 ## Num. obs. 311 ## ===============================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rComo sabemos, el modelo nos muestra el valor del intercepto, los coeficientes y el \\(R^2\\) estimado. Sin embargo, hay algunos elementos en los cuales no nos hemos detenido en prácticas anteriores: los valores que se encuentran entre paréntesis, y los asteriscos (*) que se encuentran a la derecha de los coeficientes. En el mismo sentido, no nos hemos detenido en los astericos y valores que se encuentran en la última fila de la tabla. Es hora de revisarlos.\n\r2. Los supuestos de Gauss-Markov de la regresión lineal múltiple\rRecordemos los supuestos formulados en Wooldridge (2015):\nLineal en los parámetros: El modelo poblacional puede expresarse como:\r\r\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_kx_k +u\r\\end{equation}\r\\]\rdonde _0, _1,…, _k son los parámetros (constantes) desconocidos de interés, y \\(u\\) el error aleatorio o término de perturbación no observable\nMuestreo aleatorio: se utilizan datos con muestreo aleatorio con n observaciones, de acuerdo con el modelo poblacional formulado en el punto anterior.\n\rEn la muestra y la población, ninguna variable explicativa es constante, y no existen relaciones lineal exactas entre las variables explicativas.\n\rMedia condicional cero de \\(u\\): el valor esperado del error \\(u\\) para cualquier valor de las variables explicativas es igual a cero, o sea:\n\r\r\\[\r\\begin{equation}\rE(u|x_1, x_2, ... , x_k) = 0\r\\end{equation}\r\\]\r5. Homocedasticidad: el error \\(u\\) presenta la misma varianza para cualquier valor de las variables explicativas; es decir:\n\\[\r\\begin{equation}\rVar(u|x_1, x_2, ... , x_k) = \\sigma^2\r\\end{equation}\r\\]\nSiguiendo estos supuestos, es posible asumir que los estimadores \\(\\beta_j\\) estimados a partir del método MCO son insesgados (supuestos 1 a 4) y eficientes (supuesto 5). Así, el Teorema de Gauss-Markov nos permite afirmar que los \\(\\hat\\beta_j\\) (valor estimado para la muestra) estimados vía MCO son los mejores estimadores lineales insesgados (MELI) para \\(\\beta_j\\) (parámetro poblacional desconocido). Ello implica que es el estimador lineal e insesgado (\\(E(\\hat\\beta) = \\beta\\)) con la menor varianza; o, en el peor de los casos, otros estimadores presentarán, al menos, tanta varianza como los coeficientes estimados vía MCO.\nNo obstante, para poder hacer inferencia tenemos que conocer la distribución muestral de \\(\\hat\\beta_j\\). Los puntos 1 a 5 no nos indican nada respecto de la distribución del estimador. No obstante, podemos considerar:\nNormalidad: El error poblacional \\(u\\) se distribuye normalmente, lo cual podemos considerar si a) el modelo está bien especificado, es decir, se incluyen todos los predictores relevantes y se excluyen los no relevantes; y b) tenemos un \\(n\\) lo suficientemente grande para considerar la aplicación del teorema del límite central, según el cual la distribución de los factores no observados es aproximadamente normal.\r\r\r3. Formulando hipótesis para los coeficientes de regresión\rCuando estimamos un modelo de regresión lineal, esperamos que el efecto de las variables explicativas sobre la variable explicada sea estadísticamente significativo. En este caso, ello quiere decir que lo que esperamos es que exista un efecto de \\(x_n\\) sobre \\(y\\). Estadísticamente, ello se formula:\n\\[\r\\begin{equation}\rH_0: \\beta_n = 0\r\\end{equation}\r\\]\nEs decir, nuestra hipótesis nula, que buscamos rechazar, indica que el valor estimado para el coeficiente será igual a cero. O sea, esperamos que el modelo no nos indique que, por cada unidad que aumente \\(x_n\\), el valor esperado de \\(y\\) aumentará en 0.\n\\[\r\\begin{equation}\rH_1: \\beta_n \\neq 0\r\\end{equation}\r\\]\n\r4. Test de significancia a través de alternativa de una cola\rPor su parte, la hipótesis alternativa planteada en caso de rechazar la hipótesis nula es que el valor estimado del coeficiente sea distinto de cero. No obstante, ¿cómo testeamos esto? para ello recurriremos a la prueba-\\(t\\). Para ello, debemos estimar el valor \\(t\\) de la siguiente manera:\n\\[\r\\begin{equation}\rt_{\\hat\\beta_j} \\equiv \\hat\\beta_j/ee(\\hat\\beta_j)\r\\end{equation}\r\\]\ndonde \\(ee(\\hat\\beta_j)\\) corresponde al error estándar del estimador \\(\\hat\\beta_j\\), que en nuestra tabla se presenta en los valores entre paréntesis bajo los coeficientes. Así, por ejemplo, para educ\n\\[\r\\begin{equation}\rt_{\\hat\\beta_{educ}} = \\frac{\\hat\\beta_{educ}}{ee(\\hat\\beta_{educ})} = \\frac{0.48}{0.06} = 8\r\\end{equation}\r\\]\nDebemos comparar el valor-\\(t\\) calculado con el valor-\\(t\\) crítico para los grados de confianza estimados \\(n-k-1\\), donde \\(n\\) refiere al tamaño muestral y \\(k\\) al número de coeficientes estimados. Para este caso, \\(gl = 311- 6 -1 = 304\\). No olvidemos que si \\(n\u0026gt;120\\), los valores críticos \\(c\\) se aproximarán a los de la distribución normal. Para rechazar la hipótesis nula, esperamos que el valor estimado \\(t_{\\hat\\beta_{educ}}\u0026gt;c\\). Si consideramos un nivel de confianza del 95% (o, por otra parte, un error \\(\\alpha=0.05\\)), el valor-\\(t\\) crítico \\(c= 1.645\\). En este caso, \\(8\u0026gt;1.645\\), por lo cual es posible rechazar la hipótesis nula \\(H_0\\) y afirmar, con un nivel de confainza del 95%, que el efecto de educ sobre wage es distinto de cero; es decir, se acepta la hipótesis alternativa \\(H_1\\). Por el contrario, si ello no se cumple, no podemos rechazar \\(H_0\\), es decir, no podemos afirmar que existe un efecto de los años de escolaridad sobre el salario por hora.\nA esta prueba se le denomina también prueba con alternativas de una cola, pues se estima la probabilidad de que, a determinado nivel de confianza (o de error \\(\\alpha\\)), \\(t_{\\hat\\beta_{educ}}\u0026gt;c\\), o de que el estimador se encuentre en la región de rechazo de la distribución \\(t\\), lo cual nos permite rechazar la hipótesis nula \\(H_0\\).\n\r5. Test de significancia a través de intervalos de confianza\rOtra alternativa es estimar los intervalos de confianza para un nivel de confianza determinado, considerado que el estimador es insesgado en caso del cumplimiento de los supuestos 1-4 de Gauss-Markov. En este caso estimaremos la probabilidad de que, tolerando un nivel de error \\(\\alpha\\), el valor-\\(t\\) estimado se encuentre en la región de rechazo a ambos extremos de la distribución teórica \\(t\\). Para ello, estimamos\n\\[\r\\begin{equation}\r[t_{\\hat\\beta_-j}, t_{\\hat\\beta_j}] \\equiv [\\hat\\beta_{j} - ee(\\hat\\beta_{j}) * t_{n-k-1}^\\frac{1-a}{2}, \\hat\\beta_{j} + ee(\\hat\\beta_{j}) * t_{n-k-1}^\\frac{1-a}{2}]\r\\end{equation}\r\\]\rDémonos cuenta de que no utilizamos \\(\\alpha\\), sino \\(\\alpha/2\\), pues ahora buscamos realizar la prueba en ambas colas de la distribución. Por ejemplo, si queremos hacer una prueba de dos colas al 95% de confianza, la región de rechazo de cada cola se encontrará estimando un valor crítico \\(c\\) menor y mayor a un error del 2.5% en cada cola. En este caso, para educ:\n\\[\r\\begin{equation}\r[t_{\\hat\\beta_{-educ}}, t_{\\hat\\beta_{educ}}] = [0.48 - (0.06 * 1.96), 0.48 + (0.06 * 1.96)] = [0.3624, 0.5976]\r\\end{equation}\r\\]\nComo podemos observar, el intervalo de confianza estimado no incluye al valor \\(0\\), lo cual nos permite rechazar \\(H_0\\), y aceptar la hipótesis alternativa \\(H_1\\) de que, a un nivel de confianza del 95%, los años de escolaridad tienen un efecto sobre los salarios por hora.\n\r6. Cálculo de valor-\\(p\\) en las pruebas \\(t\\).\rAmbos métodos involucran un nivel de arbitrariedad, pues el investigador debe definir de antemano un nivel de confianza que esté dispuesto a tolerar. Ello puede significar ocultar información útil respecto del resultado de la prueba de hipótesis, e.g. tener la posibilidad de rechazar \\(H_0\\) a un nivel de significancia mayor que el escogido. Así, podríamos preguntarnos cual es el nivel más bajo de significancia al que podríamos rechazar \\(H_0\\), lo cual es conocido como valor-\\(p\\) de la prueba de hipótesis. Para ello estimamos la probabilidad de que una variable aleatoria \\(t\\) con determinados grados de confianza, sea mayor que el valor \\(t_{\\hat\\beta_{j}}\\) estimado. Este valor es una probabilidad, por lo cual su rango es [0,1]. En este caso, lm() estima los valores-\\(p\\) automáticamente, según se especifica en la última fila de la tabla, calculando las áreas bajo la función densidad de probabilidad de la distribución \\(t\\). Usualmente, la prueba se hace considerando ambas colas.\n## ## ===============================\r## Model 1 ## -------------------------------\r## (Intercept) -0.31 ## (0.97) ## educ 0.48 ***\r## (0.06) ## exper 0.05 ***\r## (0.01) ## rama2. Manufactura -0.18 ## (0.70) ## rama3. Info. y com. -0.33 ## (0.85) ## rama4. Comercio -1.64 ** ## (0.63) ## rama5. Servicios -2.14 ** ## (0.71) ## -------------------------------\r## R^2 0.24 ## Adj. R^2 0.23 ## Num. obs. 311 ## ===============================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rEn este caso, los valores-\\(p\\) indican que los coeficientes que, si la hipótesis nula es verdadera, un valor absoluto del estadístico \\(t\\) tan grande como el estimado para los coeficientes de educ y exper se observaría menos del 0.1% de las veces. Asimismo, estimar un estadístico \\(t\\) con un valor absoluto como los observados para Comercio y Servicios de rama se observaría menos del 1% de las veces. Para el resto de los casos, el valor-\\(p\\) estimado no es lo suficientemente pequeño como para rechazar la hipótesis nula a un nivel de confianza razonable de, al menos, un 95%.\n\r6. Formulando hipótesis de significancia global\rHasta ahora, hemos revisado test de hipótesis que consideran una única restricción (esperamos que \\(\\beta_n \\neq 0\\)). Ahora bien, es posible buscar probar la hipótesis nula de que un conjunto de variables no tienen efecto sobre \\(y\\), controlando por otro conjunto de variables. Pensemos, por ejemplo, que queremos probar la hipótesis nula de que, controlando por años de escolaridad educ, las variables ocupacionales (exper y rama) no tendrán un efecto estadísticamente significativo sobre wage. En este caso\n\\[\r\\begin{equation}\rH_0: \\beta_{exper} = 0, \\beta_{rama_k} = 0\r\\end{equation}\r\\]\nAl poner múltiples restricciones, estamos realizando una prueba de hipótesis múltiple o conjunta. En este caso, la hipótesis alternativa sería\n\\(H_1: H0\\) no es verdadera.\nO sea, exper y rama sí tienen un efecto sobre wage. Para ello, tenemos que ver qué sucede con la suma de los residualdes cuadrados SRC (\\(SRC = \\sum(y_i-\\hat{y_i})\\)). Si este aumenta lo suficiente al eliminar del modelo a exper y rama (al que denominamos modelo restringido, frente al no restringido), es posible rechazar \\(H_0\\). Comparemos nuestros modelos:\n## ## ================================================\r## No restringido Restringido\r## ------------------------------------------------\r## (Intercept) -0.31 0.13 ## (0.97) (0.77) ## educ 0.48 *** 0.42 *** ## (0.06) (0.06) ## exper 0.05 *** ## (0.01) ## rama2. Manufactura -0.18 ## (0.70) ## rama3. Info. y com. -0.33 ## (0.85) ## rama4. Comercio -1.64 ** ## (0.63) ## rama5. Servicios -2.14 ** ## (0.71) ## ------------------------------------------------\r## R^2 0.24 0.13 ## Adj. R^2 0.23 0.13 ## Num. obs. 311 311 ## ================================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rPodemos ver que el estadístico \\(R^2\\) ajustado del modelo restringido es menor que el del no restringido.\n\r7. Test de significancia global\rDebemos, no obstante, combinar la información del SRC de ambos modelos para obtener un estadístico de prueba que tenga una distribución conocida bajo \\(H_0\\). Este será el estadístico \\(F\\)\n\\[\r\\begin{equation}\rF \\equiv \\frac{(SRC_r-SRC_{nr})/q}{SRC_{nr}/(n-k-1)},\r\\end{equation}\r\\]\nDonde \\(SRC_r\\) es la suma total de cuadrados del modelo restringido; \\(SRC_{nr}\\) es la suma total de cuadrados del modelo no restringido; y \\(q\\) es el número de restricciones a probar. Sin embargo, utilizando el output de nuestro modelo con summary() podemos identificar el estadístico F calculado para el modelo junto con sus grados de confianza de manera sencilla\nsummary(m1)\r## ## Call:\r## lm(formula = wage ~ educ + exper + rama, data = data)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -4.7297 -1.8817 -0.5236 1.0960 16.7215 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.30547 0.97387 -0.314 0.75399 ## educ 0.48349 0.06166 7.841 0.0000000000000762 ***\r## exper 0.05354 0.01270 4.214 0.0000330823141231 ***\r## rama2. Manufactura -0.18412 0.70430 -0.261 0.79394 ## rama3. Info. y com. -0.32825 0.84937 -0.386 0.69942 ## rama4. Comercio -1.64280 0.63204 -2.599 0.00980 ** ## rama5. Servicios -2.14411 0.71002 -3.020 0.00274 ** ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 2.863 on 304 degrees of freedom\r## Multiple R-squared: 0.2422, Adjusted R-squared: 0.2272 ## F-statistic: 16.19 on 6 and 304 DF, p-value: 0.0000000000000003541\rCon esta información es posible estimar el valor-\\(p\\) para el modelo estimado, considerando los grados de confianza del modelo restringido y del modelo no restringido:\npf(16.19, 6, 304, lower.tail = F)\r## [1] 0.0000000000000003572259\rComo podemos observar, este valor indica que la probabilidad de encontrar un valor para el estadístico F como el estimado es muy baja. Ello nos permite caer en la región de rechazo, acetpando la hipótesis alternativa \\(H_1\\) de que \\(H_0\\) es falsa y, en consecuencia, confirmando la significancia global del modelo.\n\rDesafío: estimando la significancia estadística de los coeficientes a mano\rA continuación, se propondrá el siguiente desafío. Quienes logren realizarlo obtendrán una bonificación de 5 décimas en la prueba del curso. Para ello, con el siguiente set de datos\nx = data[sample(nrow(data), size=100),]\rm3 = lm(wage ~ educ + exper +rama, data = data)\rsummary(m3)\r## ## Call:\r## lm(formula = wage ~ educ + exper + rama, data = data)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -4.7297 -1.8817 -0.5236 1.0960 16.7215 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.30547 0.97387 -0.314 0.75399 ## educ 0.48349 0.06166 7.841 0.0000000000000762 ***\r## exper 0.05354 0.01270 4.214 0.0000330823141231 ***\r## rama2. Manufactura -0.18412 0.70430 -0.261 0.79394 ## rama3. Info. y com. -0.32825 0.84937 -0.386 0.69942 ## rama4. Comercio -1.64280 0.63204 -2.599 0.00980 ** ## rama5. Servicios -2.14411 0.71002 -3.020 0.00274 ** ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 2.863 on 304 degrees of freedom\r## Multiple R-squared: 0.2422, Adjusted R-squared: 0.2272 ## F-statistic: 16.19 on 6 and 304 DF, p-value: 0.0000000000000003541\rdeben, manualmente:\nEstimar el valor-\\(t\\) para cada coeficiente del modelo.\rRealizar prueba de hipótesis a una y dos colas.\r\r\rResumen\rEn este práctico aprendimos a formular y testear hipótesis para poder realizar inferencia con nuestros estimadores de MCO.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8901d363a328efdc0a5bd1d6c76db785","permalink":"/example/08-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/08-practico/","section":"example","summary":"0. Objetivo del práctico\rEl presente práctico tiene dos objetivos:\nAprender a formular y testear hipótesis para coeficientes de regresión lineal.\n\rAprender a formular y testear hipótesis de significancia global para modelos de regresión lineal.","tags":null,"title":"Inferencia y predicción","type":"docs"},{"authors":null,"categories":null,"content":"\r\r0. Objetivo del práctico\rEl objetivo de este práctico es aprender a generar e interpretar modelos con transformaciones cuadrática y logarítmica en las variables \\(x\\) e \\(y\\) con lm().\nMateriales de la sesión\rTal como en la sesión anterior, en este práctico se utilizarán los datos sobre precios de casas utilizados en el capítulo 6 del libro Introducción a la econometría de J.W. Wooldridge (2015). En este caso, cargaremos los datos ya procesados. Asimismo, la realización de este práctico requiere la carga de diversos paquetes que nos permitirán explorar los datos y presentar los modelos estimados.\nif (!require(\u0026quot;pacman\u0026quot;)) install.packages(\u0026quot;pacman\u0026quot;) # Instalamos pacman en caso de necesitarlo\r## Loading required package: pacman\rpacman::p_load(wooldridge, #Para descargar los datos\rdplyr, #Para procesar datos\rggplot2,#Para graficar\rsjmisc, #Para explorar los datos\rsjPlot, #Para explorar los datos\rtexreg) #Para presentar el modelo de regresión estimado\rdata(\u0026quot;hprice2\u0026quot;)\r\r\r1. Explorando los datos\rEsta vez trabajaremos con los datos hprice2 sobre precios de casas y medio ambiente. En específico, utilizaremos las variables\nVolvemos a encontrarnos con:\n\rprice (\\(y\\)): indica el precio mediano de las casas en cada comunidad.\rnox (\\(x_1\\)): indica la concentración de óxido nitroso de la comunidad en partes por 100 millones.\rrooms (\\(x_2\\)): indica la media de habitaciones por vivienda en la comunidad.\r\rTambién utilizaremos el logaritmo de las dos primeras variables variables: lprice, lnox.\nGeneremos el modelo con lm(), y visualicémoslo\nm1 = lm(price ~ nox + rooms, data = hprice2)\rscreenreg(m1, custom.model.names = \u0026quot;Modelo 1\u0026quot;)\r## ## ==========================\r## Modelo 1 ## --------------------------\r## (Intercept) -18423.40 ***\r## (3346.66) ## nox -1884.68 ***\r## (253.57) ## rooms 8178.56 ***\r## (418.08) ## --------------------------\r## R^2 0.54 ## Adj. R^2 0.53 ## Num. obs. 506 ## ==========================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rPodemos ver que, mientras el efecto de la concentración de óxido nitroso sobre el precio mediano de las casas es negativo, el número de habitaciones tiene un efecto positivo sobre el precio mediano de tales. Además, en conjunto, ambas variables explican en torno al 53% de la varianza del precio mediano de las casas.\n\r2. Las transformaciones funcionales: la transformación funcional logarítmica\rMuchas veces es posible que las relaciones que existen entre nuestra variable explicada y nuestras variables explicativas no es lineal. Para subsanar este problema, recurriremos a diversas fórmulas, una de las cuales es la transformación logarítmica. En las siguientes clases estaremos revisando otras dos: la transformación funcional cuadrática, y las interacciones entre variables explicativas.\nPara la transformación funcional logarítmica, simplemente tenemos que incorporar, bien como variables predictoras o predichas, el logaritmo natural. Por supuesto, esto sólo aplica para variables numéricas: no es posible ejecutar una transformación funcional logarítmica a una variable cualitativa.\nConsideremos los parámetros del modelo original:\n\\[\r\\begin{equation}\rprice = \\beta_0 + \\beta_1nox + \\beta_2rooms\r\\end{equation}\r\\]\nAl interpretar este modelo, podemos señalar que, por cada unidad que varíe \\(nox\\), el valor predicho para \\(price\\) aumentará o disminuirá en \\(\\beta_1\\) unidades. Cuando aplicamos transformaciones funcionales logarítmicas, las variaciones y el efecto se deben interpretar porcentualmente, según corresponda.\nUna de las limitaciones de esta transformacional funcional es que no puede utilizarse si una variable toma valores negativos o cero.\na) Transformación funcional logarítmica a variable \\(x\\)\rUna de las variaciones que podemos realizar es estimar el modelo transformando logarítmicamente uno de sus predictores. En este caso, implementaremos la transformación funcional sobre \\(nox\\).\n\\[\r\\begin{equation}\rprice = \\beta_0 + \\beta_1log(nox) + \\beta_2rooms\r\\end{equation}\r\\]\nEstimemos el modelo con lm() y comparemos con el modelo original:\nm2 = lm(price ~ lnox + rooms, data = hprice2)\rscreenreg(list(m1,m2), custom.model.names = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;))\r## ## =========================================\r## Modelo 1 Modelo 2 ## -----------------------------------------\r## (Intercept) -18423.40 *** -10237.60 * ## (3346.66) (4125.88) ## nox -1884.68 *** ## (253.57) ## rooms 8178.56 *** 8162.07 ***\r## (418.08) (417.94) ## lnox -10951.41 ***\r## (1457.92) ## -----------------------------------------\r## R^2 0.54 0.54 ## Adj. R^2 0.53 0.53 ## Num. obs. 506 506 ## =========================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rEn este caso, ambos modelos presentan los mismos valores en \\(R^2\\) y \\(R^2\\) ajustado. No obstante, es posible apreciar que los coeficientes de \\(nox\\) y \\(log(nox)\\) son diferentes. Lo mismo sucede con los coeficientes estimados para \\(rooms\\), que no analizaremos en este ejemplo. Interpretemos los dos primeros por separado:\n\r\\(nox\\): por cada unidad que aumente \\(nox\\), se espera que el precio mediano de las casas en cada comunidad disminuya en 1884.68 dólares en promedio.\r\\(lnox\\): por cada punto porcentual (1%) que aumente \\(lnox\\), se espera que el precio mediano de las casas disminuya, en promedio, 10951.41 dólares.\r\r\rb) Transformación funcional logarítmica a variable \\(y\\)\r¿Y si, en lugar de transformar logarítmicamente al predictor, lo hacemos con la variable predicha?\n\\[\r\\begin{equation}\rlog(price) = \\beta_0 + \\beta_1nox + \\beta_2rooms\r\\end{equation}\r\\]\nm3 = lm(lprice ~ nox + rooms, data = hprice2)\rscreenreg(list(m1,m2, m3), custom.model.names = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;))\r## ## =====================================================\r## Modelo 1 Modelo 2 Modelo 3 ## -----------------------------------------------------\r## (Intercept) -18423.40 *** -10237.60 * 8.70 ***\r## (3346.66) (4125.88) (0.15) ## nox -1884.68 *** -0.12 ***\r## (253.57) (0.01) ## rooms 8178.56 *** 8162.07 *** 0.31 ***\r## (418.08) (417.94) (0.02) ## lnox -10951.41 *** ## (1457.92) ## -----------------------------------------------------\r## R^2 0.54 0.54 0.51 ## Adj. R^2 0.53 0.53 0.51 ## Num. obs. 506 506 506 ## =====================================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rEn este caso, podemos darnos cuenta de dos cosas fundamentales:\n\rLa magnitud de los coeficientes ha disminuido bastante. Esto se debe a que, ahora, las variaciones por unidad de \\(x\\) tendrán un efecto porcentual en la variación media de \\(y\\).\rLos estadísticos \\(R^2\\) de este último modelo son levemente inferiores que los estimados para los modelos previos. Esto nos indica que transformar funcionalmente las variables incorporadas en nuestro modelo puede afectar también su bondad de ajuste.\r\rAsí, podemos señalar que, por cada unidad que aumenta el promedio de habitaciones en las casas de cada comunidad, se espera que el precio de estas aumente, en promedio, un 31%. En estos casos denominamos a \\(\\beta_2*100\\) como semielasticidad de \\(price\\) respecto a \\(rooms\\). No obstante, a medida que la variación de \\(log(y)\\) aumenta, se incrementa el error de aproximación que se realiza al estimar el efecto como %\\(\\vartriangle y \\approx 100*\\vartriangle log(y)\\). Para ello, debemos ejecutar el siguiente procedimiento:\n\\[\r\\begin{equation}\r\\%\\vartriangle \\hat{y} = 100 * [exp(\\beta x) - 1]\r\\end{equation}\r\\]\nEn este caso:\n\\[\r\\begin{equation}\r\\%\\vartriangle \\hat{y} = 100 * [exp(.31*1) - 1] = 100 * [1.363-1] = 100* 0.363 = 36.3 \\%\r\\end{equation}\r\\]\n\rc) Transformación funcional logarítmica a variable \\(x\\) e \\(y\\)\rPor último, podemos incluso transformar funcionalmente a nuestras variables explicativas y explicada:\n\\[\r\\begin{equation}\rlog(price) = \\beta_0 + \\beta_1log(nox) + \\beta_2rooms\r\\end{equation}\r\\]\nm4 = lm(lprice ~ lnox + rooms, data = hprice2)\rscreenreg(list(m1,m2, m3, m4), custom.model.names = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;))\r## ## =================================================================\r## Modelo 1 Modelo 2 Modelo 3 Modelo 4 ## -----------------------------------------------------------------\r## (Intercept) -18423.40 *** -10237.60 * 8.70 *** 9.23 ***\r## (3346.66) (4125.88) (0.15) (0.19) ## nox -1884.68 *** -0.12 *** ## (253.57) (0.01) ## rooms 8178.56 *** 8162.07 *** 0.31 *** 0.31 ***\r## (418.08) (417.94) (0.02) (0.02) ## lnox -10951.41 *** -0.72 ***\r## (1457.92) (0.07) ## -----------------------------------------------------------------\r## R^2 0.54 0.54 0.51 0.51 ## Adj. R^2 0.53 0.53 0.51 0.51 ## Num. obs. 506 506 506 506 ## =================================================================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\rPodemos notar que, mientras los modelos 3 y 4 comparten los mismos estadísticos \\(R^2\\) y el mismo coeficiente para \\(rooms\\), los coeficientes estimados para \\(nox\\) y \\(lnox\\) sobre \\(lprice\\) son diferentes. Comparemos sus interpretaciones:\n\r\\(nox\\): por cada unidad que aumente la concentración de óxido nitroso en el ambiente de la comunidad, el precio mediano de sus casas disminuirá, en promedio, un 12%.\r\\(lnox\\): por cada punto porcentual (1%) que aumente la concentración de óxido nitroso en el ambiente de la comunidad, el precio mediano de sus casas disminuirá, en promedio, en un 72%.\r\r\r\r3. Funciones cuadráticas\rSe emplean para captar efectos marginales crecientes o decrecientes. En términos matemáticos, se formula\n\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x + \\beta_2x^2\r\\end{equation}\r\\]\rEn R, creamos una nueva variable con el cuadrado de habitaciones \\(rooms2\\), y luego la incorporamos al modelo como variable explicativa\nhprice2$rooms2 = (hprice2$rooms)^2\rm5 = lm(price ~ rooms + rooms2, data = hprice2)\rscreenreg(list(m5), custom.model.names = c(\u0026quot;Modelo 5\u0026quot;))\r## ## ==========================\r## Modelo 5 ## --------------------------\r## (Intercept) 66203.18 ***\r## (12111.41) ## rooms -22713.18 ***\r## (3756.83) ## rooms2 2477.09 ***\r## (290.74) ## --------------------------\r## R^2 0.55 ## Adj. R^2 0.55 ## Num. obs. 506 ## ==========================\r## *** p \u0026lt; 0.001; ** p \u0026lt; 0.01; * p \u0026lt; 0.05\r\\[\r\\begin{equation}\ry = \\beta_0 + \\beta_1x + \\beta_2x^2\r\\end{equation}\r\\]\nDadas las características de una función cuadrática, en este caso no tiene sentido mantener \\(x^2\\) constante mientras varía \\(x\\), por lo que \\(\\beta_1\\) no mide la variación en y respecto de \\(x\\). Luego, se tiene la aproximación\n\\[\r\\begin{equation}\r\\vartriangle \\hat{y} \\approx (\\beta_1x + 2\\beta_2x)\\vartriangle x,\r\\end{equation}\r\\]\nde manera que\n\\[\r\\begin{equation}\r\\vartriangle \\hat{y} / \\vartriangle x \\approx \\beta_1x + 2\\beta_2x\r\\end{equation}\r\\]\nAsí, la pendiente de la relación entre \\(x\\) e \\(y\\) depende de \\(x\\), equivaliendo a \\(\\beta_1x + 2\\beta_2x\\). Si \\(x=0\\), es posible señalar que \\(\\beta_1\\) puede interpretarse como la pendiente aproximada al pasar de \\(x=0\\) a \\(x=1\\). Si queremos conocer el efecto de \\(x\\) sobre \\(y\\), simplemente interpretamos el coeficiente de la tabla. No obstante, para conocer el efecto de \\(x\\) sobre \\(y\\), debemos reemplazar para analizar la variabilidad de \\(y\\) por cada unidad que aumenta \\(x\\). En este caso:\n\\[\r\\begin{equation}\rprice = 66203.18 + -22713.18rooms + 2477.09rooms^2\r\\end{equation}\r\\]\nAsí, si queremois conocer la diferencia de precio estimada para una casa de 4 habitaciones versus una de tres:\n\\(price = 66203.18 + -22713.18*3 + 2477.09*(3)^2 = 66203.18 + -68139.54 + 22293.81 = 20357.45\\)\n\\(price = 66203.18 + -22713.18*4 + 2477.09*(4)^2 = 66203.18 + -90852.72 + 39633.44 = 14983.9\\)\nEn este caso, el modelo predice que el precio mediano tendería a disminuir en \\(20357.45 - 14983.9\\) \\(5373.55\\) por cada habitación extra, lo cual sería contraintuitivo. Recordemos que las funciones cuadráticas tienen forma de parábolas, por lo que, pasado un punto máximo o mínimo, la relación se invertirá. Es decir, si para los valores inferiores de \\(x\\) el efecto sobre \\(y\\) es negativo, para los valores superiores el efecto de \\(x\\) sobre \\(y\\) será positivo, y viceversa. Para estimarlo, seguimos la siguiente fórmula:\n\\[\r\\begin{equation}\rx^* = |{\\hat{\\beta1}}/(2\\hat{\\beta_2})|\r\\end{equation}\r\\]\nEn nuestro caso, esto equivale a \\(|{\\hat{\\beta1}}/(2\\hat{\\beta_2})| = |-22713.18/2*(2477.09)| = 4.58465\\). Es decir, si \\(x\u0026gt;4.58465\\), el efecto será negativo; mientras que valores de \\(x\u0026lt;4.58465\\) tendrán un efecto positivo sobre \\(y\\).\n\rResumen\rEn este práctico comprendimos cómo las transformaciones funcionales permiten solucionar problemas de estimación al estimar modelos de regresión lineal. Además, aprendimos a analizar los coeficientes de predictores transformados funcionalmente a través de la logaritmización y la elevación al cuadrado.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2d8b143ec44c88c4156cb60bc3485283","permalink":"/example/09-practico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/09-practico/","section":"example","summary":"0. Objetivo del práctico\rEl objetivo de este práctico es aprender a generar e interpretar modelos con transformaciones cuadrática y logarítmica en las variables \\(x\\) e \\(y\\) con lm().","tags":null,"title":"Transformaciones funcionales","type":"docs"},{"authors":null,"categories":null,"content":"\r\rClases (): Esta página contiene las presentaciones y lecturas correspondientes al tema.\n\rPrácticos (): Esta página contiene los ejercicios prácticos asociados a cada sesión de clase. Podrás encontrar el código de R. Esta página será muy importante para los controles sorpresa y proyecto de investigación.\n\rEvaluaciones (): Esta página contiene las instrucciones para cada evaluación.\n\r\rPuedes suscribir la planificación del curso con la URL del calendario en Outlook, Google Calendar o Apple Calendar:\n \r\r\rEstadística II\rClases\rPrácticos\rEvaluaciones\rTalleres\r\r7-16 de agosto\rUnidad 1. Muestras probabilísticas en ciencias sociales\r\r\r\r\r\r\r\r\r\r7 y 9 marzo\n(Sesión 1)\r1.1 Introducción al Diseño de Muestras en la Investigación Social 1.2 Conceptos Elementales del Muestreo e Inferencia Estadística\r\r\r\r\r\r\r14 y 16 marzo\n(Sesión 2)\r1.3 Muestreo Aleatorio Simple y otros tipos de muestreo 1.4 Análisis de muestras complejas\r\r\r\r\r\r\r21 marzo - 11 mayo\rUnidad 2. Modelo de Regresión Lineal\r\r\r\r\r\r\r\r\r\r21 y 24 marzo\n(Sesión 3)\r2.1. Método científico en ciencias sociales.\n2.2 Causalidad y noción de control.\r\r\r\r\r\r28 y 30 marzo\n(Sesión 4)\r2.3 Definición regresion lineal simple\n2.4 Estimador de MCO y sus propiedades\r\r\r\r\r\r\r\r4 y 6 abril\n(Sesión 5)\r2.5 Interpretacion coeficientes 2.6 Supuestos.\r\r\r\r\r\r\r\r11 y 13 abril\n(Sesión 6)\r2.7 Regresion lineal múltiple 2.8 Noción de efectos parciales\r\r\r\r\r\r\r\r18 y 20 abril\n(Sesión 7)\r2.9 Variables dependientes categóricas\r\r\r\r\r\r\r25 y 27 abril\n(Sesión 8)\r2.10 Inferencia y predicción en regresión lineal múltiple\r\r\r\r\r\r\r2 y 4 mayo\rSemana de receso\r\r\r\r\r\r\r\r\r9 y 11 mayo\rPrueba\r\r\r\r\r\r\r\r\r16 mayo-22 junio\rUnidad 3. Especificación y desafíos para el análisis de regresión lineal\r\r\r\r\r\r\r\r\r\r16 y 18 mayo\n(Sesión 9)\r3.1 Transformación de variables dependientes e independientes\r\r\r\r\r\r\r\r23 y 25 mayo\n(Sesión 10)\r3.2 Relaciones no lineales (interacciones)\r\r\r\r\r\r\r\r30 mayo y 1 junio\n(Sesión 11)\r3.3. Supuestos regresiones\r\r\r\r\r\r\r\r6 y 8 junio\n(Sesión 12)\r3.4. Errores de medición\r\r\r\r\r\r\r\r13 y 15 junio\n(Sesión 13)\r3.5. Omisión de variables relevantes e inclusión de variables irrelevantes.\r\r\r\r\r\r\r\r20 y 22 junio\n(Sesión 14)\r3.6. Extensiones.\r\r\r\r\r\r\r\r27 junio-6 julio\rEntrega y presentación examenes\r\r\r\r\r\r\r\r\r\rResumen Evaluaciones\rClases\rPrácticos\rEvaluaciones\rTalleres\r\r?\r Controles sorpresa\r\r\r\r\r\r\r\r\r21 a 23 marzo\r Control de repaso\r\r\r\r\r\r\r\r\r18 a 20 abril\r Entrega avance proyecto\r\r\r\r\r\r\r\r\r9 y 11 mayo\r Prueba\r\r\r\r\r\r\r\r\r27 a 6 julio\r Entrega final de proyecto\r\r\r\r\r\r\r\r\r\r\r\rPuedes descargar el programa apretando el siguiente botón:\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Clases (): Esta página contiene las presentaciones y lecturas correspondientes al tema.\n\rPrácticos (): Esta página contiene los ejercicios prácticos asociados a cada sesión de clase. Podrás encontrar el código de R.","tags":null,"title":"Calendario","type":"page"},{"authors":null,"categories":null,"content":"\r\rPropósitos de aprendizaje\rContenidos\r\rUnidad I: Muestras Probabilísticas en Ciencias Sociales (2 clases)\rUnidad II: Modelo de Regresión Lineal (6 clases)\rUnidad III: Especificación y desafíos del análisis de Regresión Lineal(5 clases)\r\rMetodología del curso\r\rRecursos principales de aprendizaje\r\rCalendario de actividades\rRecursos pedagógicos\r\r0. Referencias bibliográficas sobre R\r2. Referencias Unidad 1\r3. Referencias Unidad 2 y 3\r2. Sitios de consulta\r\rDescargar programa en pdf\rNormativa de la universidad\r\r\rDocente\r Valentina Andrade\rvalentinaandrade.netlify.app/\r valentinaandrade@uchile.cl\r @valentiandrade\r Agendar reunión\r\r\rApoyo Docente\r Nicolas Godoy\rINE\r nicolas.godoy.m@ug.uchile.cl\r Agendar reunión\r Alberto Reyes\r alberto.reyes@ug.uchile.cl\r Agendar reunión\r\r\rAyudantes\r Charo Astorga\r rosarioastorgap@gmail.com\r Agendar reunión\r Moira Martinez\r moira0martinez@gmail.com\r Agendar reunión\r\r\rDetalles del curso\r Clases: Martes o Jueves (1 bloque)\r Práctico: Martes o Jueves (2 bloque)\r Sala por definir Slack\r\r\r\rPropósitos de aprendizaje\rEl curso busca contribuir al desarrollo de habilidades de investigación cuantitativa aplicada en el área de muestreo y uso de modelos de regresión. Se espera que al término del curso los estudiantes sean capaces de:\nExplicar el rol de la teoría de muestreo en la investigación aplicada\ren ciencias sociales\n\rExaminar la ficha técnica de un estudio cuantitativo\n\rRealizar inferencia estadística con diseños de muestras complejas\n\rAplicar e interpretar modelos de regresión lineal en la investigación social\n\rExplicar la lógica del uso de modelos teóricos y estadísticos en la investigación social\n\rEjecutar adecuadamente los procedimientos necesarios para realizar los análisis anteriormente descritos con el lenguaje de programación R\n\r\r¡Iniciemos este desafío juntas/os!\n\rContenidos\rUnidad I: Muestras Probabilísticas en Ciencias Sociales (2 clases)\rIntroducción al Diseño de Muestras en la Investigación Social\n\rConceptos Elementales del Muestreo e Inferencia Estadística\n\rMuestreo Aleatorio Simple y otros tipos de muestreo\n\rAnálisis de muestras complejas\n\r\r\rUnidad II: Modelo de Regresión Lineal (6 clases)\rUso de modelos en ciencias sociales\n\rRegresión lineal simple y múltiple\n\rSupuestos de MRL\n\rInferencia y predicción\n\r\r\rUnidad III: Especificación y desafíos del análisis de Regresión Lineal(5 clases)\rEspecificación\n\rHeterocedasticidad\n\rErrores de medida\n\rOmisión de variables relevantes\n\r\r\r\rMetodología del curso\rDado el contexto de pandemia se tendrán tres espacios principales de aprendizaje:\nSesiones de clases lectivas (),donde se presentarán los aspectos centrales de los contenidos correspondientes a la semana.El documento de presentación de la clase se encontrará disponible en la pestaña de Clases de este sitio web del curso. Estas se desarrollarán en el primer bloque los días martes o jueves (depende de la sección).\n\rPrácticas guiadas (): cada tema de las sesiones se acompaña de una guía práctica de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma por cada estudiante semana a semana. También serán desarrolladas y revisadas cada semana en grupos pequeños con supervisión de ayudantes para dar mayor oportunidad de participación y resolver las dudas respectivas. Los prácticos se desarrollan en el segundo bloque de clase\n\rEvaluaciones (): para evaluar las clases teóricas durante el curso se tomará un control de repaso, controles sorpresa y una prueba. Además, se contempla la entrega de un proyecto de investigación grupal para aplicar los conceptos desarrollados en las clases teóricas y práctica. Este proyecto de investigación será evaluado con una entrega parcial y final (que corresponde al examen). La siguiente tabla muestra las ponderaciones de cada tipo de evaluación:\n\r\r\r\rEvaluación\rFormato\rFecha\rPonderación Nota Final\r\r\r\rControl repaso\rIndividual\r21-23 marzo\r8 %\r\rControles sorpresa\rIndividual\rSorpresa\r12% (en total)\r\rAvance proyecto\rGrupal\r18-20 abril\r25%\r\rPrueba\rIndividual\r9-11 mayo\r30%\r\rFinal proyecto (Examen)\rGrupal\r27 junio\r25%\r\r\r\rLos controles sorpresa corresponden a evaluaciones cortas y recurrentes que medirán el nivel de aprendizaje de la materia revisada en clases y ayudantías al momento de rendirlos. Estas evaluaciones se tomarán los días lunes o miércoles durante el horario de clase. Se estima la realización de aproximadamente 6 controles sorpresa, entre los cuales no se considerará la calificación más baja a la hora de calcular el promedio de notas obtenido en estas evaluaciones.\nEl proyecto de investigación se realizará en grupos de 3 estudiantes de una misma sección. Cada grupo de estudiantes deberá elegir a inicio del semestre un set de datos para realizar los análisis. Se deberá entregar un archivo en pdf, RMarkdown y Rscript (a través de la plataforma GitHub Classroom)\nLa o el estudiante que obtenga una nota inferior a 3,0 en su examen final será reprobado. Si su promedio (con examen incluido) es inferior a 4,0 se le mantendrá la nota promedio como calificación final del curso. Por el contrario, si el alumno obtiene un promedio igual o superior a 4,0 el estudiante será aprobado\nRecursos principales de aprendizaje\r1. Sitio web\nEl curso tiene disponible este sitio web, que he programado pues permite integrar texto y código de R, junto con hacer interactuar con otras plataformas como GitHub\n2. R, RStudio y RStudio Cloud \nEl software que se utilizará principalmente será R y su interfaz RStudio. Ahora bien, muchos usuario/as de R presentan problemas de instalación dada la capacidad de sus computadores y sistemas operativos. Por ello se promoverá el uso del servicio gratuito de RStudio.cloud.\n3. Slack \nSlack es una herramienta de uso frecuente en equipos de trabajo que utilizan R pues permite integrar script (o código) de distintos lenguajes en el chat. Se tendrá un espacio de trabajo en la app Slack que permite que cualquier persona del curso pueda hacer preguntas y cualquiera pueda responder. Esta es una de las prácticas que se promoverán en el curso pues es probable que los estudiantes tengan dudas similares a las de sus compañeros, por lo que las respuestas de la docente, ayudante y otros compañeros serán de libre disposición de todo el curso. Dentro del Slack se tendrán canales para hacer preguntas sobre las sesiones, tareas y proyectos, y el link que permite unirse a este estará disponible en el sitio del curso.\n Guía de uso de slack\n Unirse a Slack de curso\n4. GitHub \nGithub es una plataforma online que permite depositar archivos y el control de versiones (VCS), por lo que se ha transformado una herramienta fácil y popular para corregir, colaborar y compartir códigos de distintos lenguajes (no solo R). Utilizaremos esta plataforma para subir los avances y reportes, ayudarlos/as de manera directa con su código y darles feedback.\n\r\rCalendario de actividades\rEl calendario de actividades se puede revisar con detención en la pestaña planificación.\n\rRecursos pedagógicos\r0. Referencias bibliográficas sobre R\r\rWickham, H., \u0026amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). Sebastopol: O’Reilly. Libro con enfoque en el aprendizaje de R. Disponible en español como “R para ciencia de datos”\n\rDaniel Lüdecke (2021) Data Visualization for Statistics in Social Science R package version 2.8.7\n\rWickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686\n\rYihui Xie, J. J. Allaire, Garrett Grolemund (2021) R Markdown: The Definitive Guide\n\rBryan, Jenny (2019) Happy Git in R\n\r\r\r2. Referencias Unidad 1\r\rLohr, S. L. (2000). Muestreo: Diseño y análisis. México:International Thomson Editores\n\rPardo, Ruiz y San Martín (2015). Análisis de Datos en Ciencias Sociales y de la Salud I. Editorial Síntesis: Madrid.\n\r\r\r3. Referencias Unidad 2 y 3\r\rWooldridge, J. (2015), Introducción a la Econometría. Cengage Learning. Quinta edición.\n\rMoore, D (2005) Estadística Aplicada Básica\n\r\r\r2. Sitios de consulta\r\rlearn-R (Learn R - UAH)\rrOpensci (R Open Scicnce Tools)\rLaboratorio de Ciencia Social Abierta, Centro de Estudios de Conflicto y Cohesión Social (LISA-COES)\rStackoverflow\rRStudio Community\rRMarkdown\rsjPlot\rtidyverse\r\r\r\rDescargar programa en pdf\r\n\rNormativa de la universidad\rLos justificativos por inasistencia a clases y/o evaluaciones por motivos de enfermedad y/o otras razones deben hacerse a la coordinación de la carrera en el plazo establecido por el reglamento. Quienes no lo hagan serán evaluados con nota 1,0 o con inasistencia a clases, según corresponda. Para presentarse a examen se requiere nota promedio 3,5 y haber rendido todas las evaluaciones. En caso de no cumplir tales requisitos no podrá rendir examen. Por último, la ponderación de las evaluaciones no rendidas en clases será asignada a la ponderación del examen en la nota final de cada estudiante.\nReglamento Académico del Estudiante de Pregrado. Art. 23.- Cualquier conducta de un estudiante que tienda a viciar la evaluación de actividades académicas o que constituya fraude académico, figura que contempla irregularidades tales como copia, suplantación o alteración de evaluaciones, plagio, faltas a la ética profesional, sin que esta enumeración sea taxativa, dará origen a las siguientes sanciones, según la gravedad de la falta cometida: (i) nota mínima 1,0 (uno) en la respectiva evaluación; (ii) reprobación del curso respectivo; (iii) amonestación; (iv) permanencia condicional; (v) suspensión de actividades académicas por un período académico; (vi) expulsión de la Universidad.\nAsimismo, toda actividad de un estudiante que entorpezca gravemente y/o dificulte el normal desarrollo académico, podrá ser sancionada de conformidad a las disposiciones establecidas en el Reglamento de Conducta y Convivencia de la Universidad Alberto Hurtado.\nArt. 24.- Las dos primeras sanciones previstas en el artículo anterior, a saber (i) Nota mínima 1,0; y (ii) Reprobación del Curso respectivo, son prerrogativa del docente a cargo de la asignatura, quien deberá informarlas a la Dirección de la Carrera.\nPara evitar el plagio todo trabajo, composición o material documental que los estudiantes realicen debe citar adecuadamente las fuentes utilizadas, ya sea a través del sistema APA (American Psychological Association) http://www.apastyle.org o MLA (Modern Language Association) http://www.mla.org/.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"/syllabus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/syllabus/","section":"","summary":"Propósitos de aprendizaje\rContenidos\r\rUnidad I: Muestras Probabilísticas en Ciencias Sociales (2 clases)\rUnidad II: Modelo de Regresión Lineal (6 clases)\rUnidad III: Especificación y desafíos del análisis de Regresión Lineal(5 clases)\r\rMetodología del curso\r\rRecursos principales de aprendizaje\r\rCalendario de actividades\rRecursos pedagógicos\r\r0.","tags":null,"title":"Syllabus","type":"page"}]